{
  "version": 3,
  "sources": ["../../../../node_modules/@apollo/src/version.ts", "../../../../node_modules/@apollo/src/link/http/parseAndCheckHttpResponse.ts", "../../../../node_modules/@apollo/src/link/http/serializeFetchParameter.ts", "../../../../node_modules/@apollo/src/link/http/selectHttpOptionsAndBody.ts", "../../../../node_modules/@apollo/src/link/http/checkFetcher.ts", "../../../../node_modules/@apollo/src/link/http/createSignalIfSupported.ts", "../../../../node_modules/@apollo/src/link/http/selectURI.ts", "../../../../node_modules/@apollo/src/link/http/rewriteURIForGET.ts", "../../../../node_modules/@apollo/src/link/http/createHttpLink.ts", "../../../../node_modules/@apollo/src/link/http/HttpLink.ts", "../../../../node_modules/@wry/equality/src/equality.ts", "../../../../node_modules/@wry/trie/src/trie.ts", "../../../../node_modules/@wry/context/src/slot.ts", "../../../../node_modules/@wry/context/src/context.ts", "../../../../node_modules/optimism/src/cache.ts", "../../../../node_modules/optimism/src/context.ts", "../../../../node_modules/optimism/src/helpers.ts", "../../../../node_modules/optimism/src/entry.ts", "../../../../node_modules/optimism/src/dep.ts", "../../../../node_modules/optimism/src/index.ts", "../../../../node_modules/@apollo/src/cache/core/cache.ts", "../../../../node_modules/@apollo/src/cache/core/types/Cache.ts", "../../../../node_modules/@apollo/src/cache/core/types/common.ts", "../../../../node_modules/@apollo/src/cache/inmemory/helpers.ts", "../../../../node_modules/@apollo/src/cache/inmemory/entityStore.ts", "../../../../node_modules/@apollo/src/cache/inmemory/object-canon.ts", "../../../../node_modules/@apollo/src/cache/inmemory/readFromStore.ts", "../../../../node_modules/@apollo/src/cache/inmemory/reactiveVars.ts", "../../../../node_modules/@apollo/src/cache/inmemory/key-extractor.ts", "../../../../node_modules/@apollo/src/cache/inmemory/policies.ts", "../../../../node_modules/@apollo/src/cache/inmemory/writeToStore.ts", "../../../../node_modules/@apollo/src/cache/inmemory/inMemoryCache.ts", "../../../../node_modules/@apollo/src/errors/index.ts", "../../../../node_modules/@apollo/src/core/networkStatus.ts", "../../../../node_modules/@apollo/src/core/ObservableQuery.ts", "../../../../node_modules/@apollo/src/core/LocalState.ts", "../../../../node_modules/@apollo/src/core/QueryInfo.ts", "../../../../node_modules/@apollo/src/core/QueryManager.ts", "../../../../node_modules/@apollo/src/core/ApolloClient.ts", "../../../../node_modules/graphql-tag/src/index.ts", "../../../../node_modules/@apollo/src/core/index.ts", "../../../../node_modules/@apollo/src/react/context/ApolloConsumer.tsx", "../../../../node_modules/@apollo/src/react/context/ApolloContext.ts", "../../../../node_modules/@apollo/src/react/context/ApolloProvider.tsx", "../../../../node_modules/@apollo/src/react/hooks/useApolloClient.ts", "../../../../node_modules/@apollo/src/react/hooks/useLazyQuery.ts", "../../../../node_modules/@apollo/src/react/hooks/useQuery.ts", "../../../../node_modules/@apollo/src/react/parser/index.ts", "../../../../node_modules/@apollo/src/react/hooks/useMutation.ts", "../../../../node_modules/@apollo/src/react/hooks/useSubscription.ts", "../../../../node_modules/@apollo/src/react/hooks/useReactiveVar.ts"],
  "sourcesContent": ["export const version = 'local';\n", "import { Operation } from '../core';\nimport { throwServerError } from '../utils';\n\nconst { hasOwnProperty } = Object.prototype;\n\nexport type ServerParseError = Error & {\n  response: Response;\n  statusCode: number;\n  bodyText: string;\n};\n\nexport function parseAndCheckHttpResponse(\n  operations: Operation | Operation[],\n) {\n  return (response: Response) => response\n    .text()\n    .then(bodyText => {\n      try {\n        return JSON.parse(bodyText);\n      } catch (err) {\n        const parseError = err as ServerParseError;\n        parseError.name = 'ServerParseError';\n        parseError.response = response;\n        parseError.statusCode = response.status;\n        parseError.bodyText = bodyText;\n        throw parseError;\n      }\n    })\n    .then((result: any) => {\n      if (response.status >= 300) {\n        // Network error\n        throwServerError(\n          response,\n          result,\n          `Response not successful: Received status code ${response.status}`,\n        );\n      }\n\n      if (\n        !Array.isArray(result) &&\n        !hasOwnProperty.call(result, 'data') &&\n        !hasOwnProperty.call(result, 'errors')\n      ) {\n        // Data error\n        throwServerError(\n          response,\n          result,\n          `Server response was missing for query '${\n            Array.isArray(operations)\n              ? operations.map(op => op.operationName)\n              : operations.operationName\n          }'.`,\n        );\n      }\n      return result;\n    });\n}\n", "import { InvariantError } from '../../utilities/globals';\n\nexport type ClientParseError = InvariantError & {\n  parseError: Error;\n};\n\nexport const serializeFetchParameter = (p: any, label: string) => {\n  let serialized;\n  try {\n    serialized = JSON.stringify(p);\n  } catch (e) {\n    const parseError = new InvariantError(\n      `Network request failed. ${label} is not serializable: ${e.message}`,\n    ) as ClientParseError;\n    parseError.parseError = e;\n    throw parseError;\n  }\n  return serialized;\n};\n", "import { ASTNode, print } from 'graphql';\n\nimport { Operation } from '../core';\n\nexport interface Printer {\n  (node: ASTNode, originalPrint: typeof print): string\n};\n\nexport interface UriFunction {\n  (operation: Operation): string;\n}\n\nexport interface Body {\n  query?: string;\n  operationName?: string;\n  variables?: Record<string, any>;\n  extensions?: Record<string, any>;\n}\n\nexport interface HttpOptions {\n  /**\n   * The URI to use when fetching operations.\n   *\n   * Defaults to '/graphql'.\n   */\n  uri?: string | UriFunction;\n\n  /**\n   * Passes the extensions field to your graphql server.\n   *\n   * Defaults to false.\n   */\n  includeExtensions?: boolean;\n\n  /**\n   * A `fetch`-compatible API to use when making requests.\n   */\n  fetch?: WindowOrWorkerGlobalScope['fetch'];\n\n  /**\n   * An object representing values to be sent as headers on the request.\n   */\n  headers?: any;\n\n  /**\n   * The credentials policy you want to use for the fetch call.\n   */\n  credentials?: string;\n\n  /**\n   * Any overrides of the fetch options argument to pass to the fetch call.\n   */\n  fetchOptions?: any;\n\n  /**\n   * If set to true, use the HTTP GET method for query operations. Mutations\n   * will still use the method specified in fetchOptions.method (which defaults\n   * to POST).\n   */\n  useGETForQueries?: boolean;\n\n  /**\n   * If set to true, the default behavior of stripping unused variables\n   * from the request will be disabled.\n   *\n   * Unused variables are likely to trigger server-side validation errors,\n   * per https://spec.graphql.org/draft/#sec-All-Variables-Used, but this\n   * includeUnusedVariables option can be useful if your server deviates\n   * from the GraphQL specification by not strictly enforcing that rule.\n   */\n  includeUnusedVariables?: boolean;\n  /**\n   * A function to substitute for the default query print function. Can be\n   * used to apply changes to the results of the print function.\n   */\n   print?: Printer;\n}\n\nexport interface HttpQueryOptions {\n  includeQuery?: boolean;\n  includeExtensions?: boolean;\n}\n\nexport interface HttpConfig {\n  http?: HttpQueryOptions;\n  options?: any;\n  headers?: any;\n  credentials?: any;\n}\n\nconst defaultHttpOptions: HttpQueryOptions = {\n  includeQuery: true,\n  includeExtensions: false,\n};\n\nconst defaultHeaders = {\n  // headers are case insensitive (https://stackoverflow.com/a/5259004)\n  accept: '*/*',\n  'content-type': 'application/json',\n};\n\nconst defaultOptions = {\n  method: 'POST',\n};\n\nexport const fallbackHttpConfig = {\n  http: defaultHttpOptions,\n  headers: defaultHeaders,\n  options: defaultOptions,\n};\n\nexport const defaultPrinter: Printer = (ast, printer) => printer(ast);\n\nexport function selectHttpOptionsAndBody(\n  operation: Operation,\n  fallbackConfig: HttpConfig,\n  ...configs: Array<HttpConfig>\n) {\n  configs.unshift(fallbackConfig);\n  return selectHttpOptionsAndBodyInternal(\n    operation,\n    defaultPrinter,\n    ...configs,\n  );\n}\n\nexport function selectHttpOptionsAndBodyInternal(\n  operation: Operation,\n  printer: Printer,\n  ...configs: HttpConfig[]\n) {\n  let options = {} as HttpConfig & Record<string, any>;\n  let http = {} as HttpQueryOptions;\n\n  configs.forEach(config => {\n    options = {\n      ...options,\n      ...config.options,\n      headers: {\n        ...options.headers,\n        ...headersToLowerCase(config.headers),\n      },\n    };\n\n    if (config.credentials) {\n      options.credentials = config.credentials;\n    }\n\n    http = {\n      ...http,\n      ...config.http,\n    };\n  });\n\n  //The body depends on the http options\n  const { operationName, extensions, variables, query } = operation;\n  const body: Body = { operationName, variables };\n\n  if (http.includeExtensions) (body as any).extensions = extensions;\n\n  // not sending the query (i.e persisted queries)\n  if (http.includeQuery) (body as any).query = printer(query, print);\n\n  return {\n    options,\n    body,\n  };\n};\n\nfunction headersToLowerCase(\n  headers: Record<string, string> | undefined\n): typeof headers {\n  if (headers) {\n    const normalized = Object.create(null);\n    Object.keys(Object(headers)).forEach(name => {\n      normalized[name.toLowerCase()] = headers[name];\n    });\n    return normalized;\n  }\n  return headers;\n}\n", "import { InvariantError } from '../../utilities/globals';\n\nexport const checkFetcher = (fetcher: WindowOrWorkerGlobalScope['fetch'] | undefined) => {\n  if (!fetcher && typeof fetch === 'undefined') {\n    throw new InvariantError(`\n\"fetch\" has not been found globally and no fetcher has been \\\nconfigured. To fix this, install a fetch package (like \\\nhttps://www.npmjs.com/package/cross-fetch), instantiate the \\\nfetcher, and pass it into your HttpLink constructor. For example:\n\nimport fetch from 'cross-fetch';\nimport { ApolloClient, HttpLink } from '@apollo/client';\nconst client = new ApolloClient({\n  link: new HttpLink({ uri: '/graphql', fetch })\n});\n    `);\n  }\n};\n", "export const createSignalIfSupported = () => {\n  if (typeof AbortController === 'undefined')\n    return { controller: false, signal: false };\n\n  const controller = new AbortController();\n  const signal = controller.signal;\n  return { controller, signal };\n};\n", "import { Operation } from '../core';\n\nexport const selectURI = (\n  operation: Operation,\n  fallbackURI?: string | ((operation: Operation) => string),\n) => {\n  const context = operation.getContext();\n  const contextURI = context.uri;\n\n  if (contextURI) {\n    return contextURI;\n  } else if (typeof fallbackURI === 'function') {\n    return fallbackURI(operation);\n  } else {\n    return (fallbackURI as string) || '/graphql';\n  }\n};\n", "import { serializeFetchParameter } from './serializeFetchParameter';\nimport { Body } from './selectHttpOptionsAndBody';\n\n// For GET operations, returns the given URI rewritten with parameters, or a\n// parse error.\nexport function rewriteURIForGET(chosenURI: string, body: Body) {\n  // Implement the standard HTTP GET serialization, plus 'extensions'. Note\n  // the extra level of JSON serialization!\n  const queryParams: string[] = [];\n  const addQueryParam = (key: string, value: string) => {\n    queryParams.push(`${key}=${encodeURIComponent(value)}`);\n  };\n\n  if ('query' in body) {\n    addQueryParam('query', body.query!);\n  }\n  if (body.operationName) {\n    addQueryParam('operationName', body.operationName);\n  }\n  if (body.variables) {\n    let serializedVariables;\n    try {\n      serializedVariables = serializeFetchParameter(\n        body.variables,\n        'Variables map',\n      );\n    } catch (parseError) {\n      return { parseError };\n    }\n    addQueryParam('variables', serializedVariables);\n  }\n  if (body.extensions) {\n    let serializedExtensions;\n    try {\n      serializedExtensions = serializeFetchParameter(\n        body.extensions,\n        'Extensions map',\n      );\n    } catch (parseError) {\n      return { parseError };\n    }\n    addQueryParam('extensions', serializedExtensions);\n  }\n\n  // Reconstruct the URI with added query params.\n  // XXX This assumes that the URI is well-formed and that it doesn't\n  //     already contain any of these query params. We could instead use the\n  //     URL API and take a polyfill (whatwg-url@6) for older browsers that\n  //     don't support URLSearchParams. Note that some browsers (and\n  //     versions of whatwg-url) support URL but not URLSearchParams!\n  let fragment = '',\n    preFragment = chosenURI;\n  const fragmentStart = chosenURI.indexOf('#');\n  if (fragmentStart !== -1) {\n    fragment = chosenURI.substr(fragmentStart);\n    preFragment = chosenURI.substr(0, fragmentStart);\n  }\n  const queryParamsPrefix = preFragment.indexOf('?') === -1 ? '?' : '&';\n  const newURI =\n    preFragment + queryParamsPrefix + queryParams.join('&') + fragment;\n  return { newURI };\n}\n", "import '../../utilities/globals';\n\nimport { visit, DefinitionNode, VariableDefinitionNode } from 'graphql';\n\nimport { ApolloLink } from '../core';\nimport { Observable } from '../../utilities';\nimport { serializeFetchParameter } from './serializeFetchParameter';\nimport { selectURI } from './selectURI';\nimport { parseAndCheckHttpResponse } from './parseAndCheckHttpResponse';\nimport { checkFetcher } from './checkFetcher';\nimport {\n  selectHttpOptionsAndBodyInternal,\n  defaultPrinter,\n  fallbackHttpConfig,\n  HttpOptions\n} from './selectHttpOptionsAndBody';\nimport { createSignalIfSupported } from './createSignalIfSupported';\nimport { rewriteURIForGET } from './rewriteURIForGET';\nimport { fromError } from '../utils';\nimport { maybe } from '../../utilities';\n\nconst backupFetch = maybe(() => fetch);\n\nexport const createHttpLink = (linkOptions: HttpOptions = {}) => {\n  let {\n    uri = '/graphql',\n    // use default global fetch if nothing passed in\n    fetch: preferredFetch,\n    print = defaultPrinter,\n    includeExtensions,\n    useGETForQueries,\n    includeUnusedVariables = false,\n    ...requestOptions\n  } = linkOptions;\n\n  if (__DEV__) {\n    // Make sure at least one of preferredFetch, window.fetch, or backupFetch is\n    // defined, so requests won't fail at runtime.\n    checkFetcher(preferredFetch || backupFetch);\n  }\n\n  const linkConfig = {\n    http: { includeExtensions },\n    options: requestOptions.fetchOptions,\n    credentials: requestOptions.credentials,\n    headers: requestOptions.headers,\n  };\n\n  return new ApolloLink(operation => {\n    let chosenURI = selectURI(operation, uri);\n\n    const context = operation.getContext();\n\n    // `apollographql-client-*` headers are automatically set if a\n    // `clientAwareness` object is found in the context. These headers are\n    // set first, followed by the rest of the headers pulled from\n    // `context.headers`. If desired, `apollographql-client-*` headers set by\n    // the `clientAwareness` object can be overridden by\n    // `apollographql-client-*` headers set in `context.headers`.\n    const clientAwarenessHeaders: {\n      'apollographql-client-name'?: string;\n      'apollographql-client-version'?: string;\n    } = {};\n\n    if (context.clientAwareness) {\n      const { name, version } = context.clientAwareness;\n      if (name) {\n        clientAwarenessHeaders['apollographql-client-name'] = name;\n      }\n      if (version) {\n        clientAwarenessHeaders['apollographql-client-version'] = version;\n      }\n    }\n\n    const contextHeaders = { ...clientAwarenessHeaders, ...context.headers };\n\n    const contextConfig = {\n      http: context.http,\n      options: context.fetchOptions,\n      credentials: context.credentials,\n      headers: contextHeaders,\n    };\n\n    //uses fallback, link, and then context to build options\n    const { options, body } = selectHttpOptionsAndBodyInternal(\n      operation,\n      print,\n      fallbackHttpConfig,\n      linkConfig,\n      contextConfig,\n    );\n\n    if (body.variables && !includeUnusedVariables) {\n      const unusedNames = new Set(Object.keys(body.variables));\n      visit(operation.query, {\n        Variable(node, _key, parent) {\n          // A variable type definition at the top level of a query is not\n          // enough to silence server-side errors about the variable being\n          // unused, so variable definitions do not count as usage.\n          // https://spec.graphql.org/draft/#sec-All-Variables-Used\n          if (parent && (parent as VariableDefinitionNode).kind !== 'VariableDefinition') {\n            unusedNames.delete(node.name.value);\n          }\n        },\n      });\n      if (unusedNames.size) {\n        // Make a shallow copy of body.variables (with keys in the same\n        // order) and then delete unused variables from the copy.\n        body.variables = { ...body.variables };\n        unusedNames.forEach(name => {\n          delete body.variables![name];\n        });\n      }\n    }\n\n    let controller: any;\n    if (!(options as any).signal) {\n      const { controller: _controller, signal } = createSignalIfSupported();\n      controller = _controller;\n      if (controller) (options as any).signal = signal;\n    }\n\n    // If requested, set method to GET if there are no mutations.\n    const definitionIsMutation = (d: DefinitionNode) => {\n      return d.kind === 'OperationDefinition' && d.operation === 'mutation';\n    };\n    if (\n      useGETForQueries &&\n      !operation.query.definitions.some(definitionIsMutation)\n    ) {\n      options.method = 'GET';\n    }\n\n    if (options.method === 'GET') {\n      const { newURI, parseError } = rewriteURIForGET(chosenURI, body);\n      if (parseError) {\n        return fromError(parseError);\n      }\n      chosenURI = newURI;\n    } else {\n      try {\n        (options as any).body = serializeFetchParameter(body, 'Payload');\n      } catch (parseError) {\n        return fromError(parseError);\n      }\n    }\n\n    return new Observable(observer => {\n      // Prefer linkOptions.fetch (preferredFetch) if provided, and otherwise\n      // fall back to the *current* global window.fetch function (see issue\n      // #7832), or (if all else fails) the backupFetch function we saved when\n      // this module was first evaluated. This last option protects against the\n      // removal of window.fetch, which is unlikely but not impossible.\n      const currentFetch = preferredFetch || maybe(() => fetch) || backupFetch;\n\n      currentFetch!(chosenURI, options)\n        .then(response => {\n          operation.setContext({ response });\n          return response;\n        })\n        .then(parseAndCheckHttpResponse(operation))\n        .then(result => {\n          // we have data and can send it to back up the link chain\n          observer.next(result);\n          observer.complete();\n          return result;\n        })\n        .catch(err => {\n          // fetch was cancelled so it's already been cleaned up in the unsubscribe\n          if (err.name === 'AbortError') return;\n          // if it is a network error, BUT there is graphql result info\n          // fire the next observer before calling error\n          // this gives apollo-client (and react-apollo) the `graphqlErrors` and `networErrors`\n          // to pass to UI\n          // this should only happen if we *also* have data as part of the response key per\n          // the spec\n          if (err.result && err.result.errors && err.result.data) {\n            // if we don't call next, the UI can only show networkError because AC didn't\n            // get any graphqlErrors\n            // this is graphql execution result info (i.e errors and possibly data)\n            // this is because there is no formal spec how errors should translate to\n            // http status codes. So an auth error (401) could have both data\n            // from a public field, errors from a private field, and a status of 401\n            // {\n            //  user { // this will have errors\n            //    firstName\n            //  }\n            //  products { // this is public so will have data\n            //    cost\n            //  }\n            // }\n            //\n            // the result of above *could* look like this:\n            // {\n            //   data: { products: [{ cost: \"$10\" }] },\n            //   errors: [{\n            //      message: 'your session has timed out',\n            //      path: []\n            //   }]\n            // }\n            // status code of above would be a 401\n            // in the UI you want to show data where you can, errors as data where you can\n            // and use correct http status codes\n            observer.next(err.result);\n          }\n          observer.error(err);\n        });\n\n      return () => {\n        // XXX support canceling this request\n        // https://developers.google.com/web/updates/2017/09/abortable-fetch\n        if (controller) controller.abort();\n      };\n    });\n  });\n};\n", "import { ApolloLink, RequestHandler } from '../core';\nimport { HttpOptions } from './selectHttpOptionsAndBody';\nimport { createHttpLink } from './createHttpLink';\n\nexport class HttpLink extends ApolloLink {\n  public requester: RequestHandler;\n  constructor(public options: HttpOptions = {}) {\n    super(createHttpLink(options).request);\n  }\n}\n", "const { toString, hasOwnProperty } = Object.prototype;\nconst fnToStr = Function.prototype.toString;\nconst previousComparisons = new Map<object, Set<object>>();\n\n/**\n * Performs a deep equality check on two JavaScript values, tolerating cycles.\n */\nexport function equal(a: any, b: any): boolean {\n  try {\n    return check(a, b);\n  } finally {\n    previousComparisons.clear();\n  }\n}\n\n// Allow default imports as well.\nexport default equal;\n\nfunction check(a: any, b: any): boolean {\n  // If the two values are strictly equal, our job is easy.\n  if (a === b) {\n    return true;\n  }\n\n  // Object.prototype.toString returns a representation of the runtime type of\n  // the given value that is considerably more precise than typeof.\n  const aTag = toString.call(a);\n  const bTag = toString.call(b);\n\n  // If the runtime types of a and b are different, they could maybe be equal\n  // under some interpretation of equality, but for simplicity and performance\n  // we just return false instead.\n  if (aTag !== bTag) {\n    return false;\n  }\n\n  switch (aTag) {\n    case '[object Array]':\n      // Arrays are a lot like other objects, but we can cheaply compare their\n      // lengths as a short-cut before comparing their elements.\n      if (a.length !== b.length) return false;\n      // Fall through to object case...\n    case '[object Object]': {\n      if (previouslyCompared(a, b)) return true;\n\n      const aKeys = definedKeys(a);\n      const bKeys = definedKeys(b);\n\n      // If `a` and `b` have a different number of enumerable keys, they\n      // must be different.\n      const keyCount = aKeys.length;\n      if (keyCount !== bKeys.length) return false;\n\n      // Now make sure they have the same keys.\n      for (let k = 0; k < keyCount; ++k) {\n        if (!hasOwnProperty.call(b, aKeys[k])) {\n          return false;\n        }\n      }\n\n      // Finally, check deep equality of all child properties.\n      for (let k = 0; k < keyCount; ++k) {\n        const key = aKeys[k];\n        if (!check(a[key], b[key])) {\n          return false;\n        }\n      }\n\n      return true;\n    }\n\n    case '[object Error]':\n      return a.name === b.name && a.message === b.message;\n\n    case '[object Number]':\n      // Handle NaN, which is !== itself.\n      if (a !== a) return b !== b;\n      // Fall through to shared +a === +b case...\n    case '[object Boolean]':\n    case '[object Date]':\n      return +a === +b;\n\n    case '[object RegExp]':\n    case '[object String]':\n      return a == `${b}`;\n\n    case '[object Map]':\n    case '[object Set]': {\n      if (a.size !== b.size) return false;\n      if (previouslyCompared(a, b)) return true;\n\n      const aIterator = a.entries();\n      const isMap = aTag === '[object Map]';\n\n      while (true) {\n        const info = aIterator.next();\n        if (info.done) break;\n\n        // If a instanceof Set, aValue === aKey.\n        const [aKey, aValue] = info.value;\n\n        // So this works the same way for both Set and Map.\n        if (!b.has(aKey)) {\n          return false;\n        }\n\n        // However, we care about deep equality of values only when dealing\n        // with Map structures.\n        if (isMap && !check(aValue, b.get(aKey))) {\n          return false;\n        }\n      }\n\n      return true;\n    }\n\n    case '[object Uint16Array]':\n    case '[object Uint8Array]': // Buffer, in Node.js.\n    case '[object Uint32Array]':\n    case '[object Int32Array]':\n    case '[object Int8Array]':\n    case '[object Int16Array]':\n    case '[object ArrayBuffer]':\n      // DataView doesn't need these conversions, but the equality check is\n      // otherwise the same.\n      a = new Uint8Array(a);\n      b = new Uint8Array(b);\n      // Fall through...\n    case '[object DataView]': {\n      let len = a.byteLength;\n      if (len === b.byteLength) {\n        while (len-- && a[len] === b[len]) {\n          // Keep looping as long as the bytes are equal.\n        }\n      }\n      return len === -1;\n    }\n\n    case '[object AsyncFunction]':\n    case '[object GeneratorFunction]':\n    case '[object AsyncGeneratorFunction]':\n    case '[object Function]': {\n      const aCode = fnToStr.call(a);\n      if (aCode !== fnToStr.call(b)) {\n        return false;\n      }\n\n      // We consider non-native functions equal if they have the same code\n      // (native functions require === because their code is censored).\n      // Note that this behavior is not entirely sound, since !== function\n      // objects with the same code can behave differently depending on\n      // their closure scope. However, any function can behave differently\n      // depending on the values of its input arguments (including this)\n      // and its calling context (including its closure scope), even\n      // though the function object is === to itself; and it is entirely\n      // possible for functions that are not === to behave exactly the\n      // same under all conceivable circumstances. Because none of these\n      // factors are statically decidable in JavaScript, JS function\n      // equality is not well-defined. This ambiguity allows us to\n      // consider the best possible heuristic among various imperfect\n      // options, and equating non-native functions that have the same\n      // code has enormous practical benefits, such as when comparing\n      // functions that are repeatedly passed as fresh function\n      // expressions within objects that are otherwise deeply equal. Since\n      // any function created from the same syntactic expression (in the\n      // same code location) will always stringify to the same code\n      // according to fnToStr.call, we can reasonably expect these\n      // repeatedly passed function expressions to have the same code, and\n      // thus behave \"the same\" (with all the caveats mentioned above),\n      // even though the runtime function objects are !== to one another.\n      return !endsWith(aCode, nativeCodeSuffix);\n    }\n  }\n\n  // Otherwise the values are not equal.\n  return false;\n}\n\nfunction definedKeys<TObject extends object>(obj: TObject) {\n  // Remember that the second argument to Array.prototype.filter will be\n  // used as `this` within the callback function.\n  return Object.keys(obj).filter(isDefinedKey, obj);\n}\nfunction isDefinedKey<TObject extends object>(\n  this: TObject,\n  key: keyof TObject,\n) {\n  return this[key] !== void 0;\n}\n\nconst nativeCodeSuffix = \"{ [native code] }\";\n\nfunction endsWith(full: string, suffix: string) {\n  const fromIndex = full.length - suffix.length;\n  return fromIndex >= 0 &&\n    full.indexOf(suffix, fromIndex) === fromIndex;\n}\n\nfunction previouslyCompared(a: object, b: object): boolean {\n  // Though cyclic references can make an object graph appear infinite from the\n  // perspective of a depth-first traversal, the graph still contains a finite\n  // number of distinct object references. We use the previousComparisons cache\n  // to avoid comparing the same pair of object references more than once, which\n  // guarantees termination (even if we end up comparing every object in one\n  // graph to every object in the other graph, which is extremely unlikely),\n  // while still allowing weird isomorphic structures (like rings with different\n  // lengths) a chance to pass the equality test.\n  let bSet = previousComparisons.get(a);\n  if (bSet) {\n    // Return true here because we can be sure false will be returned somewhere\n    // else if the objects are not equivalent.\n    if (bSet.has(b)) return true;\n  } else {\n    previousComparisons.set(a, bSet = new Set);\n  }\n  bSet.add(b);\n  return false;\n}\n", "// A [trie](https://en.wikipedia.org/wiki/Trie) data structure that holds\n// object keys weakly, yet can also hold non-object keys, unlike the\n// native `WeakMap`.\n\n// If no makeData function is supplied, the looked-up data will be an empty,\n// null-prototype Object.\nconst defaultMakeData = () => Object.create(null);\n\n// Useful for processing arguments objects as well as arrays.\nconst { forEach, slice } = Array.prototype;\n\nexport class Trie<Data> {\n  // Since a `WeakMap` cannot hold primitive values as keys, we need a\n  // backup `Map` instance to hold primitive keys. Both `this._weakMap`\n  // and `this._strongMap` are lazily initialized.\n  private weak?: WeakMap<any, Trie<Data>>;\n  private strong?: Map<any, Trie<Data>>;\n  private data?: Data;\n\n  constructor(\n    private weakness = true,\n    private makeData: (array: any[]) => Data = defaultMakeData,\n  ) {}\n\n  public lookup<T extends any[]>(...array: T): Data {\n    return this.lookupArray(array);\n  }\n\n  public lookupArray<T extends IArguments | any[]>(array: T): Data {\n    let node: Trie<Data> = this;\n    forEach.call(array, key => node = node.getChildTrie(key));\n    return node.data || (node.data = this.makeData(slice.call(array)));\n  }\n\n  private getChildTrie(key: any) {\n    const map = this.weakness && isObjRef(key)\n      ? this.weak || (this.weak = new WeakMap<any, Trie<Data>>())\n      : this.strong || (this.strong = new Map<any, Trie<Data>>());\n    let child = map.get(key);\n    if (!child) map.set(key, child = new Trie<Data>(this.weakness, this.makeData));\n    return child;\n  }\n}\n\nfunction isObjRef(value: any) {\n  switch (typeof value) {\n  case \"object\":\n    if (value === null) break;\n    // Fall through to return true...\n  case \"function\":\n    return true;\n  }\n  return false;\n}\n", "type Context = {\n  parent: Context | null;\n  slots: { [slotId: string]: any };\n}\n\n// This currentContext variable will only be used if the makeSlotClass\n// function is called, which happens only if this is the first copy of the\n// @wry/context package to be imported.\nlet currentContext: Context | null = null;\n\n// This unique internal object is used to denote the absence of a value\n// for a given Slot, and is never exposed to outside code.\nconst MISSING_VALUE: any = {};\n\nlet idCounter = 1;\n\n// Although we can't do anything about the cost of duplicated code from\n// accidentally bundling multiple copies of the @wry/context package, we can\n// avoid creating the Slot class more than once using makeSlotClass.\nconst makeSlotClass = () => class Slot<TValue> {\n  // If you have a Slot object, you can find out its slot.id, but you cannot\n  // guess the slot.id of a Slot you don't have access to, thanks to the\n  // randomized suffix.\n  public readonly id = [\n    \"slot\",\n    idCounter++,\n    Date.now(),\n    Math.random().toString(36).slice(2),\n  ].join(\":\");\n\n  public hasValue() {\n    for (let context = currentContext; context; context = context.parent) {\n      // We use the Slot object iself as a key to its value, which means the\n      // value cannot be obtained without a reference to the Slot object.\n      if (this.id in context.slots) {\n        const value = context.slots[this.id];\n        if (value === MISSING_VALUE) break;\n        if (context !== currentContext) {\n          // Cache the value in currentContext.slots so the next lookup will\n          // be faster. This caching is safe because the tree of contexts and\n          // the values of the slots are logically immutable.\n          currentContext!.slots[this.id] = value;\n        }\n        return true;\n      }\n    }\n    if (currentContext) {\n      // If a value was not found for this Slot, it's never going to be found\n      // no matter how many times we look it up, so we might as well cache\n      // the absence of the value, too.\n      currentContext.slots[this.id] = MISSING_VALUE;\n    }\n    return false;\n  }\n\n  public getValue(): TValue | undefined {\n    if (this.hasValue()) {\n      return currentContext!.slots[this.id] as TValue;\n    }\n  }\n\n  public withValue<TResult, TArgs extends any[], TThis = any>(\n    value: TValue,\n    callback: (this: TThis, ...args: TArgs) => TResult,\n    // Given the prevalence of arrow functions, specifying arguments is likely\n    // to be much more common than specifying `this`, hence this ordering:\n    args?: TArgs,\n    thisArg?: TThis,\n  ): TResult {\n    const slots = {\n      __proto__: null,\n      [this.id]: value,\n    };\n    const parent = currentContext;\n    currentContext = { parent, slots };\n    try {\n      // Function.prototype.apply allows the arguments array argument to be\n      // omitted or undefined, so args! is fine here.\n      return callback.apply(thisArg!, args!);\n    } finally {\n      currentContext = parent;\n    }\n  }\n\n  // Capture the current context and wrap a callback function so that it\n  // reestablishes the captured context when called.\n  static bind<TArgs extends any[], TResult, TThis = any>(\n    callback: (this: TThis, ...args: TArgs) => TResult,\n  ) {\n    const context = currentContext;\n    return function (this: TThis) {\n      const saved = currentContext;\n      try {\n        currentContext = context;\n        return callback.apply(this, arguments as any);\n      } finally {\n        currentContext = saved;\n      }\n    } as typeof callback;\n  }\n\n  // Immediately run a callback function without any captured context.\n  static noContext<TResult, TArgs extends any[], TThis = any>(\n    callback: (this: TThis, ...args: TArgs) => TResult,\n    // Given the prevalence of arrow functions, specifying arguments is likely\n    // to be much more common than specifying `this`, hence this ordering:\n    args?: TArgs,\n    thisArg?: TThis,\n  ) {\n    if (currentContext) {\n      const saved = currentContext;\n      try {\n        currentContext = null;\n        // Function.prototype.apply allows the arguments array argument to be\n        // omitted or undefined, so args! is fine here.\n        return callback.apply(thisArg!, args!);\n      } finally {\n        currentContext = saved;\n      }\n    } else {\n      return callback.apply(thisArg!, args!);\n    }\n  }\n};\n\n// We store a single global implementation of the Slot class as a permanent\n// non-enumerable symbol property of the Array constructor. This obfuscation\n// does nothing to prevent access to the Slot class, but at least it ensures\n// the implementation (i.e. currentContext) cannot be tampered with, and all\n// copies of the @wry/context package (hopefully just one) will share the\n// same Slot implementation. Since the first copy of the @wry/context package\n// to be imported wins, this technique imposes a very high cost for any\n// future breaking changes to the Slot class.\nconst globalKey = \"@wry/context:Slot\";\nconst host = Array as any;\n\nexport const Slot: ReturnType<typeof makeSlotClass> = host[globalKey] || function () {\n  const Slot = makeSlotClass();\n  try {\n    Object.defineProperty(host, globalKey, {\n      value: host[globalKey] = Slot,\n      enumerable: false,\n      writable: false,\n      configurable: false,\n    });\n  } finally {\n    return Slot;\n  }\n}();\n", "import { Slot } from \"./slot\";\nexport { Slot }\nexport const { bind, noContext } = Slot;\n\n// Relying on the @types/node declaration of global.setTimeout can make\n// things tricky for dowstream projects (see PR #7).\ndeclare function setTimeout(\n  callback: (...args: any[]) => any,\n  ms?: number,\n  ...args: any[]\n): any;\n\n// Like global.setTimeout, except the callback runs with captured context.\nexport { setTimeoutWithContext as setTimeout };\nfunction setTimeoutWithContext(callback: () => any, delay: number) {\n  return setTimeout(bind(callback), delay);\n}\n\n// Turn any generator function into an async function (using yield instead\n// of await), with context automatically preserved across yields.\nexport function asyncFromGen<\n  TArgs extends any[],\n  TYield = any,\n  TReturn = any,\n  TNext = any,\n>(\n  genFn: (...args: TArgs) => Generator<TYield, TReturn, TNext>\n) {\n  return function (this: any) {\n    const gen = genFn.apply(this, arguments as any);\n\n    type Method = (\n      this: Generator<TYield, TReturn, TNext>,\n      arg: any,\n    ) => IteratorResult<TYield, TReturn>;\n\n    const boundNext: Method = bind(gen.next);\n    const boundThrow: Method = bind(gen.throw!);\n\n    return new Promise((resolve, reject) => {\n      function invoke(method: Method, argument: any) {\n        try {\n          var result: any = method.call(gen, argument);\n        } catch (error) {\n          return reject(error);\n        }\n        const next = result.done ? resolve : invokeNext;\n        if (isPromiseLike(result.value)) {\n          result.value.then(next, result.done ? reject : invokeThrow);\n        } else {\n          next(result.value);\n        }\n      }\n      const invokeNext = (value?: any) => invoke(boundNext, value);\n      const invokeThrow = (error: any) => invoke(boundThrow, error);\n      invokeNext();\n    });\n  } as (...args: TArgs) => Promise<any>;\n}\n\nfunction isPromiseLike(value: any): value is PromiseLike<any> {\n  return value && typeof value.then === \"function\";\n}\n\n// If you use the fibers npm package to implement coroutines in Node.js,\n// you should call this function at least once to ensure context management\n// remains coherent across any yields.\nconst wrappedFibers: Function[] = [];\nexport function wrapYieldingFiberMethods<F extends Function>(Fiber: F): F {\n  // There can be only one implementation of Fiber per process, so this array\n  // should never grow longer than one element.\n  if (wrappedFibers.indexOf(Fiber) < 0) {\n    const wrap = (obj: any, method: string) => {\n      const fn = obj[method];\n      obj[method] = function () {\n        return noContext(fn, arguments as any, this);\n      };\n    }\n    // These methods can yield, according to\n    // https://github.com/laverdet/node-fibers/blob/ddebed9b8ae3883e57f822e2108e6943e5c8d2a8/fibers.js#L97-L100\n    wrap(Fiber, \"yield\");\n    wrap(Fiber.prototype, \"run\");\n    wrap(Fiber.prototype, \"throwInto\");\n    wrappedFibers.push(Fiber);\n  }\n  return Fiber;\n}\n", "interface Node<K, V> {\n  key: K;\n  value: V;\n  newer: Node<K, V> | null;\n  older: Node<K, V> | null;\n}\n\nfunction defaultDispose() {}\n\nexport class Cache<K = any, V = any> {\n  private map = new Map<K, Node<K, V>>();\n  private newest: Node<K, V> | null = null;\n  private oldest: Node<K, V> | null = null;\n\n  constructor(\n    private max = Infinity,\n    public dispose: (value: V, key: K) => void = defaultDispose,\n  ) {}\n\n  public has(key: K): boolean {\n    return this.map.has(key);\n  }\n\n  public get(key: K): V | undefined {\n    const node = this.getNode(key);\n    return node && node.value;\n  }\n\n  private getNode(key: K): Node<K, V> | undefined {\n    const node = this.map.get(key);\n\n    if (node && node !== this.newest) {\n      const { older, newer } = node;\n\n      if (newer) {\n        newer.older = older;\n      }\n\n      if (older) {\n        older.newer = newer;\n      }\n\n      node.older = this.newest;\n      node.older!.newer = node;\n\n      node.newer = null;\n      this.newest = node;\n\n      if (node === this.oldest) {\n        this.oldest = newer;\n      }\n    }\n\n    return node;\n  }\n\n  public set(key: K, value: V): V {\n    let node = this.getNode(key);\n    if (node) {\n      return node.value = value;\n    }\n\n    node = {\n      key,\n      value,\n      newer: null,\n      older: this.newest\n    };\n\n    if (this.newest) {\n      this.newest.newer = node;\n    }\n\n    this.newest = node;\n    this.oldest = this.oldest || node;\n\n    this.map.set(key, node);\n\n    return node.value;\n  }\n\n  public clean() {\n    while (this.oldest && this.map.size > this.max) {\n      this.delete(this.oldest.key);\n    }\n  }\n\n  public delete(key: K): boolean {\n    const node = this.map.get(key);\n    if (node) {\n      if (node === this.newest) {\n        this.newest = node.older;\n      }\n\n      if (node === this.oldest) {\n        this.oldest = node.newer;\n      }\n\n      if (node.newer) {\n        node.newer.older = node.older;\n      }\n\n      if (node.older) {\n        node.older.newer = node.newer;\n      }\n\n      this.map.delete(key);\n      this.dispose(node.value, key);\n\n      return true;\n    }\n\n    return false;\n  }\n}\n", "import { AnyEntry } from \"./entry\";\nimport { Slot } from \"@wry/context\";\n\nexport const parentEntrySlot = new Slot<AnyEntry>();\n\nexport {\n  bind as bindContext,\n  noContext,\n  setTimeout,\n  asyncFromGen,\n} from \"@wry/context\";\n", "export const {\n  hasOwnProperty,\n} = Object.prototype;\n\nexport const {\n  // This Array.from polyfill is restricted to working with Set<any> for now,\n  // but we can improve the polyfill and add other input types, as needed. Note\n  // that this fallback implementation will only be used if the host environment\n  // does not support a native Array.from function. In most modern JS runtimes,\n  // the toArray function exported here will be === Array.from.\n  from: toArray = (collection: Set<any>) => {\n    const array: any[] = [];\n    collection.forEach(item => array.push(item));\n    return array;\n  },\n} = Array;\n\nexport type Unsubscribable = {\n  unsubscribe?: void | (() => any);\n}\n\nexport function maybeUnsubscribe(entryOrDep: Unsubscribable) {\n  const { unsubscribe } = entryOrDep;\n  if (typeof unsubscribe === \"function\") {\n    entryOrDep.unsubscribe = void 0;\n    unsubscribe();\n  }\n}\n", "import { parentEntrySlot } from \"./context\";\nimport { OptimisticWrapOptions } from \"./index\";\nimport { Dep } from \"./dep\";\nimport { maybeUnsubscribe, toArray, Unsubscribable } from \"./helpers\";\n\nconst emptySetPool: Set<any>[] = [];\nconst POOL_TARGET_SIZE = 100;\n\n// Since this package might be used browsers, we should avoid using the\n// Node built-in assert module.\nfunction assert(condition: any, optionalMessage?: string) {\n  if (! condition) {\n    throw new Error(optionalMessage || \"assertion failure\");\n  }\n}\n\n// Since exceptions are cached just like normal values, we need an efficient\n// way of representing unknown, ordinary, and exceptional values.\ntype Value<T> =\n  | []           // unknown\n  | [T]          // known value\n  | [void, any]; // known exception\n\nfunction valueIs(a: Value<any>, b: Value<any>) {\n  const len = a.length;\n  return (\n    // Unknown values are not equal to each other.\n    len > 0 &&\n    // Both values must be ordinary (or both exceptional) to be equal.\n    len === b.length &&\n    // The underlying value or exception must be the same.\n    a[len - 1] === b[len - 1]\n  );\n}\n\nfunction valueGet<T>(value: Value<T>): T {\n  switch (value.length) {\n    case 0: throw new Error(\"unknown value\");\n    case 1: return value[0];\n    case 2: throw value[1];\n  }\n}\n\nfunction valueCopy<T>(value: Value<T>): Value<T> {\n  return value.slice(0) as Value<T>;\n}\n\nexport type AnyEntry = Entry<any, any>;\n\nexport class Entry<TArgs extends any[], TValue> {\n  public static count = 0;\n\n  public subscribe: OptimisticWrapOptions<TArgs>[\"subscribe\"];\n  public unsubscribe: Unsubscribable[\"unsubscribe\"];\n\n  public readonly parents = new Set<AnyEntry>();\n  public readonly childValues = new Map<AnyEntry, Value<any>>();\n\n  // When this Entry has children that are dirty, this property becomes\n  // a Set containing other Entry objects, borrowed from emptySetPool.\n  // When the set becomes empty, it gets recycled back to emptySetPool.\n  public dirtyChildren: Set<AnyEntry> | null = null;\n\n  public dirty = true;\n  public recomputing = false;\n  public readonly value: Value<TValue> = [];\n\n  constructor(\n    public readonly fn: (...args: TArgs) => TValue,\n  ) {\n    ++Entry.count;\n  }\n\n  public peek(): TValue | undefined {\n    if (this.value.length === 1 && !mightBeDirty(this)) {\n      rememberParent(this);\n      return this.value[0];\n    }\n  }\n\n  // This is the most important method of the Entry API, because it\n  // determines whether the cached this.value can be returned immediately,\n  // or must be recomputed. The overall performance of the caching system\n  // depends on the truth of the following observations: (1) this.dirty is\n  // usually false, (2) this.dirtyChildren is usually null/empty, and thus\n  // (3) valueGet(this.value) is usually returned without recomputation.\n  public recompute(args: TArgs): TValue {\n    assert(! this.recomputing, \"already recomputing\");\n    rememberParent(this);\n    return mightBeDirty(this)\n      ? reallyRecompute(this, args)\n      : valueGet(this.value);\n  }\n\n  public setDirty() {\n    if (this.dirty) return;\n    this.dirty = true;\n    this.value.length = 0;\n    reportDirty(this);\n    // We can go ahead and unsubscribe here, since any further dirty\n    // notifications we receive will be redundant, and unsubscribing may\n    // free up some resources, e.g. file watchers.\n    maybeUnsubscribe(this);\n  }\n\n  public dispose() {\n    this.setDirty();\n\n    // Sever any dependency relationships with our own children, so those\n    // children don't retain this parent Entry in their child.parents sets,\n    // thereby preventing it from being fully garbage collected.\n    forgetChildren(this);\n\n    // Because this entry has been kicked out of the cache (in index.js),\n    // we've lost the ability to find out if/when this entry becomes dirty,\n    // whether that happens through a subscription, because of a direct call\n    // to entry.setDirty(), or because one of its children becomes dirty.\n    // Because of this loss of future information, we have to assume the\n    // worst (that this entry might have become dirty very soon), so we must\n    // immediately mark this entry's parents as dirty. Normally we could\n    // just call entry.setDirty() rather than calling parent.setDirty() for\n    // each parent, but that would leave this entry in parent.childValues\n    // and parent.dirtyChildren, which would prevent the child from being\n    // truly forgotten.\n    eachParent(this, (parent, child) => {\n      parent.setDirty();\n      forgetChild(parent, this);\n    });\n  }\n\n  public forget() {\n    // The code that creates Entry objects in index.ts will replace this method\n    // with one that actually removes the Entry from the cache, which will also\n    // trigger the entry.dispose method.\n    this.dispose();\n  }\n\n  private deps: Set<Dep<any>> | null = null;\n\n  public dependOn(dep: Dep<any>) {\n    dep.add(this);\n    if (! this.deps) {\n      this.deps = emptySetPool.pop() || new Set<Set<AnyEntry>>();\n    }\n    this.deps.add(dep);\n  }\n\n  public forgetDeps() {\n    if (this.deps) {\n      toArray(this.deps).forEach(dep => dep.delete(this));\n      this.deps.clear();\n      emptySetPool.push(this.deps);\n      this.deps = null;\n    }\n  }\n}\n\nfunction rememberParent(child: AnyEntry) {\n  const parent = parentEntrySlot.getValue();\n  if (parent) {\n    child.parents.add(parent);\n\n    if (! parent.childValues.has(child)) {\n      parent.childValues.set(child, []);\n    }\n\n    if (mightBeDirty(child)) {\n      reportDirtyChild(parent, child);\n    } else {\n      reportCleanChild(parent, child);\n    }\n\n    return parent;\n  }\n}\n\nfunction reallyRecompute(entry: AnyEntry, args: any[]) {\n  forgetChildren(entry);\n\n  // Set entry as the parent entry while calling recomputeNewValue(entry).\n  parentEntrySlot.withValue(entry, recomputeNewValue, [entry, args]);\n\n  if (maybeSubscribe(entry, args)) {\n    // If we successfully recomputed entry.value and did not fail to\n    // (re)subscribe, then this Entry is no longer explicitly dirty.\n    setClean(entry);\n  }\n\n  return valueGet(entry.value);\n}\n\nfunction recomputeNewValue(entry: AnyEntry, args: any[]) {\n  entry.recomputing = true;\n  // Set entry.value as unknown.\n  entry.value.length = 0;\n  try {\n    // If entry.fn succeeds, entry.value will become a normal Value.\n    entry.value[0] = entry.fn.apply(null, args);\n  } catch (e) {\n    // If entry.fn throws, entry.value will become exceptional.\n    entry.value[1] = e;\n  }\n  // Either way, this line is always reached.\n  entry.recomputing = false;\n}\n\nfunction mightBeDirty(entry: AnyEntry) {\n  return entry.dirty || !!(entry.dirtyChildren && entry.dirtyChildren.size);\n}\n\nfunction setClean(entry: AnyEntry) {\n  entry.dirty = false;\n\n  if (mightBeDirty(entry)) {\n    // This Entry may still have dirty children, in which case we can't\n    // let our parents know we're clean just yet.\n    return;\n  }\n\n  reportClean(entry);\n}\n\nfunction reportDirty(child: AnyEntry) {\n  eachParent(child, reportDirtyChild);\n}\n\nfunction reportClean(child: AnyEntry) {\n  eachParent(child, reportCleanChild);\n}\n\nfunction eachParent(\n  child: AnyEntry,\n  callback: (parent: AnyEntry, child: AnyEntry) => any,\n) {\n  const parentCount = child.parents.size;\n  if (parentCount) {\n    const parents = toArray(child.parents);\n    for (let i = 0; i < parentCount; ++i) {\n      callback(parents[i], child);\n    }\n  }\n}\n\n// Let a parent Entry know that one of its children may be dirty.\nfunction reportDirtyChild(parent: AnyEntry, child: AnyEntry) {\n  // Must have called rememberParent(child) before calling\n  // reportDirtyChild(parent, child).\n  assert(parent.childValues.has(child));\n  assert(mightBeDirty(child));\n  const parentWasClean = !mightBeDirty(parent);\n\n  if (! parent.dirtyChildren) {\n    parent.dirtyChildren = emptySetPool.pop() || new Set;\n\n  } else if (parent.dirtyChildren.has(child)) {\n    // If we already know this child is dirty, then we must have already\n    // informed our own parents that we are dirty, so we can terminate\n    // the recursion early.\n    return;\n  }\n\n  parent.dirtyChildren.add(child);\n\n  // If parent was clean before, it just became (possibly) dirty (according to\n  // mightBeDirty), since we just added child to parent.dirtyChildren.\n  if (parentWasClean) {\n    reportDirty(parent);\n  }\n}\n\n// Let a parent Entry know that one of its children is no longer dirty.\nfunction reportCleanChild(parent: AnyEntry, child: AnyEntry) {\n  // Must have called rememberChild(child) before calling\n  // reportCleanChild(parent, child).\n  assert(parent.childValues.has(child));\n  assert(! mightBeDirty(child));\n\n  const childValue = parent.childValues.get(child)!;\n  if (childValue.length === 0) {\n    parent.childValues.set(child, valueCopy(child.value));\n  } else if (! valueIs(childValue, child.value)) {\n    parent.setDirty();\n  }\n\n  removeDirtyChild(parent, child);\n\n  if (mightBeDirty(parent)) {\n    return;\n  }\n\n  reportClean(parent);\n}\n\nfunction removeDirtyChild(parent: AnyEntry, child: AnyEntry) {\n  const dc = parent.dirtyChildren;\n  if (dc) {\n    dc.delete(child);\n    if (dc.size === 0) {\n      if (emptySetPool.length < POOL_TARGET_SIZE) {\n        emptySetPool.push(dc);\n      }\n      parent.dirtyChildren = null;\n    }\n  }\n}\n\n// Removes all children from this entry and returns an array of the\n// removed children.\nfunction forgetChildren(parent: AnyEntry) {\n  if (parent.childValues.size > 0) {\n    parent.childValues.forEach((_value, child) => {\n      forgetChild(parent, child);\n    });\n  }\n\n  // Remove this parent Entry from any sets to which it was added by the\n  // addToSet method.\n  parent.forgetDeps();\n\n  // After we forget all our children, this.dirtyChildren must be empty\n  // and therefore must have been reset to null.\n  assert(parent.dirtyChildren === null);\n}\n\nfunction forgetChild(parent: AnyEntry, child: AnyEntry) {\n  child.parents.delete(parent);\n  parent.childValues.delete(child);\n  removeDirtyChild(parent, child);\n}\n\nfunction maybeSubscribe(entry: AnyEntry, args: any[]) {\n  if (typeof entry.subscribe === \"function\") {\n    try {\n      maybeUnsubscribe(entry); // Prevent double subscriptions.\n      entry.unsubscribe = entry.subscribe.apply(null, args);\n    } catch (e) {\n      // If this Entry has a subscribe function and it threw an exception\n      // (or an unsubscribe function it previously returned now throws),\n      // return false to indicate that we were not able to subscribe (or\n      // unsubscribe), and this Entry should remain dirty.\n      entry.setDirty();\n      return false;\n    }\n  }\n\n  // Returning true indicates either that there was no entry.subscribe\n  // function or that it succeeded.\n  return true;\n}\n", "import { AnyEntry } from \"./entry\";\nimport { OptimisticWrapOptions } from \"./index\";\nimport { parentEntrySlot } from \"./context\";\nimport { hasOwnProperty, Unsubscribable, maybeUnsubscribe, toArray } from \"./helpers\";\n\ntype EntryMethodName = keyof typeof EntryMethods;\nconst EntryMethods = {\n  setDirty: true, // Mark parent Entry as needing to be recomputed (default)\n  dispose: true,  // Detach parent Entry from parents and children, but leave in LRU cache\n  forget: true,   // Fully remove parent Entry from LRU cache and computation graph\n};\n\nexport type OptimisticDependencyFunction<TKey> =\n  ((key: TKey) => void) & {\n    dirty: (key: TKey, entryMethodName?: EntryMethodName) => void;\n  };\n\nexport type Dep<TKey> = Set<AnyEntry> & {\n  subscribe: OptimisticWrapOptions<[TKey]>[\"subscribe\"];\n} & Unsubscribable;\n\nexport function dep<TKey>(options?: {\n  subscribe: Dep<TKey>[\"subscribe\"];\n}) {\n  const depsByKey = new Map<TKey, Dep<TKey>>();\n  const subscribe = options && options.subscribe;\n\n  function depend(key: TKey) {\n    const parent = parentEntrySlot.getValue();\n    if (parent) {\n      let dep = depsByKey.get(key);\n      if (!dep) {\n        depsByKey.set(key, dep = new Set as Dep<TKey>);\n      }\n      parent.dependOn(dep);\n      if (typeof subscribe === \"function\") {\n        maybeUnsubscribe(dep);\n        dep.unsubscribe = subscribe(key);\n      }\n    }\n  }\n\n  depend.dirty = function dirty(\n    key: TKey,\n    entryMethodName?: EntryMethodName,\n  ) {\n    const dep = depsByKey.get(key);\n    if (dep) {\n      const m: EntryMethodName = (\n        entryMethodName &&\n        hasOwnProperty.call(EntryMethods, entryMethodName)\n      ) ? entryMethodName : \"setDirty\";\n      // We have to use toArray(dep).forEach instead of dep.forEach, because\n      // modifying a Set while iterating over it can cause elements in the Set\n      // to be removed from the Set before they've been iterated over.\n      toArray(dep).forEach(entry => entry[m]());\n      depsByKey.delete(key);\n      maybeUnsubscribe(dep);\n    }\n  };\n\n  return depend as OptimisticDependencyFunction<TKey>;\n}\n", "import { Trie } from \"@wry/trie\";\n\nimport { Cache } from \"./cache\";\nimport { Entry, AnyEntry } from \"./entry\";\nimport { parentEntrySlot } from \"./context\";\n\n// These helper functions are important for making optimism work with\n// asynchronous code. In order to register parent-child dependencies,\n// optimism needs to know about any currently active parent computations.\n// In ordinary synchronous code, the parent context is implicit in the\n// execution stack, but asynchronous code requires some extra guidance in\n// order to propagate context from one async task segment to the next.\nexport {\n  bindContext,\n  noContext,\n  setTimeout,\n  asyncFromGen,\n} from \"./context\";\n\n// A lighter-weight dependency, similar to OptimisticWrapperFunction, except\n// with only one argument, no makeCacheKey, no wrapped function to recompute,\n// and no result value. Useful for representing dependency leaves in the graph\n// of computation. Subscriptions are supported.\nexport { dep, OptimisticDependencyFunction } from \"./dep\";\n\nfunction makeDefaultMakeCacheKeyFunction<\n  TKeyArgs extends any[],\n  TCacheKey = any,\n>(): (...args: TKeyArgs) => TCacheKey {\n  const keyTrie = new Trie<TCacheKey>(typeof WeakMap === \"function\");\n  return function () {\n    return keyTrie.lookupArray(arguments);\n  };\n}\n\n// The defaultMakeCacheKey function is remarkably powerful, because it gives\n// a unique object for any shallow-identical list of arguments. If you need\n// to implement a custom makeCacheKey function, you may find it helpful to\n// delegate the final work to defaultMakeCacheKey, which is why we export it\n// here. However, you may want to avoid defaultMakeCacheKey if your runtime\n// does not support WeakMap, or you have the ability to return a string key.\n// In those cases, just write your own custom makeCacheKey functions.\nexport const defaultMakeCacheKey = makeDefaultMakeCacheKeyFunction();\n\n// If you're paranoid about memory leaks, or you want to avoid using WeakMap\n// under the hood, but you still need the behavior of defaultMakeCacheKey,\n// import this constructor to create your own tries.\nexport { Trie as KeyTrie }\n\nexport type OptimisticWrapperFunction<\n  TArgs extends any[],\n  TResult,\n  TKeyArgs extends any[] = TArgs,\n  TCacheKey = any,\n> = ((...args: TArgs) => TResult) & {\n  // Get the current number of Entry objects in the LRU cache.\n  readonly size: number;\n\n  // \"Dirty\" any cached Entry stored for the given arguments, marking that Entry\n  // and its ancestors as potentially needing to be recomputed. The .dirty(...)\n  // method of an optimistic function takes the same parameter types as the\n  // original function by default, unless a keyArgs function is configured, and\n  // then it matters that .dirty takes TKeyArgs instead of TArgs.\n  dirty: (...args: TKeyArgs) => void;\n  // A version of .dirty that accepts a key returned by .getKey.\n  dirtyKey: (key: TCacheKey) => void;\n\n  // Examine the current value without recomputing it.\n  peek: (...args: TKeyArgs) => TResult | undefined;\n  // A version of .peek that accepts a key returned by .getKey.\n  peekKey: (key: TCacheKey) => TResult | undefined;\n\n  // Completely remove the entry from the cache, dirtying any parent entries.\n  forget: (...args: TKeyArgs) => boolean;\n  // A version of .forget that accepts a key returned by .getKey.\n  forgetKey: (key: TCacheKey) => boolean;\n\n  // In order to use the -Key version of the above functions, you need a key\n  // rather than the arguments used to compute the key. These two functions take\n  // TArgs or TKeyArgs and return the corresponding TCacheKey. If no keyArgs\n  // function has been configured, TArgs will be the same as TKeyArgs, and thus\n  // getKey and makeCacheKey will be synonymous.\n  getKey: (...args: TArgs) => TCacheKey;\n\n  // This property is equivalent to the makeCacheKey function provided in the\n  // OptimisticWrapOptions, or (if no options.makeCacheKey function is provided)\n  // a default implementation of makeCacheKey.\n  makeCacheKey: (...args: TKeyArgs) => TCacheKey;\n};\n\nexport type OptimisticWrapOptions<\n  TArgs extends any[],\n  TKeyArgs extends any[] = TArgs,\n  TCacheKey = any,\n> = {\n  // The maximum number of cache entries that should be retained before the\n  // cache begins evicting the oldest ones.\n  max?: number;\n  // Transform the raw arguments to some other type of array, which will then\n  // be passed to makeCacheKey.\n  keyArgs?: (...args: TArgs) => TKeyArgs;\n  // The makeCacheKey function takes the same arguments that were passed to\n  // the wrapper function and returns a single value that can be used as a key\n  // in a Map to identify the cached result.\n  makeCacheKey?: (...args: TKeyArgs) => TCacheKey;\n  // If provided, the subscribe function should either return an unsubscribe\n  // function or return nothing.\n  subscribe?: (...args: TArgs) => void | (() => any);\n};\n\nconst caches = new Set<Cache<any, AnyEntry>>();\n\nexport function wrap<\n  TArgs extends any[],\n  TResult,\n  TKeyArgs extends any[] = TArgs,\n  TCacheKey = any,\n>(\n  originalFunction: (...args: TArgs) => TResult,\n  options: OptimisticWrapOptions<TArgs, TKeyArgs> = Object.create(null),\n) {\n  const cache = new Cache<TCacheKey, Entry<TArgs, TResult>>(\n    options.max || Math.pow(2, 16),\n    entry => entry.dispose(),\n  );\n\n  const keyArgs = options.keyArgs;\n  const makeCacheKey = options.makeCacheKey ||\n    makeDefaultMakeCacheKeyFunction<TKeyArgs, TCacheKey>();\n\n  const optimistic = function (): TResult {\n    const key = makeCacheKey.apply(\n      null,\n      keyArgs ? keyArgs.apply(null, arguments as any) : arguments as any\n    );\n\n    if (key === void 0) {\n      return originalFunction.apply(null, arguments as any);\n    }\n\n    let entry = cache.get(key)!;\n    if (!entry) {\n      cache.set(key, entry = new Entry(originalFunction));\n      entry.subscribe = options.subscribe;\n      // Give the Entry the ability to trigger cache.delete(key), even though\n      // the Entry itself does not know about key or cache.\n      entry.forget = () => cache.delete(key);\n    }\n\n    const value = entry.recompute(\n      Array.prototype.slice.call(arguments) as TArgs,\n    );\n\n    // Move this entry to the front of the least-recently used queue,\n    // since we just finished computing its value.\n    cache.set(key, entry);\n\n    caches.add(cache);\n\n    // Clean up any excess entries in the cache, but only if there is no\n    // active parent entry, meaning we're not in the middle of a larger\n    // computation that might be flummoxed by the cleaning.\n    if (! parentEntrySlot.hasValue()) {\n      caches.forEach(cache => cache.clean());\n      caches.clear();\n    }\n\n    return value;\n  } as OptimisticWrapperFunction<TArgs, TResult, TKeyArgs, TCacheKey>;\n\n  Object.defineProperty(optimistic, \"size\", {\n    get() {\n      return cache[\"map\"].size;\n    },\n    configurable: false,\n    enumerable: false,\n  });\n\n  function dirtyKey(key: TCacheKey) {\n    const entry = cache.get(key);\n    if (entry) {\n      entry.setDirty();\n    }\n  }\n  optimistic.dirtyKey = dirtyKey;\n  optimistic.dirty = function dirty() {\n    dirtyKey(makeCacheKey.apply(null, arguments as any));\n  };\n\n  function peekKey(key: TCacheKey) {\n    const entry = cache.get(key);\n    if (entry) {\n      return entry.peek();\n    }\n  }\n  optimistic.peekKey = peekKey;\n  optimistic.peek = function peek() {\n    return peekKey(makeCacheKey.apply(null, arguments as any));\n  };\n\n  function forgetKey(key: TCacheKey) {\n    return cache.delete(key);\n  }\n  optimistic.forgetKey = forgetKey;\n  optimistic.forget = function forget() {\n    return forgetKey(makeCacheKey.apply(null, arguments as any));\n  };\n\n  optimistic.makeCacheKey = makeCacheKey;\n  optimistic.getKey = keyArgs ? function getKey() {\n    return makeCacheKey.apply(null, keyArgs.apply(null, arguments as any));\n  } : makeCacheKey as (...args: any[]) => TCacheKey;\n\n  return Object.freeze(optimistic);\n}\n", "import { DocumentNode } from 'graphql';\nimport { wrap } from 'optimism';\n\nimport {\n  StoreObject,\n  Reference,\n  getFragmentQueryDocument,\n} from '../../utilities';\nimport { DataProxy } from './types/DataProxy';\nimport { Cache } from './types/Cache';\n\nexport type Transaction<T> = (c: ApolloCache<T>) => void;\n\nexport abstract class ApolloCache<TSerialized> implements DataProxy {\n  // required to implement\n  // core API\n  public abstract read<TData = any, TVariables = any>(\n    query: Cache.ReadOptions<TVariables, TData>,\n  ): TData | null;\n  public abstract write<TData = any, TVariables = any>(\n    write: Cache.WriteOptions<TData, TVariables>,\n  ): Reference | undefined;\n  public abstract diff<T>(query: Cache.DiffOptions): Cache.DiffResult<T>;\n  public abstract watch<TData = any, TVariables = any>(\n    watch: Cache.WatchOptions<TData, TVariables>,\n  ): () => void;\n\n  // Empty the cache and restart all current watches (unless\n  // options.discardWatches is true).\n  public abstract reset(options?: Cache.ResetOptions): Promise<void>;\n\n  // Remove whole objects from the cache by passing just options.id, or\n  // specific fields by passing options.field and/or options.args. If no\n  // options.args are provided, all fields matching options.field (even\n  // those with arguments) will be removed. Returns true iff any data was\n  // removed from the cache.\n  public abstract evict(options: Cache.EvictOptions): boolean;\n\n  // initializer / offline / ssr API\n  /**\n   * Replaces existing state in the cache (if any) with the values expressed by\n   * `serializedState`.\n   *\n   * Called when hydrating a cache (server side rendering, or offline storage),\n   * and also (potentially) during hot reloads.\n   */\n  public abstract restore(\n    serializedState: TSerialized,\n  ): ApolloCache<TSerialized>;\n\n  /**\n   * Exposes the cache's complete state, in a serializable format for later restoration.\n   */\n  public abstract extract(optimistic?: boolean): TSerialized;\n\n  // Optimistic API\n\n  public abstract removeOptimistic(id: string): void;\n\n  // Transactional API\n\n  // The batch method is intended to replace/subsume both performTransaction\n  // and recordOptimisticTransaction, but performTransaction came first, so we\n  // provide a default batch implementation that's just another way of calling\n  // performTransaction. Subclasses of ApolloCache (such as InMemoryCache) can\n  // override the batch method to do more interesting things with its options.\n  public batch<U>(options: Cache.BatchOptions<this, U>): U {\n    const optimisticId =\n      typeof options.optimistic === \"string\" ? options.optimistic :\n      options.optimistic === false ? null : void 0;\n    let updateResult: U;\n    this.performTransaction(\n      () => updateResult = options.update(this),\n      optimisticId,\n    );\n    return updateResult!;\n  }\n\n  public abstract performTransaction(\n    transaction: Transaction<TSerialized>,\n    // Although subclasses may implement recordOptimisticTransaction\n    // however they choose, the default implementation simply calls\n    // performTransaction with a string as the second argument, allowing\n    // performTransaction to handle both optimistic and non-optimistic\n    // (broadcast-batching) transactions. Passing null for optimisticId is\n    // also allowed, and indicates that performTransaction should apply\n    // the transaction non-optimistically (ignoring optimistic data).\n    optimisticId?: string | null,\n  ): void;\n\n  public recordOptimisticTransaction(\n    transaction: Transaction<TSerialized>,\n    optimisticId: string,\n  ) {\n    this.performTransaction(transaction, optimisticId);\n  }\n\n  // Optional API\n\n  public transformDocument(document: DocumentNode): DocumentNode {\n    return document;\n  }\n\n  public identify(object: StoreObject | Reference): string | undefined {\n    return;\n  }\n\n  public gc(): string[] {\n    return [];\n  }\n\n  public modify(options: Cache.ModifyOptions): boolean {\n    return false;\n  }\n\n  // Experimental API\n\n  public transformForLink(document: DocumentNode): DocumentNode {\n    return document;\n  }\n\n  // DataProxy API\n  /**\n   *\n   * @param options\n   * @param optimistic\n   */\n  public readQuery<QueryType, TVariables = any>(\n    options: Cache.ReadQueryOptions<QueryType, TVariables>,\n    optimistic = !!options.optimistic,\n  ): QueryType | null {\n    return this.read({\n      ...options,\n      rootId: options.id || 'ROOT_QUERY',\n      optimistic,\n    });\n  }\n\n  // Make sure we compute the same (===) fragment query document every\n  // time we receive the same fragment in readFragment.\n  private getFragmentDoc = wrap(getFragmentQueryDocument);\n\n  public readFragment<FragmentType, TVariables = any>(\n    options: Cache.ReadFragmentOptions<FragmentType, TVariables>,\n    optimistic = !!options.optimistic,\n  ): FragmentType | null {\n    return this.read({\n      ...options,\n      query: this.getFragmentDoc(options.fragment, options.fragmentName),\n      rootId: options.id,\n      optimistic,\n    });\n  }\n\n  public writeQuery<TData = any, TVariables = any>({\n    id,\n    data,\n    ...options\n  }: Cache.WriteQueryOptions<TData, TVariables>): Reference | undefined {\n    return this.write(Object.assign(options, {\n      dataId: id || 'ROOT_QUERY',\n      result: data,\n    }));\n  }\n\n  public writeFragment<TData = any, TVariables = any>({\n    id,\n    data,\n    fragment,\n    fragmentName,\n    ...options\n  }: Cache.WriteFragmentOptions<TData, TVariables>): Reference | undefined {\n    return this.write(Object.assign(options, {\n      query: this.getFragmentDoc(fragment, fragmentName),\n      dataId: id,\n      result: data,\n    }));\n  }\n\n  public updateQuery<TData = any, TVariables = any>(\n    options: Cache.UpdateQueryOptions<TData, TVariables>,\n    update: (data: TData | null) => TData | null | void,\n  ): TData | null {\n    return this.batch({\n      update(cache) {\n        const value = cache.readQuery<TData, TVariables>(options);\n        const data = update(value);\n        if (data === void 0 || data === null) return value;\n        cache.writeQuery<TData, TVariables>({ ...options, data });\n        return data;\n      },\n    });\n  }\n\n  public updateFragment<TData = any, TVariables = any>(\n    options: Cache.UpdateFragmentOptions<TData, TVariables>,\n    update: (data: TData | null) => TData | null | void,\n  ): TData | null {\n    return this.batch({\n      update(cache) {\n        const value = cache.readFragment<TData, TVariables>(options);\n        const data = update(value);\n        if (data === void 0 || data === null) return value;\n        cache.writeFragment<TData, TVariables>({ ...options, data });\n        return data;\n      },\n    });\n  }\n}\n", "import { DataProxy } from './DataProxy';\nimport { Modifier, Modifiers } from './common';\nimport { ApolloCache } from '../cache';\n\nexport namespace Cache {\n  export type WatchCallback<TData = any> = (\n    diff: Cache.DiffResult<TData>,\n    lastDiff?: Cache.DiffResult<TData>,\n  ) => void;\n\n  export interface ReadOptions<TVariables = any, TData = any>\n    extends DataProxy.Query<TVariables, TData> {\n    rootId?: string;\n    previousResult?: any;\n    optimistic: boolean;\n    returnPartialData?: boolean;\n    canonizeResults?: boolean;\n  }\n\n  export interface WriteOptions<TResult = any, TVariables = any>\n    extends Omit<DataProxy.Query<TVariables, TResult>, \"id\">,\n            Omit<DataProxy.WriteOptions<TResult>, \"data\">\n  {\n    dataId?: string;\n    result: TResult;\n  }\n\n  export interface DiffOptions<\n    TData = any,\n    TVariables = any,\n  > extends ReadOptions<TVariables, TData> {\n    // The DiffOptions interface is currently just an alias for\n    // ReadOptions, though DiffOptions used to be responsible for\n    // declaring the returnPartialData option.\n  }\n\n  export interface WatchOptions<\n    TData = any,\n    TVariables = any,\n  > extends ReadOptions<TVariables, TData> {\n    watcher?: object;\n    immediate?: boolean;\n    callback: WatchCallback<TData>;\n    lastDiff?: DiffResult<TData>;\n  }\n\n  export interface EvictOptions {\n    id?: string;\n    fieldName?: string;\n    args?: Record<string, any>;\n    broadcast?: boolean;\n  }\n\n  // Although you can call cache.reset() without options, its behavior can be\n  // configured by passing a Cache.ResetOptions object.\n  export interface ResetOptions {\n    discardWatches?: boolean;\n  }\n\n  export interface ModifyOptions {\n    id?: string;\n    fields: Modifiers | Modifier<any>;\n    optimistic?: boolean;\n    broadcast?: boolean;\n  }\n\n  export interface BatchOptions<\n    TCache extends ApolloCache<any>,\n    TUpdateResult = void,\n  > {\n    // Same as the first parameter of performTransaction, except the cache\n    // argument will have the subclass type rather than ApolloCache.\n    update(cache: TCache): TUpdateResult;\n\n    // Passing a string for this option creates a new optimistic layer, with the\n    // given string as its layer.id, just like passing a string for the\n    // optimisticId parameter of performTransaction. Passing true is the same as\n    // passing undefined to performTransaction (running the batch operation\n    // against the current top layer of the cache), and passing false is the\n    // same as passing null (running the operation against root/non-optimistic\n    // cache data).\n    optimistic?: string | boolean;\n\n    // If you specify the ID of an optimistic layer using this option, that\n    // layer will be removed as part of the batch transaction, triggering at\n    // most one broadcast for both the transaction and the removal of the layer.\n    // Note: this option is needed because calling cache.removeOptimistic during\n    // the transaction function may not be not safe, since any modifications to\n    // cache layers may be discarded after the transaction finishes.\n    removeOptimistic?: string;\n\n    // If you want to find out which watched queries were invalidated during\n    // this batch operation, pass this optional callback function. Returning\n    // false from the callback will prevent broadcasting this result.\n    onWatchUpdated?: (\n      this: TCache,\n      watch: Cache.WatchOptions,\n      diff: Cache.DiffResult<any>,\n      lastDiff: Cache.DiffResult<any> | undefined,\n    ) => any;\n  }\n\n  export import DiffResult = DataProxy.DiffResult;\n  export import ReadQueryOptions = DataProxy.ReadQueryOptions;\n  export import ReadFragmentOptions = DataProxy.ReadFragmentOptions;\n  export import WriteQueryOptions = DataProxy.WriteQueryOptions;\n  export import WriteFragmentOptions = DataProxy.WriteFragmentOptions;\n  export import UpdateQueryOptions = DataProxy.UpdateQueryOptions;\n  export import UpdateFragmentOptions = DataProxy.UpdateFragmentOptions;\n  export import Fragment = DataProxy.Fragment;\n}\n", "import { DocumentNode, FieldNode } from 'graphql';\n\nimport {\n  Reference,\n  StoreObject,\n  StoreValue,\n  isReference,\n} from '../../../utilities';\n\nimport { StorageType } from '../../inmemory/policies';\n\n// The Readonly<T> type only really works for object types, since it marks\n// all of the object's properties as readonly, but there are many cases when\n// a generic type parameter like TExisting might be a string or some other\n// primitive type, in which case we need to avoid wrapping it with Readonly.\n// SafeReadonly<string> collapses to just string, which makes string\n// assignable to SafeReadonly<any>, whereas string is not assignable to\n// Readonly<any>, somewhat surprisingly.\nexport type SafeReadonly<T> = T extends object ? Readonly<T> : T;\n\nexport type MissingTree = string | {\n  readonly [key: string]: MissingTree;\n};\n\nexport class MissingFieldError {\n  constructor(\n    public readonly message: string,\n    public readonly path: MissingTree | Array<string | number>,\n    public readonly query: DocumentNode,\n    public readonly variables?: Record<string, any>,\n  ) {}\n}\n\nexport interface FieldSpecifier {\n  typename?: string;\n  fieldName: string;\n  field?: FieldNode;\n  args?: Record<string, any>;\n  variables?: Record<string, any>;\n}\n\nexport interface ReadFieldOptions extends FieldSpecifier {\n  from?: StoreObject | Reference;\n}\n\nexport interface ReadFieldFunction {\n  <V = StoreValue>(options: ReadFieldOptions): SafeReadonly<V> | undefined;\n  <V = StoreValue>(\n    fieldName: string,\n    from?: StoreObject | Reference,\n  ): SafeReadonly<V> | undefined;\n}\n\nexport type ToReferenceFunction = (\n  objOrIdOrRef: StoreObject | string | Reference,\n  mergeIntoStore?: boolean,\n) => Reference | undefined;\n\nexport type CanReadFunction = (value: StoreValue) => boolean;\n\nexport type Modifier<T> = (value: T, details: {\n  DELETE: any;\n  INVALIDATE: any;\n  fieldName: string;\n  storeFieldName: string;\n  readField: ReadFieldFunction;\n  canRead: CanReadFunction;\n  isReference: typeof isReference;\n  toReference: ToReferenceFunction;\n  storage: StorageType;\n}) => T;\n\nexport type Modifiers = {\n  [fieldName: string]: Modifier<any>;\n};\n", "import { SelectionSetNode } from 'graphql';\n\nimport {\n  NormalizedCache,\n  InMemoryCacheConfig,\n} from './types';\n\nimport { KeyFieldsContext } from './policies';\n\nimport {\n  Reference,\n  isReference,\n  StoreValue,\n  StoreObject,\n  isField,\n  DeepMerger,\n  resultKeyNameFromField,\n  shouldInclude,\n  isNonNullObject,\n  compact,\n} from '../../utilities';\n\nexport const {\n  hasOwnProperty: hasOwn,\n} = Object.prototype;\n\nexport function defaultDataIdFromObject(\n  { __typename, id, _id }: Readonly<StoreObject>,\n  context?: KeyFieldsContext,\n): string | undefined {\n  if (typeof __typename === \"string\") {\n    if (context) {\n      context.keyObject =\n         id !== void 0 ? {  id } :\n        _id !== void 0 ? { _id } :\n        void 0;\n    }\n    // If there is no object.id, fall back to object._id.\n    if (id === void 0) id = _id;\n    if (id !== void 0) {\n      return `${__typename}:${(\n        typeof id === \"number\" ||\n        typeof id === \"string\"\n      ) ? id : JSON.stringify(id)}`;\n    }\n  }\n}\n\nconst defaultConfig = {\n  dataIdFromObject: defaultDataIdFromObject,\n  addTypename: true,\n  resultCaching: true,\n  // Thanks to the shouldCanonizeResults helper, this should be the only line\n  // you have to change to reenable canonization by default in the future.\n  canonizeResults: false,\n};\n\nexport function normalizeConfig(config: InMemoryCacheConfig) {\n  return compact(defaultConfig, config);\n}\n\nexport function shouldCanonizeResults(\n  config: Pick<InMemoryCacheConfig, \"canonizeResults\">,\n): boolean {\n  const value = config.canonizeResults;\n  return value === void 0 ? defaultConfig.canonizeResults : value;\n}\n\nexport function getTypenameFromStoreObject(\n  store: NormalizedCache,\n  objectOrReference: StoreObject | Reference,\n): string | undefined {\n  return isReference(objectOrReference)\n    ? store.get(objectOrReference.__ref, \"__typename\") as string\n    : objectOrReference && objectOrReference.__typename;\n}\n\nexport const TypeOrFieldNameRegExp = /^[_a-z][_0-9a-z]*/i;\n\nexport function fieldNameFromStoreName(storeFieldName: string): string {\n  const match = storeFieldName.match(TypeOrFieldNameRegExp);\n  return match ? match[0] : storeFieldName;\n}\n\nexport function selectionSetMatchesResult(\n  selectionSet: SelectionSetNode,\n  result: Record<string, any>,\n  variables?: Record<string, any>,\n): boolean {\n  if (isNonNullObject(result)) {\n    return isArray(result)\n      ? result.every(item => selectionSetMatchesResult(selectionSet, item, variables))\n      : selectionSet.selections.every(field => {\n        if (isField(field) && shouldInclude(field, variables)) {\n          const key = resultKeyNameFromField(field);\n          return hasOwn.call(result, key) &&\n            (!field.selectionSet ||\n             selectionSetMatchesResult(field.selectionSet, result[key], variables));\n        }\n        // If the selection has been skipped with @skip(true) or\n        // @include(false), it should not count against the matching. If\n        // the selection is not a field, it must be a fragment (inline or\n        // named). We will determine if selectionSetMatchesResult for that\n        // fragment when we get to it, so for now we return true.\n        return true;\n      });\n  }\n  return false;\n}\n\nexport function storeValueIsStoreObject(\n  value: StoreValue,\n): value is StoreObject {\n  return isNonNullObject(value) &&\n    !isReference(value) &&\n    !isArray(value);\n}\n\nexport function makeProcessedFieldsMerger() {\n  return new DeepMerger;\n}\n\nexport const isArray = (a: any): a is any[] | readonly any[] => Array.isArray(a)\n", "import { invariant } from '../../utilities/globals';\nimport { dep, OptimisticDependencyFunction } from 'optimism';\nimport { equal } from '@wry/equality';\nimport { Trie } from '@wry/trie';\n\nimport {\n  isReference,\n  StoreValue,\n  StoreObject,\n  Reference,\n  makeReference,\n  DeepMerger,\n  maybeDeepFreeze,\n  canUseWeakMap,\n  isNonNullObject,\n} from '../../utilities';\nimport { NormalizedCache, NormalizedCacheObject } from './types';\nimport { hasOwn, fieldNameFromStoreName } from './helpers';\nimport { Policies, StorageType } from './policies';\nimport { Cache } from '../core/types/Cache';\nimport {\n  SafeReadonly,\n  Modifier,\n  Modifiers,\n  ReadFieldOptions,\n  ToReferenceFunction,\n  CanReadFunction,\n} from '../core/types/common';\n\nconst DELETE: any = Object.create(null);\nconst delModifier: Modifier<any> = () => DELETE;\nconst INVALIDATE: any = Object.create(null);\n\nexport abstract class EntityStore implements NormalizedCache {\n  protected data: NormalizedCacheObject = Object.create(null);\n\n  constructor(\n    public readonly policies: Policies,\n    public readonly group: CacheGroup,\n  ) {}\n\n  public abstract addLayer(\n    layerId: string,\n    replay: (layer: EntityStore) => any,\n  ): Layer;\n\n  public abstract removeLayer(layerId: string): EntityStore;\n\n  // Although the EntityStore class is abstract, it contains concrete\n  // implementations of the various NormalizedCache interface methods that\n  // are inherited by the Root and Layer subclasses.\n\n  public toObject(): NormalizedCacheObject {\n    return { ...this.data };\n  }\n\n  public has(dataId: string): boolean {\n    return this.lookup(dataId, true) !== void 0;\n  }\n\n  public get(dataId: string, fieldName: string): StoreValue {\n    this.group.depend(dataId, fieldName);\n    if (hasOwn.call(this.data, dataId)) {\n      const storeObject = this.data[dataId];\n      if (storeObject && hasOwn.call(storeObject, fieldName)) {\n        return storeObject[fieldName];\n      }\n    }\n    if (fieldName === \"__typename\" &&\n        hasOwn.call(this.policies.rootTypenamesById, dataId)) {\n      return this.policies.rootTypenamesById[dataId];\n    }\n    if (this instanceof Layer) {\n      return this.parent.get(dataId, fieldName);\n    }\n  }\n\n  protected lookup(dataId: string, dependOnExistence?: boolean): StoreObject | undefined {\n    // The has method (above) calls lookup with dependOnExistence = true, so\n    // that it can later be invalidated when we add or remove a StoreObject for\n    // this dataId. Any consumer who cares about the contents of the StoreObject\n    // should not rely on this dependency, since the contents could change\n    // without the object being added or removed.\n    if (dependOnExistence) this.group.depend(dataId, \"__exists\");\n\n    if (hasOwn.call(this.data, dataId)) {\n      return this.data[dataId];\n    }\n\n    if (this instanceof Layer) {\n      return this.parent.lookup(dataId, dependOnExistence);\n    }\n\n    if (this.policies.rootTypenamesById[dataId]) {\n      return Object.create(null);\n    }\n  }\n\n  public merge(\n    older: string | StoreObject,\n    newer: StoreObject | string,\n  ): void {\n    let dataId: string | undefined;\n\n    // Convert unexpected references to ID strings.\n    if (isReference(older)) older = older.__ref;\n    if (isReference(newer)) newer = newer.__ref;\n\n    const existing: StoreObject | undefined =\n      typeof older === \"string\"\n        ? this.lookup(dataId = older)\n        : older;\n\n    const incoming: StoreObject | undefined =\n      typeof newer === \"string\"\n        ? this.lookup(dataId = newer)\n        : newer;\n\n    // If newer was a string ID, but that ID was not defined in this store,\n    // then there are no fields to be merged, so we're done.\n    if (!incoming) return;\n\n    invariant(\n      typeof dataId === \"string\",\n      \"store.merge expects a string ID\",\n    );\n\n    const merged: StoreObject =\n      new DeepMerger(storeObjectReconciler).merge(existing, incoming);\n\n    // Even if merged === existing, existing may have come from a lower\n    // layer, so we always need to set this.data[dataId] on this level.\n    this.data[dataId] = merged;\n\n    if (merged !== existing) {\n      delete this.refs[dataId];\n      if (this.group.caching) {\n        const fieldsToDirty: Record<string, 1> = Object.create(null);\n\n        // If we added a new StoreObject where there was previously none, dirty\n        // anything that depended on the existence of this dataId, such as the\n        // EntityStore#has method.\n        if (!existing) fieldsToDirty.__exists = 1;\n\n        // Now invalidate dependents who called getFieldValue for any fields\n        // that are changing as a result of this merge.\n        Object.keys(incoming).forEach(storeFieldName => {\n          if (!existing || existing[storeFieldName] !== merged[storeFieldName]) {\n            // Always dirty the full storeFieldName, which may include\n            // serialized arguments following the fieldName prefix.\n            fieldsToDirty[storeFieldName] = 1;\n\n            // Also dirty fieldNameFromStoreName(storeFieldName) if it's\n            // different from storeFieldName and this field does not have\n            // keyArgs configured, because that means the cache can't make\n            // any assumptions about how field values with the same field\n            // name but different arguments might be interrelated, so it\n            // must err on the side of invalidating all field values that\n            // share the same short fieldName, regardless of arguments.\n            const fieldName = fieldNameFromStoreName(storeFieldName);\n            if (fieldName !== storeFieldName &&\n                !this.policies.hasKeyArgs(merged.__typename, fieldName)) {\n              fieldsToDirty[fieldName] = 1;\n            }\n\n            // If merged[storeFieldName] has become undefined, and this is the\n            // Root layer, actually delete the property from the merged object,\n            // which is guaranteed to have been created fresh in this method.\n            if (merged[storeFieldName] === void 0 && !(this instanceof Layer)) {\n              delete merged[storeFieldName];\n            }\n          }\n        });\n\n        if (fieldsToDirty.__typename &&\n            !(existing && existing.__typename) &&\n            // Since we return default root __typename strings\n            // automatically from store.get, we don't need to dirty the\n            // ROOT_QUERY.__typename field if merged.__typename is equal\n            // to the default string (usually \"Query\").\n            this.policies.rootTypenamesById[dataId] === merged.__typename) {\n          delete fieldsToDirty.__typename;\n        }\n\n        Object.keys(fieldsToDirty).forEach(\n          fieldName => this.group.dirty(dataId as string, fieldName));\n      }\n    }\n  }\n\n  public modify(\n    dataId: string,\n    fields: Modifier<any> | Modifiers,\n  ): boolean {\n    const storeObject = this.lookup(dataId);\n\n    if (storeObject) {\n      const changedFields: Record<string, any> = Object.create(null);\n      let needToMerge = false;\n      let allDeleted = true;\n\n      const sharedDetails = {\n        DELETE,\n        INVALIDATE,\n        isReference,\n        toReference: this.toReference,\n        canRead: this.canRead,\n        readField: <V = StoreValue>(\n          fieldNameOrOptions: string | ReadFieldOptions,\n          from?: StoreObject | Reference,\n        ) => this.policies.readField<V>(\n          typeof fieldNameOrOptions === \"string\" ? {\n            fieldName: fieldNameOrOptions,\n            from: from || makeReference(dataId),\n          } : fieldNameOrOptions,\n          { store: this },\n        ),\n      };\n\n      Object.keys(storeObject).forEach(storeFieldName => {\n        const fieldName = fieldNameFromStoreName(storeFieldName);\n        let fieldValue = storeObject[storeFieldName];\n        if (fieldValue === void 0) return;\n        const modify: Modifier<StoreValue> = typeof fields === \"function\"\n          ? fields\n          : fields[storeFieldName] || fields[fieldName];\n        if (modify) {\n          let newValue = modify === delModifier ? DELETE :\n            modify(maybeDeepFreeze(fieldValue), {\n              ...sharedDetails,\n              fieldName,\n              storeFieldName,\n              storage: this.getStorage(dataId, storeFieldName),\n            });\n          if (newValue === INVALIDATE) {\n            this.group.dirty(dataId, storeFieldName);\n          } else {\n            if (newValue === DELETE) newValue = void 0;\n            if (newValue !== fieldValue) {\n              changedFields[storeFieldName] = newValue;\n              needToMerge = true;\n              fieldValue = newValue;\n            }\n          }\n        }\n        if (fieldValue !== void 0) {\n          allDeleted = false;\n        }\n      });\n\n      if (needToMerge) {\n        this.merge(dataId, changedFields);\n\n        if (allDeleted) {\n          if (this instanceof Layer) {\n            this.data[dataId] = void 0;\n          } else {\n            delete this.data[dataId];\n          }\n          this.group.dirty(dataId, \"__exists\");\n        }\n\n        return true;\n      }\n    }\n\n    return false;\n  }\n\n  // If called with only one argument, removes the entire entity\n  // identified by dataId. If called with a fieldName as well, removes all\n  // fields of that entity whose names match fieldName according to the\n  // fieldNameFromStoreName helper function. If called with a fieldName\n  // and variables, removes all fields of that entity whose names match fieldName\n  // and whose arguments when cached exactly match the variables passed.\n  public delete(\n    dataId: string,\n    fieldName?: string,\n    args?: Record<string, any>,\n  ) {\n    const storeObject = this.lookup(dataId);\n    if (storeObject) {\n      const typename = this.getFieldValue<string>(storeObject, \"__typename\");\n      const storeFieldName = fieldName && args\n        ? this.policies.getStoreFieldName({ typename, fieldName, args })\n        : fieldName;\n      return this.modify(dataId, storeFieldName ? {\n        [storeFieldName]: delModifier,\n      } : delModifier);\n    }\n    return false;\n  }\n\n  public evict(\n    options: Cache.EvictOptions,\n    limit: EntityStore,\n  ): boolean {\n    let evicted = false;\n    if (options.id) {\n      if (hasOwn.call(this.data, options.id)) {\n        evicted = this.delete(options.id, options.fieldName, options.args);\n      }\n      if (this instanceof Layer && this !== limit) {\n        evicted = this.parent.evict(options, limit) || evicted;\n      }\n      // Always invalidate the field to trigger rereading of watched\n      // queries, even if no cache data was modified by the eviction,\n      // because queries may depend on computed fields with custom read\n      // functions, whose values are not stored in the EntityStore.\n      if (options.fieldName || evicted) {\n        this.group.dirty(options.id, options.fieldName || \"__exists\");\n      }\n    }\n    return evicted;\n  }\n\n  public clear(): void {\n    this.replace(null);\n  }\n\n  public extract(): NormalizedCacheObject {\n    const obj = this.toObject();\n    const extraRootIds: string[] = [];\n    this.getRootIdSet().forEach(id => {\n      if (!hasOwn.call(this.policies.rootTypenamesById, id)) {\n        extraRootIds.push(id);\n      }\n    });\n    if (extraRootIds.length) {\n      obj.__META = { extraRootIds: extraRootIds.sort() };\n    }\n    return obj;\n  }\n\n  public replace(newData: NormalizedCacheObject | null): void {\n    Object.keys(this.data).forEach(dataId => {\n      if (!(newData && hasOwn.call(newData, dataId))) {\n        this.delete(dataId);\n      }\n    });\n    if (newData) {\n      const { __META, ...rest } = newData;\n      Object.keys(rest).forEach(dataId => {\n        this.merge(dataId, rest[dataId] as StoreObject);\n      });\n      if (__META) {\n        __META.extraRootIds.forEach(this.retain, this);\n      }\n    }\n  }\n\n  public abstract getStorage(\n    idOrObj: string | StoreObject,\n    ...storeFieldNames: (string | number)[]\n  ): StorageType;\n\n  // Maps root entity IDs to the number of times they have been retained, minus\n  // the number of times they have been released. Retained entities keep other\n  // entities they reference (even indirectly) from being garbage collected.\n  private rootIds: {\n    [rootId: string]: number;\n  } = Object.create(null);\n\n  public retain(rootId: string): number {\n    return this.rootIds[rootId] = (this.rootIds[rootId] || 0) + 1;\n  }\n\n  public release(rootId: string): number {\n    if (this.rootIds[rootId] > 0) {\n      const count = --this.rootIds[rootId];\n      if (!count) delete this.rootIds[rootId];\n      return count;\n    }\n    return 0;\n  }\n\n  // Return a Set<string> of all the ID strings that have been retained by\n  // this layer/root *and* any layers/roots beneath it.\n  public getRootIdSet(ids = new Set<string>()) {\n    Object.keys(this.rootIds).forEach(ids.add, ids);\n    if (this instanceof Layer) {\n      this.parent.getRootIdSet(ids);\n    } else {\n      // Official singleton IDs like ROOT_QUERY and ROOT_MUTATION are\n      // always considered roots for garbage collection, regardless of\n      // their retainment counts in this.rootIds.\n      Object.keys(this.policies.rootTypenamesById).forEach(ids.add, ids);\n    }\n    return ids;\n  }\n\n  // The goal of garbage collection is to remove IDs from the Root layer of the\n  // store that are no longer reachable starting from any IDs that have been\n  // explicitly retained (see retain and release, above). Returns an array of\n  // dataId strings that were removed from the store.\n  public gc() {\n    const ids = this.getRootIdSet();\n    const snapshot = this.toObject();\n    ids.forEach(id => {\n      if (hasOwn.call(snapshot, id)) {\n        // Because we are iterating over an ECMAScript Set, the IDs we add here\n        // will be visited in later iterations of the forEach loop only if they\n        // were not previously contained by the Set.\n        Object.keys(this.findChildRefIds(id)).forEach(ids.add, ids);\n        // By removing IDs from the snapshot object here, we protect them from\n        // getting removed from the root store layer below.\n        delete snapshot[id];\n      }\n    });\n    const idsToRemove = Object.keys(snapshot);\n    if (idsToRemove.length) {\n      let root: EntityStore = this;\n      while (root instanceof Layer) root = root.parent;\n      idsToRemove.forEach(id => root.delete(id));\n    }\n    return idsToRemove;\n  }\n\n  // Lazily tracks { __ref: <dataId> } strings contained by this.data[dataId].\n  private refs: {\n    [dataId: string]: Record<string, true>;\n  } = Object.create(null);\n\n  public findChildRefIds(dataId: string): Record<string, true> {\n    if (!hasOwn.call(this.refs, dataId)) {\n      const found = this.refs[dataId] = Object.create(null);\n      const root = this.data[dataId];\n      if (!root) return found;\n\n      const workSet = new Set<Record<string | number, any>>([root]);\n      // Within the store, only arrays and objects can contain child entity\n      // references, so we can prune the traversal using this predicate:\n      workSet.forEach(obj => {\n        if (isReference(obj)) {\n          found[obj.__ref] = true;\n          // In rare cases, a { __ref } Reference object may have other fields.\n          // This often indicates a mismerging of References with StoreObjects,\n          // but garbage collection should not be fooled by a stray __ref\n          // property in a StoreObject (ignoring all the other fields just\n          // because the StoreObject looks like a Reference). To avoid this\n          // premature termination of findChildRefIds recursion, we fall through\n          // to the code below, which will handle any other properties of obj.\n        }\n        if (isNonNullObject(obj)) {\n          Object.keys(obj).forEach(key => {\n            const child = obj[key];\n            // No need to add primitive values to the workSet, since they cannot\n            // contain reference objects.\n            if (isNonNullObject(child)) {\n              workSet.add(child);\n            }\n          });\n        }\n      });\n    }\n    return this.refs[dataId];\n  }\n\n  // Used to compute cache keys specific to this.group.\n  public makeCacheKey(...args: any[]): object;\n  public makeCacheKey() {\n    return this.group.keyMaker.lookupArray(arguments);\n  }\n\n  // Bound function that can be passed around to provide easy access to fields\n  // of Reference objects as well as ordinary objects.\n  public getFieldValue = <T = StoreValue>(\n    objectOrReference: StoreObject | Reference | undefined,\n    storeFieldName: string,\n  ) => maybeDeepFreeze(\n    isReference(objectOrReference)\n      ? this.get(objectOrReference.__ref, storeFieldName)\n      : objectOrReference && objectOrReference[storeFieldName]\n  ) as SafeReadonly<T>;\n\n  // Returns true for non-normalized StoreObjects and non-dangling\n  // References, indicating that readField(name, objOrRef) has a chance of\n  // working. Useful for filtering out dangling references from lists.\n  public canRead: CanReadFunction = objOrRef => {\n    return isReference(objOrRef)\n      ? this.has(objOrRef.__ref)\n      : typeof objOrRef === \"object\";\n  };\n\n  // Bound function that converts an id or an object with a __typename and\n  // primary key fields to a Reference object. If called with a Reference object,\n  // that same Reference object is returned. Pass true for mergeIntoStore to persist\n  // an object into the store.\n  public toReference: ToReferenceFunction = (\n    objOrIdOrRef,\n    mergeIntoStore,\n  ) => {\n    if (typeof objOrIdOrRef === \"string\") {\n      return makeReference(objOrIdOrRef);\n    }\n\n    if (isReference(objOrIdOrRef)) {\n      return objOrIdOrRef;\n    }\n\n    const [id] = this.policies.identify(objOrIdOrRef);\n\n    if (id) {\n      const ref = makeReference(id);\n      if (mergeIntoStore) {\n        this.merge(id, objOrIdOrRef);\n      }\n      return ref;\n    }\n  };\n}\n\nexport type FieldValueGetter = EntityStore[\"getFieldValue\"];\n\n// A single CacheGroup represents a set of one or more EntityStore objects,\n// typically the Root store in a CacheGroup by itself, and all active Layer\n// stores in a group together. A single EntityStore object belongs to only\n// one CacheGroup, store.group. The CacheGroup is responsible for tracking\n// dependencies, so store.group is helpful for generating unique keys for\n// cached results that need to be invalidated when/if those dependencies\n// change. If we used the EntityStore objects themselves as cache keys (that\n// is, store rather than store.group), the cache would become unnecessarily\n// fragmented by all the different Layer objects. Instead, the CacheGroup\n// approach allows all optimistic Layer objects in the same linked list to\n// belong to one CacheGroup, with the non-optimistic Root object belonging\n// to another CacheGroup, allowing resultCaching dependencies to be tracked\n// separately for optimistic and non-optimistic entity data.\nclass CacheGroup {\n  private d: OptimisticDependencyFunction<string> | null = null;\n\n  // Used by the EntityStore#makeCacheKey method to compute cache keys\n  // specific to this CacheGroup.\n  public keyMaker: Trie<object>;\n\n  constructor(\n    public readonly caching: boolean,\n    private parent: CacheGroup | null = null,\n  ) {\n    this.resetCaching();\n  }\n\n  public resetCaching() {\n    this.d = this.caching ? dep<string>() : null;\n    this.keyMaker = new Trie(canUseWeakMap);\n  }\n\n  public depend(dataId: string, storeFieldName: string) {\n    if (this.d) {\n      this.d(makeDepKey(dataId, storeFieldName));\n      const fieldName = fieldNameFromStoreName(storeFieldName);\n      if (fieldName !== storeFieldName) {\n        // Fields with arguments that contribute extra identifying\n        // information to the fieldName (thus forming the storeFieldName)\n        // depend not only on the full storeFieldName but also on the\n        // short fieldName, so the field can be invalidated using either\n        // level of specificity.\n        this.d(makeDepKey(dataId, fieldName));\n      }\n      if (this.parent) {\n        this.parent.depend(dataId, storeFieldName);\n      }\n    }\n  }\n\n  public dirty(dataId: string, storeFieldName: string) {\n    if (this.d) {\n      this.d.dirty(\n        makeDepKey(dataId, storeFieldName),\n        // When storeFieldName === \"__exists\", that means the entity identified\n        // by dataId has either disappeared from the cache or was newly added,\n        // so the result caching system would do well to \"forget everything it\n        // knows\" about that object. To achieve that kind of invalidation, we\n        // not only dirty the associated result cache entry, but also remove it\n        // completely from the dependency graph. For the optimism implementation\n        // details, see https://github.com/benjamn/optimism/pull/195.\n        storeFieldName === \"__exists\" ? \"forget\" : \"setDirty\",\n      );\n    }\n  }\n}\n\nfunction makeDepKey(dataId: string, storeFieldName: string) {\n  // Since field names cannot have '#' characters in them, this method\n  // of joining the field name and the ID should be unambiguous, and much\n  // cheaper than JSON.stringify([dataId, fieldName]).\n  return storeFieldName + '#' + dataId;\n}\n\nexport function maybeDependOnExistenceOfEntity(\n  store: NormalizedCache,\n  entityId: string,\n) {\n  if (supportsResultCaching(store)) {\n    // We use this pseudo-field __exists elsewhere in the EntityStore code to\n    // represent changes in the existence of the entity object identified by\n    // entityId. This dependency gets reliably dirtied whenever an object with\n    // this ID is deleted (or newly created) within this group, so any result\n    // cache entries (for example, StoreReader#executeSelectionSet results) that\n    // depend on __exists for this entityId will get dirtied as well, leading to\n    // the eventual recomputation (instead of reuse) of those result objects the\n    // next time someone reads them from the cache.\n    store.group.depend(entityId, \"__exists\");\n  }\n}\n\nexport namespace EntityStore {\n  // Refer to this class as EntityStore.Root outside this namespace.\n  export class Root extends EntityStore {\n    constructor({\n      policies,\n      resultCaching = true,\n      seed,\n    }: {\n      policies: Policies;\n      resultCaching?: boolean;\n      seed?: NormalizedCacheObject;\n    }) {\n      super(policies, new CacheGroup(resultCaching));\n      if (seed) this.replace(seed);\n    }\n\n    public readonly stump = new Stump(this);\n\n    public addLayer(\n      layerId: string,\n      replay: (layer: EntityStore) => any,\n    ): Layer {\n      // Adding an optimistic Layer on top of the Root actually adds the Layer\n      // on top of the Stump, so the Stump always comes between the Root and\n      // any Layer objects that we've added.\n      return this.stump.addLayer(layerId, replay);\n    }\n\n    public removeLayer(): Root {\n      // Never remove the root layer.\n      return this;\n    }\n\n    public readonly storageTrie = new Trie<StorageType>(canUseWeakMap);\n    public getStorage(): StorageType {\n      return this.storageTrie.lookupArray(arguments);\n    }\n  }\n}\n\n// Not exported, since all Layer instances are created by the addLayer method\n// of the EntityStore.Root class.\nclass Layer extends EntityStore {\n  constructor(\n    public readonly id: string,\n    public readonly parent: EntityStore,\n    public readonly replay: (layer: EntityStore) => any,\n    public readonly group: CacheGroup,\n  ) {\n    super(parent.policies, group);\n    replay(this);\n  }\n\n  public addLayer(\n    layerId: string,\n    replay: (layer: EntityStore) => any,\n  ): Layer {\n    return new Layer(layerId, this, replay, this.group);\n  }\n\n  public removeLayer(layerId: string): EntityStore {\n    // Remove all instances of the given id, not just the first one.\n    const parent = this.parent.removeLayer(layerId);\n\n    if (layerId === this.id) {\n      if (this.group.caching) {\n        // Dirty every ID we're removing. Technically we might be able to avoid\n        // dirtying fields that have values in higher layers, but we don't have\n        // easy access to higher layers here, and we're about to recreate those\n        // layers anyway (see parent.addLayer below).\n        Object.keys(this.data).forEach(dataId => {\n          const ownStoreObject = this.data[dataId];\n          const parentStoreObject = parent[\"lookup\"](dataId);\n          if (!parentStoreObject) {\n            // The StoreObject identified by dataId was defined in this layer\n            // but will be undefined in the parent layer, so we can delete the\n            // whole entity using this.delete(dataId). Since we're about to\n            // throw this layer away, the only goal of this deletion is to dirty\n            // the removed fields.\n            this.delete(dataId);\n          } else if (!ownStoreObject) {\n            // This layer had an entry for dataId but it was undefined, which\n            // means the entity was deleted in this layer, and it's about to\n            // become undeleted when we remove this layer, so we need to dirty\n            // all fields that are about to be reexposed.\n            this.group.dirty(dataId, \"__exists\");\n            Object.keys(parentStoreObject).forEach(storeFieldName => {\n              this.group.dirty(dataId, storeFieldName);\n            });\n          } else if (ownStoreObject !== parentStoreObject) {\n            // If ownStoreObject is not exactly the same as parentStoreObject,\n            // dirty any fields whose values will change as a result of this\n            // removal.\n            Object.keys(ownStoreObject).forEach(storeFieldName => {\n              if (!equal(ownStoreObject[storeFieldName],\n                         parentStoreObject[storeFieldName])) {\n                this.group.dirty(dataId, storeFieldName);\n              }\n            });\n          }\n        });\n      }\n\n      return parent;\n    }\n\n    // No changes are necessary if the parent chain remains identical.\n    if (parent === this.parent) return this;\n\n    // Recreate this layer on top of the new parent.\n    return parent.addLayer(this.id, this.replay);\n  }\n\n  public toObject(): NormalizedCacheObject {\n    return {\n      ...this.parent.toObject(),\n      ...this.data,\n    };\n  }\n\n  public findChildRefIds(dataId: string): Record<string, true> {\n    const fromParent = this.parent.findChildRefIds(dataId);\n    return hasOwn.call(this.data, dataId) ? {\n      ...fromParent,\n      ...super.findChildRefIds(dataId),\n    } : fromParent;\n  }\n\n  public getStorage(): StorageType {\n    let p: EntityStore = this.parent;\n    while ((p as Layer).parent) p = (p as Layer).parent;\n    return p.getStorage.apply(p, arguments);\n  }\n}\n\n// Represents a Layer permanently installed just above the Root, which allows\n// reading optimistically (and registering optimistic dependencies) even when\n// no optimistic layers are currently active. The stump.group CacheGroup object\n// is shared by any/all Layer objects added on top of the Stump.\nclass Stump extends Layer {\n  constructor(root: EntityStore.Root) {\n    super(\n      \"EntityStore.Stump\",\n      root,\n      () => {},\n      new CacheGroup(root.group.caching, root.group),\n    );\n  }\n\n  public removeLayer() {\n    // Never remove the Stump layer.\n    return this;\n  }\n\n  public merge() {\n    // We never want to write any data into the Stump, so we forward any merge\n    // calls to the Root instead. Another option here would be to throw an\n    // exception, but the toReference(object, true) function can sometimes\n    // trigger Stump writes (which used to be Root writes, before the Stump\n    // concept was introduced).\n    return this.parent.merge.apply(this.parent, arguments);\n  }\n}\n\nfunction storeObjectReconciler(\n  existingObject: StoreObject,\n  incomingObject: StoreObject,\n  property: string,\n): StoreValue {\n  const existingValue = existingObject[property];\n  const incomingValue = incomingObject[property];\n  // Wherever there is a key collision, prefer the incoming value, unless\n  // it is deeply equal to the existing value. It's worth checking deep\n  // equality here (even though blindly returning incoming would be\n  // logically correct) because preserving the referential identity of\n  // existing data can prevent needless rereading and rerendering.\n  return equal(existingValue, incomingValue) ? existingValue : incomingValue;\n}\n\nexport function supportsResultCaching(store: any): store is EntityStore {\n  // When result caching is disabled, store.depend will be null.\n  return !!(store instanceof EntityStore && store.group.caching);\n}\n", "import \"../../utilities/globals\";\n\nimport { Trie } from \"@wry/trie\";\nimport {\n  canUseWeakMap,\n  canUseWeakSet,\n  isNonNullObject as isObjectOrArray,\n} from \"../../utilities\";\nimport { isArray } from \"./helpers\";\n\nfunction shallowCopy<T>(value: T): T {\n  if (isObjectOrArray(value)) {\n    return isArray(value)\n      ? value.slice(0) as any as T\n      : { __proto__: Object.getPrototypeOf(value), ...value };\n  }\n  return value;\n}\n\n// When programmers talk about the \"canonical form\" of an object, they\n// usually have the following meaning in mind, which I've copied from\n// https://en.wiktionary.org/wiki/canonical_form:\n//\n// 1. A standard or normal presentation of a mathematical entity [or\n//    object]. A canonical form is an element of a set of representatives\n//    of equivalence classes of forms such that there is a function or\n//    procedure which projects every element of each equivalence class\n//    onto that one element, the canonical form of that equivalence\n//    class. The canonical form is expected to be simpler than the rest of\n//    the forms in some way.\n//\n// That's a long-winded way of saying any two objects that have the same\n// canonical form may be considered equivalent, even if they are !==,\n// which usually means the objects are structurally equivalent (deeply\n// equal), but don't necessarily use the same memory.\n//\n// Like a literary or musical canon, this ObjectCanon class represents a\n// collection of unique canonical items (JavaScript objects), with the\n// important property that canon.admit(a) === canon.admit(b) if a and b\n// are deeply equal to each other. In terms of the definition above, the\n// canon.admit method is the \"function or procedure which projects every\"\n// object \"onto that one element, the canonical form.\"\n//\n// In the worst case, the canonicalization process may involve looking at\n// every property in the provided object tree, so it takes the same order\n// of time as deep equality checking. Fortunately, already-canonicalized\n// objects are returned immediately from canon.admit, so the presence of\n// canonical subtrees tends to speed up canonicalization.\n//\n// Since consumers of canonical objects can check for deep equality in\n// constant time, canonicalizing cache results can massively improve the\n// performance of application code that skips re-rendering unchanged\n// results, such as \"pure\" UI components in a framework like React.\n//\n// Of course, since canonical objects may be shared widely between\n// unrelated consumers, it's important to think of them as immutable, even\n// though they are not actually frozen with Object.freeze in production,\n// due to the extra performance overhead that comes with frozen objects.\n//\n// Custom scalar objects whose internal class name is neither Array nor\n// Object can be included safely in the admitted tree, but they will not\n// be replaced with a canonical version (to put it another way, they are\n// assumed to be canonical already).\n//\n// If we ignore custom objects, no detection of cycles or repeated object\n// references is currently required by the StoreReader class, since\n// GraphQL result objects are JSON-serializable trees (and thus contain\n// neither cycles nor repeated subtrees), so we can avoid the complexity\n// of keeping track of objects we've already seen during the recursion of\n// the admit method.\n//\n// In the future, we may consider adding additional cases to the switch\n// statement to handle other common object types, such as \"[object Date]\"\n// objects, as needed.\nexport class ObjectCanon {\n  // Set of all canonical objects this ObjectCanon has admitted, allowing\n  // canon.admit to return previously-canonicalized objects immediately.\n  private known = new (canUseWeakSet ? WeakSet : Set)<object>();\n\n  // Efficient storage/lookup structure for canonical objects.\n  private pool = new Trie<{\n    array?: any[];\n    object?: Record<string, any>;\n    keys?: SortedKeysInfo;\n  }>(canUseWeakMap);\n\n  public isKnown(value: any): boolean {\n    return isObjectOrArray(value) && this.known.has(value);\n  }\n\n  // Make the ObjectCanon assume this value has already been\n  // canonicalized.\n  private passes = new WeakMap<object, object>();\n  public pass<T>(value: T): T;\n  public pass(value: any) {\n    if (isObjectOrArray(value)) {\n      const copy = shallowCopy(value);\n      this.passes.set(copy, value);\n      return copy;\n    }\n    return value;\n  }\n\n  // Returns the canonical version of value.\n  public admit<T>(value: T): T;\n  public admit(value: any) {\n    if (isObjectOrArray(value)) {\n      const original = this.passes.get(value);\n      if (original) return original;\n\n      const proto = Object.getPrototypeOf(value);\n      switch (proto) {\n        case Array.prototype: {\n          if (this.known.has(value)) return value;\n          const array: any[] = (value as any[]).map(this.admit, this);\n          // Arrays are looked up in the Trie using their recursively\n          // canonicalized elements, and the known version of the array is\n          // preserved as node.array.\n          const node = this.pool.lookupArray(array);\n          if (!node.array) {\n            this.known.add(node.array = array);\n            // Since canonical arrays may be shared widely between\n            // unrelated consumers, it's important to regard them as\n            // immutable, even if they are not frozen in production.\n            if (__DEV__) {\n              Object.freeze(array);\n            }\n          }\n          return node.array;\n        }\n\n        case null:\n        case Object.prototype: {\n          if (this.known.has(value)) return value;\n          const proto = Object.getPrototypeOf(value);\n          const array = [proto];\n          const keys = this.sortedKeys(value);\n          array.push(keys.json);\n          const firstValueIndex = array.length;\n          keys.sorted.forEach(key => {\n            array.push(this.admit((value as any)[key]));\n          });\n          // Objects are looked up in the Trie by their prototype (which\n          // is *not* recursively canonicalized), followed by a JSON\n          // representation of their (sorted) keys, followed by the\n          // sequence of recursively canonicalized values corresponding to\n          // those keys. To keep the final results unambiguous with other\n          // sequences (such as arrays that just happen to contain [proto,\n          // keys.json, value1, value2, ...]), the known version of the\n          // object is stored as node.object.\n          const node = this.pool.lookupArray(array);\n          if (!node.object) {\n            const obj = node.object = Object.create(proto);\n            this.known.add(obj);\n            keys.sorted.forEach((key, i) => {\n              obj[key] = array[firstValueIndex + i];\n            });\n            // Since canonical objects may be shared widely between\n            // unrelated consumers, it's important to regard them as\n            // immutable, even if they are not frozen in production.\n            if (__DEV__) {\n              Object.freeze(obj);\n            }\n          }\n          return node.object;\n        }\n      }\n    }\n    return value;\n  }\n\n  // It's worthwhile to cache the sorting of arrays of strings, since the\n  // same initial unsorted arrays tend to be encountered many times.\n  // Fortunately, we can reuse the Trie machinery to look up the sorted\n  // arrays in linear time (which is faster than sorting large arrays).\n  private sortedKeys(obj: object) {\n    const keys = Object.keys(obj);\n    const node = this.pool.lookupArray(keys);\n    if (!node.keys) {\n      keys.sort();\n      const json = JSON.stringify(keys);\n      if (!(node.keys = this.keysByJSON.get(json))) {\n        this.keysByJSON.set(json, node.keys = { sorted: keys, json });\n      }\n    }\n    return node.keys;\n  }\n  // Arrays that contain the same elements in a different order can share\n  // the same SortedKeysInfo object, to save memory.\n  private keysByJSON = new Map<string, SortedKeysInfo>();\n\n  // This has to come last because it depends on keysByJSON.\n  public readonly empty = this.admit({});\n}\n\ntype SortedKeysInfo = {\n  sorted: string[];\n  json: string;\n};\n\n// Since the keys of canonical objects are always created in lexicographically\n// sorted order, we can use the ObjectCanon to implement a fast and stable\n// version of JSON.stringify, which automatically sorts object keys.\nexport const canonicalStringify = Object.assign(function (value: any): string {\n  if (isObjectOrArray(value)) {\n    if (stringifyCanon === void 0) {\n      resetCanonicalStringify();\n    }\n    const canonical = stringifyCanon.admit(value);\n    let json = stringifyCache.get(canonical);\n    if (json === void 0) {\n      stringifyCache.set(\n        canonical,\n        json = JSON.stringify(canonical),\n      );\n    }\n    return json;\n  }\n  return JSON.stringify(value);\n}, {\n  reset: resetCanonicalStringify,\n});\n\n// Can be reset by calling canonicalStringify.reset().\nlet stringifyCanon: ObjectCanon;\nlet stringifyCache: WeakMap<object, string>;\n\nfunction resetCanonicalStringify() {\n  stringifyCanon = new ObjectCanon;\n  stringifyCache = new (canUseWeakMap ? WeakMap : Map)();\n}\n", "import { invariant } from '../../utilities/globals';\n\nimport {\n  DocumentNode,\n  FieldNode,\n  SelectionSetNode,\n} from 'graphql';\nimport { wrap, OptimisticWrapperFunction } from 'optimism';\n\nimport {\n  isField,\n  resultKeyNameFromField,\n  Reference,\n  isReference,\n  makeReference,\n  StoreObject,\n  createFragmentMap,\n  FragmentMap,\n  shouldInclude,\n  addTypenameToDocument,\n  getDefaultValues,\n  getFragmentDefinitions,\n  getMainDefinition,\n  getQueryDefinition,\n  DeepMerger,\n  getFragmentFromSelection,\n  maybeDeepFreeze,\n  isNonNullObject,\n  canUseWeakMap,\n  compact,\n} from '../../utilities';\nimport { Cache } from '../core/types/Cache';\nimport {\n  DiffQueryAgainstStoreOptions,\n  NormalizedCache,\n  ReadMergeModifyContext,\n} from './types';\nimport { maybeDependOnExistenceOfEntity, supportsResultCaching } from './entityStore';\nimport { getTypenameFromStoreObject, isArray, shouldCanonizeResults } from './helpers';\nimport { Policies } from './policies';\nimport { InMemoryCache } from './inMemoryCache';\nimport { MissingFieldError, MissingTree } from '../core/types/common';\nimport { canonicalStringify, ObjectCanon } from './object-canon';\n\nexport type VariableMap = { [name: string]: any };\n\ninterface ReadContext extends ReadMergeModifyContext {\n  query: DocumentNode;\n  policies: Policies;\n  canonizeResults: boolean;\n  fragmentMap: FragmentMap;\n  // General-purpose deep-merge function for use during reads.\n  merge<T>(existing: T, incoming: T): T;\n};\n\nexport type ExecResult<R = any> = {\n  result: R;\n  missing?: MissingTree;\n};\n\ntype ExecSelectionSetOptions = {\n  selectionSet: SelectionSetNode;\n  objectOrReference: StoreObject | Reference;\n  enclosingRef: Reference;\n  context: ReadContext;\n};\n\ntype ExecSubSelectedArrayOptions = {\n  field: FieldNode;\n  array: readonly any[];\n  enclosingRef: Reference;\n  context: ReadContext;\n};\n\nexport interface StoreReaderConfig {\n  cache: InMemoryCache,\n  addTypename?: boolean;\n  resultCacheMaxSize?: number;\n  canonizeResults?: boolean;\n  canon?: ObjectCanon;\n}\n\n// Arguments type after keyArgs translation.\ntype ExecSelectionSetKeyArgs = [\n  SelectionSetNode,\n  StoreObject | Reference,\n  ReadMergeModifyContext,\n  boolean,\n];\n\nfunction execSelectionSetKeyArgs(\n  options: ExecSelectionSetOptions,\n): ExecSelectionSetKeyArgs {\n  return [\n    options.selectionSet,\n    options.objectOrReference,\n    options.context,\n    // We split out this property so we can pass different values\n    // independently without modifying options.context itself.\n    options.context.canonizeResults,\n  ];\n}\n\nexport class StoreReader {\n  // cached version of executeSelectionSet\n  private executeSelectionSet: OptimisticWrapperFunction<\n    [ExecSelectionSetOptions], // Actual arguments tuple type.\n    ExecResult, // Actual return type.\n    ExecSelectionSetKeyArgs\n  >;\n\n  // cached version of executeSubSelectedArray\n  private executeSubSelectedArray: OptimisticWrapperFunction<\n    [ExecSubSelectedArrayOptions],\n    ExecResult<any>,\n    [ExecSubSelectedArrayOptions]>;\n\n  private config: {\n    cache: InMemoryCache,\n    addTypename: boolean;\n    resultCacheMaxSize?: number;\n    canonizeResults: boolean;\n  };\n\n  private knownResults = new (\n    canUseWeakMap ? WeakMap : Map\n  )<Record<string, any>, SelectionSetNode>();\n\n  public canon: ObjectCanon;\n  public resetCanon() {\n    this.canon = new ObjectCanon;\n  }\n\n  constructor(config: StoreReaderConfig) {\n    this.config = compact(config, {\n      addTypename: config.addTypename !== false,\n      canonizeResults: shouldCanonizeResults(config),\n    });\n\n    this.canon = config.canon || new ObjectCanon;\n\n    this.executeSelectionSet = wrap(options => {\n      const { canonizeResults } = options.context;\n\n      const peekArgs = execSelectionSetKeyArgs(options);\n\n      // Negate this boolean option so we can find out if we've already read\n      // this result using the other boolean value.\n      peekArgs[3] = !canonizeResults;\n\n      const other = this.executeSelectionSet.peek(...peekArgs);\n\n      if (other) {\n        if (canonizeResults) {\n          return {\n            ...other,\n            // If we previously read this result without canonizing it, we can\n            // reuse that result simply by canonizing it now.\n            result: this.canon.admit(other.result),\n          };\n        }\n        // If we previously read this result with canonization enabled, we can\n        // return that canonized result as-is.\n        return other;\n      }\n\n      maybeDependOnExistenceOfEntity(\n        options.context.store,\n        options.enclosingRef.__ref,\n      );\n\n      // Finally, if we didn't find any useful previous results, run the real\n      // execSelectionSetImpl method with the given options.\n      return this.execSelectionSetImpl(options);\n\n    }, {\n      max: this.config.resultCacheMaxSize,\n      keyArgs: execSelectionSetKeyArgs,\n      // Note that the parameters of makeCacheKey are determined by the\n      // array returned by keyArgs.\n      makeCacheKey(selectionSet, parent, context, canonizeResults) {\n        if (supportsResultCaching(context.store)) {\n          return context.store.makeCacheKey(\n            selectionSet,\n            isReference(parent) ? parent.__ref : parent,\n            context.varString,\n            canonizeResults,\n          );\n        }\n      }\n    });\n\n    this.executeSubSelectedArray = wrap((options: ExecSubSelectedArrayOptions) => {\n      maybeDependOnExistenceOfEntity(\n        options.context.store,\n        options.enclosingRef.__ref,\n      );\n      return this.execSubSelectedArrayImpl(options);\n    }, {\n      max: this.config.resultCacheMaxSize,\n      makeCacheKey({ field, array, context }) {\n        if (supportsResultCaching(context.store)) {\n          return context.store.makeCacheKey(\n            field,\n            array,\n            context.varString,\n          );\n        }\n      }\n    });\n  }\n\n  /**\n   * Given a store and a query, return as much of the result as possible and\n   * identify if any data was missing from the store.\n   * @param  {DocumentNode} query A parsed GraphQL query document\n   * @param  {Store} store The Apollo Client store object\n   * @return {result: Object, complete: [boolean]}\n   */\n  public diffQueryAgainstStore<T>({\n    store,\n    query,\n    rootId = 'ROOT_QUERY',\n    variables,\n    returnPartialData = true,\n    canonizeResults = this.config.canonizeResults,\n  }: DiffQueryAgainstStoreOptions): Cache.DiffResult<T> {\n    const policies = this.config.cache.policies;\n\n    variables = {\n      ...getDefaultValues(getQueryDefinition(query)),\n      ...variables!,\n    };\n\n    const rootRef = makeReference(rootId);\n    const merger = new DeepMerger;\n    const execResult = this.executeSelectionSet({\n      selectionSet: getMainDefinition(query).selectionSet,\n      objectOrReference: rootRef,\n      enclosingRef: rootRef,\n      context: {\n        store,\n        query,\n        policies,\n        variables,\n        varString: canonicalStringify(variables),\n        canonizeResults,\n        fragmentMap: createFragmentMap(getFragmentDefinitions(query)),\n        merge(a, b) {\n          // We use the same DeepMerger instance throughout the read, so any\n          // merged objects created during this read can be updated later in the\n          // read using in-place/destructive property assignments. Once the read\n          // is finished, these objects will be frozen, but in the meantime it's\n          // good for performance and memory usage if we avoid allocating a new\n          // object for every merged property.\n          return merger.merge(a, b);\n        },\n      },\n    });\n\n    let missing: MissingFieldError[] | undefined;\n    if (execResult.missing) {\n      // For backwards compatibility we still report an array of\n      // MissingFieldError objects, even though there will only ever be at most\n      // one of them, now that all missing field error messages are grouped\n      // together in the execResult.missing tree.\n      missing = [new MissingFieldError(\n        firstMissing(execResult.missing)!,\n        execResult.missing,\n        query,\n        variables,\n      )];\n      if (!returnPartialData) {\n        throw missing[0];\n      }\n    }\n\n    return {\n      result: execResult.result,\n      complete: !missing,\n      missing,\n    };\n  }\n\n  public isFresh(\n    result: Record<string, any>,\n    parent: StoreObject | Reference,\n    selectionSet: SelectionSetNode,\n    context: ReadMergeModifyContext,\n  ): boolean {\n    if (supportsResultCaching(context.store) &&\n        this.knownResults.get(result) === selectionSet) {\n      const latest = this.executeSelectionSet.peek(\n        selectionSet,\n        parent,\n        context,\n        // If result is canonical, then it could only have been previously\n        // cached by the canonizing version of executeSelectionSet, so we can\n        // avoid checking both possibilities here.\n        this.canon.isKnown(result),\n      );\n      if (latest && result === latest.result) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  // Uncached version of executeSelectionSet.\n  private execSelectionSetImpl({\n    selectionSet,\n    objectOrReference,\n    enclosingRef,\n    context,\n  }: ExecSelectionSetOptions): ExecResult {\n    if (isReference(objectOrReference) &&\n        !context.policies.rootTypenamesById[objectOrReference.__ref] &&\n        !context.store.has(objectOrReference.__ref)) {\n      return {\n        result: this.canon.empty,\n        missing: `Dangling reference to missing ${objectOrReference.__ref} object`,\n      };\n    }\n\n    const { variables, policies, store } = context;\n    const typename = store.getFieldValue<string>(objectOrReference, \"__typename\");\n\n    let result: any = {};\n    let missing: MissingTree | undefined;\n\n    if (this.config.addTypename &&\n        typeof typename === \"string\" &&\n        !policies.rootIdsByTypename[typename]) {\n      // Ensure we always include a default value for the __typename\n      // field, if we have one, and this.config.addTypename is true. Note\n      // that this field can be overridden by other merged objects.\n      result = { __typename: typename };\n    }\n\n    function handleMissing<T>(result: ExecResult<T>, resultName: string): T {\n      if (result.missing) {\n        missing = context.merge(missing, { [resultName]: result.missing });\n      }\n      return result.result;\n    }\n\n    const workSet = new Set(selectionSet.selections);\n\n    workSet.forEach(selection => {\n      // Omit fields with directives @skip(if: <truthy value>) or\n      // @include(if: <falsy value>).\n      if (!shouldInclude(selection, variables)) return;\n\n      if (isField(selection)) {\n        let fieldValue = policies.readField({\n          fieldName: selection.name.value,\n          field: selection,\n          variables: context.variables,\n          from: objectOrReference,\n        }, context);\n\n        const resultName = resultKeyNameFromField(selection);\n\n        if (fieldValue === void 0) {\n          if (!addTypenameToDocument.added(selection)) {\n            missing = context.merge(missing, {\n              [resultName]: `Can't find field '${\n                selection.name.value\n              }' on ${\n                isReference(objectOrReference)\n                  ? objectOrReference.__ref + \" object\"\n                  : \"object \" + JSON.stringify(objectOrReference, null, 2)\n              }`\n            });\n          }\n\n        } else if (isArray(fieldValue)) {\n          fieldValue = handleMissing(this.executeSubSelectedArray({\n            field: selection,\n            array: fieldValue,\n            enclosingRef,\n            context,\n          }), resultName);\n\n        } else if (!selection.selectionSet) {\n          // If the field does not have a selection set, then we handle it\n          // as a scalar value. To keep this.canon from canonicalizing\n          // this value, we use this.canon.pass to wrap fieldValue in a\n          // Pass object that this.canon.admit will later unwrap as-is.\n          if (context.canonizeResults) {\n            fieldValue = this.canon.pass(fieldValue);\n          }\n\n        } else if (fieldValue != null) {\n          // In this case, because we know the field has a selection set,\n          // it must be trying to query a GraphQLObjectType, which is why\n          // fieldValue must be != null.\n          fieldValue = handleMissing(this.executeSelectionSet({\n            selectionSet: selection.selectionSet,\n            objectOrReference: fieldValue as StoreObject | Reference,\n            enclosingRef: isReference(fieldValue) ? fieldValue : enclosingRef,\n            context,\n          }), resultName);\n        }\n\n        if (fieldValue !== void 0) {\n          result = context.merge(result, { [resultName]: fieldValue });\n        }\n\n      } else {\n        const fragment = getFragmentFromSelection(\n          selection,\n          context.fragmentMap,\n        );\n\n        if (fragment && policies.fragmentMatches(fragment, typename)) {\n          fragment.selectionSet.selections.forEach(workSet.add, workSet);\n        }\n      }\n    });\n\n    const finalResult: ExecResult = { result, missing };\n    const frozen = context.canonizeResults\n      ? this.canon.admit(finalResult)\n      // Since this.canon is normally responsible for freezing results (only in\n      // development), freeze them manually if canonization is disabled.\n      : maybeDeepFreeze(finalResult);\n\n    // Store this result with its selection set so that we can quickly\n    // recognize it again in the StoreReader#isFresh method.\n    if (frozen.result) {\n      this.knownResults.set(frozen.result, selectionSet);\n    }\n\n    return frozen;\n  }\n\n  // Uncached version of executeSubSelectedArray.\n  private execSubSelectedArrayImpl({\n    field,\n    array,\n    enclosingRef,\n    context,\n  }: ExecSubSelectedArrayOptions): ExecResult {\n    let missing: MissingTree | undefined;\n\n    function handleMissing<T>(childResult: ExecResult<T>, i: number): T {\n      if (childResult.missing) {\n        missing = context.merge(missing, { [i]: childResult.missing });\n      }\n      return childResult.result;\n    }\n\n    if (field.selectionSet) {\n      array = array.filter(context.store.canRead);\n    }\n\n    array = array.map((item, i) => {\n      // null value in array\n      if (item === null) {\n        return null;\n      }\n\n      // This is a nested array, recurse\n      if (isArray(item)) {\n        return handleMissing(this.executeSubSelectedArray({\n          field,\n          array: item,\n          enclosingRef,\n          context,\n        }), i);\n      }\n\n      // This is an object, run the selection set on it\n      if (field.selectionSet) {\n        return handleMissing(this.executeSelectionSet({\n          selectionSet: field.selectionSet,\n          objectOrReference: item,\n          enclosingRef: isReference(item) ? item : enclosingRef,\n          context,\n        }), i);\n      }\n\n      if (__DEV__) {\n        assertSelectionSetForIdValue(context.store, field, item);\n      }\n\n      return item;\n    });\n\n    return {\n      result: context.canonizeResults ? this.canon.admit(array) : array,\n      missing,\n    };\n  }\n}\n\nfunction firstMissing(tree: MissingTree): string | undefined {\n  try {\n    JSON.stringify(tree, (_, value) => {\n      if (typeof value === \"string\") throw value;\n      return value;\n    });\n  } catch (result) {\n    return result;\n  }\n}\n\nfunction assertSelectionSetForIdValue(\n  store: NormalizedCache,\n  field: FieldNode,\n  fieldValue: any,\n) {\n  if (!field.selectionSet) {\n    const workSet = new Set([fieldValue]);\n    workSet.forEach(value => {\n      if (isNonNullObject(value)) {\n        invariant(\n          !isReference(value),\n          `Missing selection set for object of type ${\n            getTypenameFromStoreObject(store, value)\n          } returned for query field ${field.name.value}`,\n        );\n        Object.values(value).forEach(workSet.add, workSet);\n      }\n    });\n  }\n}\n", "import { dep, OptimisticDependencyFunction } from \"optimism\";\nimport { Slot } from \"@wry/context\";\nimport { InMemoryCache } from \"./inMemoryCache\";\nimport { ApolloCache } from '../../core';\n\nexport interface ReactiveVar<T> {\n  (newValue?: T): T;\n  onNextChange(listener: ReactiveListener<T>): () => void;\n  attachCache(cache: ApolloCache<any>): this;\n  forgetCache(cache: ApolloCache<any>): boolean;\n}\n\nexport type ReactiveListener<T> = (value: T) => any;\n\n// Contextual Slot that acquires its value when custom read functions are\n// called in Policies#readField.\nexport const cacheSlot = new Slot<ApolloCache<any>>();\n\nconst cacheInfoMap = new WeakMap<ApolloCache<any>, {\n  vars: Set<ReactiveVar<any>>;\n  dep: OptimisticDependencyFunction<ReactiveVar<any>>;\n}>();\n\nfunction getCacheInfo(cache: ApolloCache<any>) {\n  let info = cacheInfoMap.get(cache)!;\n  if (!info) {\n    cacheInfoMap.set(cache, info = {\n      vars: new Set,\n      dep: dep(),\n    });\n  }\n  return info;\n}\n\nexport function forgetCache(cache: ApolloCache<any>) {\n  getCacheInfo(cache).vars.forEach(rv => rv.forgetCache(cache));\n}\n\n// Calling forgetCache(cache) serves to silence broadcasts and allows the\n// cache to be garbage collected. However, the varsByCache WeakMap\n// preserves the set of reactive variables that were previously associated\n// with this cache, which makes it possible to \"recall\" the cache at a\n// later time, by reattaching it to those variables. If the cache has been\n// garbage collected in the meantime, because it is no longer reachable,\n// you won't be able to call recallCache(cache), and the cache will\n// automatically disappear from the varsByCache WeakMap.\nexport function recallCache(cache: ApolloCache<any>) {\n  getCacheInfo(cache).vars.forEach(rv => rv.attachCache(cache));\n}\n\nexport function makeVar<T>(value: T): ReactiveVar<T> {\n  const caches = new Set<ApolloCache<any>>();\n  const listeners = new Set<ReactiveListener<T>>();\n\n  const rv: ReactiveVar<T> = function (newValue) {\n    if (arguments.length > 0) {\n      if (value !== newValue) {\n        value = newValue!;\n        caches.forEach(cache => {\n          // Invalidate any fields with custom read functions that\n          // consumed this variable, so query results involving those\n          // fields will be recomputed the next time we read them.\n          getCacheInfo(cache).dep.dirty(rv);\n          // Broadcast changes to any caches that have previously read\n          // from this variable.\n          broadcast(cache);\n        });\n        // Finally, notify any listeners added via rv.onNextChange.\n        const oldListeners = Array.from(listeners);\n        listeners.clear();\n        oldListeners.forEach(listener => listener(value));\n      }\n    } else {\n      // When reading from the variable, obtain the current cache from\n      // context via cacheSlot. This isn't entirely foolproof, but it's\n      // the same system that powers varDep.\n      const cache = cacheSlot.getValue();\n      if (cache) {\n        attach(cache);\n        getCacheInfo(cache).dep(rv);\n      }\n    }\n\n    return value;\n  };\n\n  rv.onNextChange = listener => {\n    listeners.add(listener);\n    return () => {\n      listeners.delete(listener);\n    };\n  };\n\n  const attach = rv.attachCache = cache => {\n    caches.add(cache);\n    getCacheInfo(cache).vars.add(rv);\n    return rv;\n  };\n\n  rv.forgetCache = cache => caches.delete(cache);\n\n  return rv;\n}\n\ntype Broadcastable = ApolloCache<any> & {\n  // This method is protected in InMemoryCache, which we are ignoring, but\n  // we still want some semblance of type safety when we call it.\n  broadcastWatches?: InMemoryCache[\"broadcastWatches\"];\n};\n\nfunction broadcast(cache: Broadcastable) {\n  if (cache.broadcastWatches) {\n    cache.broadcastWatches();\n  }\n}\n", "import { invariant } from \"../../utilities/globals\";\n\nimport {\n  argumentsObjectFromField,\n  DeepMerger,\n  isNonEmptyArray,\n  isNonNullObject,\n} from \"../../utilities\";\n\nimport { hasOwn, isArray } from \"./helpers\";\nimport {\n  KeySpecifier,\n  KeyFieldsFunction,\n  KeyArgsFunction,\n} from \"./policies\";\n\n// Mapping from JSON-encoded KeySpecifier strings to associated information.\nconst specifierInfoCache: Record<string, {\n  paths?: string[][];\n  keyFieldsFn?: KeyFieldsFunction;\n  keyArgsFn?: KeyArgsFunction;\n}> = Object.create(null);\n\nfunction lookupSpecifierInfo(spec: KeySpecifier) {\n  // It's safe to encode KeySpecifier arrays with JSON.stringify, since they're\n  // just arrays of strings or nested KeySpecifier arrays, and the order of the\n  // array elements is important (and suitably preserved by JSON.stringify).\n  const cacheKey = JSON.stringify(spec);\n  return specifierInfoCache[cacheKey] ||\n    (specifierInfoCache[cacheKey] = Object.create(null));\n}\n\nexport function keyFieldsFnFromSpecifier(\n  specifier: KeySpecifier,\n): KeyFieldsFunction {\n  const info = lookupSpecifierInfo(specifier);\n\n  return info.keyFieldsFn || (info.keyFieldsFn = (\n    object,\n    context,\n  ) => {\n    const extract: typeof extractKey =\n      (from, key) => context.readField(key, from);\n\n    const keyObject = context.keyObject = collectSpecifierPaths(\n      specifier,\n      schemaKeyPath => {\n        let extracted = extractKeyPath(\n          context.storeObject,\n          schemaKeyPath,\n          // Using context.readField to extract paths from context.storeObject\n          // allows the extraction to see through Reference objects and respect\n          // custom read functions.\n          extract,\n        );\n\n        if (\n          extracted === void 0 &&\n          object !== context.storeObject &&\n          hasOwn.call(object, schemaKeyPath[0])\n        ) {\n          // If context.storeObject fails to provide a value for the requested\n          // path, fall back to the raw result object, if it has a top-level key\n          // matching the first key in the path (schemaKeyPath[0]). This allows\n          // key fields included in the written data to be saved in the cache\n          // even if they are not selected explicitly in context.selectionSet.\n          // Not being mentioned by context.selectionSet is convenient here,\n          // since it means these extra fields cannot be affected by field\n          // aliasing, which is why we can use extractKey instead of\n          // context.readField for this extraction.\n          extracted = extractKeyPath(object, schemaKeyPath, extractKey);\n        }\n\n        invariant(\n          extracted !== void 0,\n          `Missing field '${schemaKeyPath.join('.')}' while extracting keyFields from ${\n            JSON.stringify(object)\n          }`,\n        );\n\n        return extracted;\n      },\n    );\n\n    return `${context.typename}:${JSON.stringify(keyObject)}`;\n  });\n}\n\n// The keyArgs extraction process is roughly analogous to keyFields extraction,\n// but there are no aliases involved, missing fields are tolerated (by merely\n// omitting them from the key), and drawing from field.directives or variables\n// is allowed (in addition to drawing from the field's arguments object).\n// Concretely, these differences mean passing a different key path extractor\n// function to collectSpecifierPaths, reusing the shared extractKeyPath helper\n// wherever possible.\nexport function keyArgsFnFromSpecifier(specifier: KeySpecifier): KeyArgsFunction {\n  const info = lookupSpecifierInfo(specifier);\n\n  return info.keyArgsFn || (info.keyArgsFn = (args, {\n    field,\n    variables,\n    fieldName,\n  }) => {\n    const collected = collectSpecifierPaths(specifier, keyPath => {\n      const firstKey = keyPath[0];\n      const firstChar = firstKey.charAt(0);\n\n      if (firstChar === \"@\") {\n        if (field && isNonEmptyArray(field.directives)) {\n          const directiveName = firstKey.slice(1);\n          // If the directive appears multiple times, only the first\n          // occurrence's arguments will be used. TODO Allow repetition?\n          // TODO Cache this work somehow, a la aliasMap?\n          const d = field.directives.find(d => d.name.value === directiveName);\n          // Fortunately argumentsObjectFromField works for DirectiveNode!\n          const directiveArgs = d && argumentsObjectFromField(d, variables);\n          // For directives without arguments (d defined, but directiveArgs ===\n          // null), the presence or absence of the directive still counts as\n          // part of the field key, so we return null in those cases. If no\n          // directive with this name was found for this field (d undefined and\n          // thus directiveArgs undefined), we return undefined, which causes\n          // this value to be omitted from the key object returned by\n          // collectSpecifierPaths.\n          return directiveArgs && extractKeyPath(\n            directiveArgs,\n            // If keyPath.length === 1, this code calls extractKeyPath with an\n            // empty path, which works because it uses directiveArgs as the\n            // extracted value.\n            keyPath.slice(1),\n          );\n        }\n        // If the key started with @ but there was no corresponding directive,\n        // we want to omit this value from the key object, not fall through to\n        // treating @whatever as a normal argument name.\n        return;\n      }\n\n      if (firstChar === \"$\") {\n        const variableName = firstKey.slice(1);\n        if (variables && hasOwn.call(variables, variableName)) {\n          const varKeyPath = keyPath.slice(0);\n          varKeyPath[0] = variableName;\n          return extractKeyPath(variables, varKeyPath);\n        }\n        // If the key started with $ but there was no corresponding variable, we\n        // want to omit this value from the key object, not fall through to\n        // treating $whatever as a normal argument name.\n        return;\n      }\n\n      if (args) {\n        return extractKeyPath(args, keyPath);\n      }\n    });\n\n    const suffix = JSON.stringify(collected);\n\n    // If no arguments were passed to this field, and it didn't have any other\n    // field key contributions from directives or variables, hide the empty\n    // :{} suffix from the field key. However, a field passed no arguments can\n    // still end up with a non-empty :{...} suffix if its key configuration\n    // refers to directives or variables.\n    if (args || suffix !== \"{}\") {\n      fieldName += \":\" + suffix;\n    }\n\n    return fieldName;\n  });\n}\n\nexport function collectSpecifierPaths(\n  specifier: KeySpecifier,\n  extractor: (path: string[]) => any,\n): Record<string, any> {\n  // For each path specified by specifier, invoke the extractor, and repeatedly\n  // merge the results together, with appropriate ancestor context.\n  const merger = new DeepMerger;\n  return getSpecifierPaths(specifier).reduce((collected, path) => {\n    let toMerge = extractor(path);\n    if (toMerge !== void 0) {\n      // This path is not expected to contain array indexes, so the toMerge\n      // reconstruction will not contain arrays. TODO Fix this?\n      for (let i = path.length - 1; i >= 0; --i) {\n        toMerge = { [path[i]]: toMerge };\n      }\n      collected = merger.merge(collected, toMerge);\n    }\n    return collected;\n  }, Object.create(null));\n}\n\nexport function getSpecifierPaths(spec: KeySpecifier): string[][] {\n  const info = lookupSpecifierInfo(spec);\n\n  if (!info.paths) {\n    const paths: string[][] = info.paths = [];\n    const currentPath: string[] = [];\n\n    spec.forEach((s, i) => {\n      if (isArray(s)) {\n        getSpecifierPaths(s).forEach(p => paths.push(currentPath.concat(p)));\n        currentPath.length = 0;\n      } else {\n        currentPath.push(s);\n        if (!isArray(spec[i + 1])) {\n          paths.push(currentPath.slice(0));\n          currentPath.length = 0;\n        }\n      }\n    });\n  }\n\n  return info.paths!;\n}\n\nfunction extractKey<\n  TObj extends Record<string, any>,\n  TKey extends string,\n>(object: TObj, key: TKey): TObj[TKey] | undefined {\n  return object[key];\n}\n\nexport function extractKeyPath(\n  object: Record<string, any>,\n  path: string[],\n  extract?: typeof extractKey,\n): any {\n  // For each key in path, extract the corresponding child property from obj,\n  // flattening arrays if encountered (uncommon for keyFields and keyArgs, but\n  // possible). The final result of path.reduce is normalized so unexpected leaf\n  // objects have their keys safely sorted. That final result is difficult to\n  // type as anything other than any. You're welcome to try to improve the\n  // return type, but keep in mind extractKeyPath is not a public function\n  // (exported only for testing), so the effort may not be worthwhile unless the\n  // limited set of actual callers (see above) pass arguments that TypeScript\n  // can statically type. If we know only that path is some array of strings\n  // (and not, say, a specific tuple of statically known strings), any (or\n  // possibly unknown) is the honest answer.\n  extract = extract || extractKey;\n  return normalize(path.reduce(function reducer(obj, key): any {\n    return isArray(obj)\n      ? obj.map(child => reducer(child, key))\n      : obj && extract!(obj, key);\n  }, object));\n}\n\nfunction normalize<T>(value: T): T {\n  // Usually the extracted value will be a scalar value, since most primary\n  // key fields are scalar, but just in case we get an object or an array, we\n  // need to do some normalization of the order of (nested) keys.\n  if (isNonNullObject(value)) {\n    if (isArray(value)) {\n      return value.map(normalize) as any;\n    }\n    return collectSpecifierPaths(\n      Object.keys(value).sort(),\n      path => extractKeyPath(value, path),\n    ) as T;\n  }\n  return value;\n}\n", "import { invariant, InvariantError } from '../../utilities/globals';\n\nimport {\n  InlineFragmentNode,\n  FragmentDefinitionNode,\n  SelectionSetNode,\n  FieldNode,\n} from 'graphql';\n\nimport {\n  FragmentMap,\n  storeKeyNameFromField,\n  StoreValue,\n  StoreObject,\n  argumentsObjectFromField,\n  Reference,\n  isReference,\n  getStoreKeyName,\n  isNonNullObject,\n  stringifyForDisplay,\n} from '../../utilities';\nimport {\n  IdGetter,\n  MergeInfo,\n  NormalizedCache,\n  ReadMergeModifyContext,\n} from \"./types\";\nimport {\n  hasOwn,\n  fieldNameFromStoreName,\n  storeValueIsStoreObject,\n  selectionSetMatchesResult,\n  TypeOrFieldNameRegExp,\n  defaultDataIdFromObject,\n  isArray,\n} from './helpers';\nimport { cacheSlot } from './reactiveVars';\nimport { InMemoryCache } from './inMemoryCache';\nimport {\n  SafeReadonly,\n  FieldSpecifier,\n  ToReferenceFunction,\n  ReadFieldFunction,\n  ReadFieldOptions,\n  CanReadFunction,\n} from '../core/types/common';\nimport { WriteContext } from './writeToStore';\n\n// Upgrade to a faster version of the default stable JSON.stringify function\n// used by getStoreKeyName. This function is used when computing storeFieldName\n// strings (when no keyArgs has been configured for a field).\nimport { canonicalStringify } from './object-canon';\nimport { keyArgsFnFromSpecifier, keyFieldsFnFromSpecifier } from './key-extractor';\n\ngetStoreKeyName.setStringify(canonicalStringify);\n\nexport type TypePolicies = {\n  [__typename: string]: TypePolicy;\n}\n\n// TypeScript 3.7 will allow recursive type aliases, so this should work:\n// type KeySpecifier = (string | KeySpecifier)[]\nexport type KeySpecifier = ReadonlyArray<string | KeySpecifier>;\n\nexport type KeyFieldsContext = {\n  // The __typename of the incoming object, even if the __typename field was\n  // aliased to another name in the raw result object. May be undefined when\n  // dataIdFromObject is called for objects without __typename fields.\n  typename: string | undefined;\n\n  // The object to be identified, after processing to remove aliases and\n  // normalize identifiable child objects with references.\n  storeObject: StoreObject;\n\n  // Handy tool for reading additional fields from context.storeObject, either\n  // readField(\"fieldName\") to read storeObject[fieldName], or readField(\"name\",\n  // objectOrReference) to read from another object or Reference. If you read a\n  // field with a read function, that function will be invoked.\n  readField: ReadFieldFunction;\n\n  // If you are writing a custom keyFields function, and you plan to use the raw\n  // result object passed as the first argument, you may also need access to the\n  // selection set and available fragments for this object, just in case any\n  // fields have aliases. Since this logic is tricky to get right, and these\n  // context properties are not even always provided (for example, they are\n  // omitted when calling cache.identify(object), where object is assumed to be\n  // a StoreObject), we recommend you use context.storeObject (which has already\n  // been de-aliased) and context.readField (which can read from references as\n  // well as objects) instead of the raw result object in your keyFields\n  // functions, or just rely on the internal implementation of keyFields:[...]\n  // syntax to get these details right for you.\n  selectionSet?: SelectionSetNode;\n  fragmentMap?: FragmentMap;\n\n  // Internal. May be set by the KeyFieldsFunction to report fields that were\n  // involved in computing the ID. Never passed in by the caller.\n  keyObject?: Record<string, any>;\n};\n\nexport type KeyFieldsFunction = (\n  object: Readonly<StoreObject>,\n  context: KeyFieldsContext,\n) => KeySpecifier | false | ReturnType<IdGetter>;\n\ntype KeyFieldsResult = Exclude<ReturnType<KeyFieldsFunction>, KeySpecifier>;\n\n// TODO Should TypePolicy be a generic type, with a TObject or TEntity\n// type parameter?\nexport type TypePolicy = {\n  // Allows defining the primary key fields for this type, either using an\n  // array of field names or a function that returns an arbitrary string.\n  keyFields?: KeySpecifier | KeyFieldsFunction | false;\n\n  // Allows defining a merge function (or merge:true/false shorthand) to\n  // be used for merging objects of this type wherever they appear, unless\n  // the parent field also defines a merge function/boolean (that is,\n  // parent field merge functions take precedence over type policy merge\n  // functions). In many cases, defining merge:true for a given type\n  // policy can save you from specifying merge:true for all the field\n  // policies where that type might be encountered.\n  merge?: FieldMergeFunction | boolean;\n\n  // In the rare event that your schema happens to use a different\n  // __typename for the root Query, Mutation, and/or Schema types, you can\n  // express your deviant preferences by enabling one of these options.\n  queryType?: true,\n  mutationType?: true,\n  subscriptionType?: true,\n\n  fields?: {\n    [fieldName: string]:\n      | FieldPolicy<any>\n      | FieldReadFunction<any>;\n  }\n};\n\nexport type KeyArgsFunction = (\n  args: Record<string, any> | null,\n  context: {\n    typename: string;\n    fieldName: string;\n    field: FieldNode | null;\n    variables?: Record<string, any>;\n  },\n) => KeySpecifier | false | ReturnType<IdGetter>;\n\nexport type FieldPolicy<\n  // The internal representation used to store the field's data in the\n  // cache. Must be JSON-serializable if you plan to serialize the result\n  // of cache.extract() using JSON.\n  TExisting = any,\n  // The type of the incoming parameter passed to the merge function,\n  // typically matching the GraphQL response format, but with Reference\n  // objects substituted for any identifiable child objects. Often the\n  // same as TExisting, but not necessarily.\n  TIncoming = TExisting,\n  // The type that the read function actually returns, using TExisting\n  // data and options.args as input. Usually the same as TIncoming.\n  TReadResult = TIncoming,\n  // Allows FieldFunctionOptions definition to be overwritten by the\n  // developer\n  TOptions extends FieldFunctionOptions = FieldFunctionOptions\n> = {\n  keyArgs?: KeySpecifier | KeyArgsFunction | false;\n  read?: FieldReadFunction<TExisting, TReadResult, TOptions>;\n  merge?: FieldMergeFunction<TExisting, TIncoming, TOptions> | boolean;\n};\n\nexport type StorageType = Record<string, any>;\n\nfunction argsFromFieldSpecifier(spec: FieldSpecifier) {\n  return spec.args !== void 0 ? spec.args :\n    spec.field ? argumentsObjectFromField(spec.field, spec.variables) : null;\n}\n\nexport interface FieldFunctionOptions<\n  TArgs = Record<string, any>,\n  TVars = Record<string, any>,\n> {\n  args: TArgs | null;\n\n  // The name of the field, equal to options.field.name.value when\n  // options.field is available. Useful if you reuse the same function for\n  // multiple fields, and you need to know which field you're currently\n  // processing. Always a string, even when options.field is null.\n  fieldName: string;\n\n  // The full field key used internally, including serialized key arguments.\n  storeFieldName: string;\n\n  // The FieldNode object used to read this field. Useful if you need to\n  // know about other attributes of the field, such as its directives. This\n  // option will be null when a string was passed to options.readField.\n  field: FieldNode | null;\n\n  variables?: TVars;\n\n  // Utilities for dealing with { __ref } objects.\n  isReference: typeof isReference;\n  toReference: ToReferenceFunction;\n\n  // A handy place to put field-specific data that you want to survive\n  // across multiple read function calls. Useful for field-level caching,\n  // if your read function does any expensive work.\n  storage: StorageType;\n\n  cache: InMemoryCache;\n\n  // Helper function for reading other fields within the current object.\n  // If a foreign object or reference is provided, the field will be read\n  // from that object instead of the current object, so this function can\n  // be used (together with isReference) to examine the cache outside the\n  // current object. If a FieldNode is passed instead of a string, and\n  // that FieldNode has arguments, the same options.variables will be used\n  // to compute the argument values. Note that this function will invoke\n  // custom read functions for other fields, if defined. Always returns\n  // immutable data (enforced with Object.freeze in development).\n  readField: ReadFieldFunction;\n\n  // Returns true for non-normalized StoreObjects and non-dangling\n  // References, indicating that readField(name, objOrRef) has a chance of\n  // working. Useful for filtering out dangling references from lists.\n  canRead: CanReadFunction;\n\n  // Instead of just merging objects with { ...existing, ...incoming }, this\n  // helper function can be used to merge objects in a way that respects any\n  // custom merge functions defined for their fields.\n  mergeObjects: MergeObjectsFunction;\n}\n\ntype MergeObjectsFunction = <T extends StoreObject | Reference>(\n  existing: T,\n  incoming: T,\n) => T;\n\nexport type FieldReadFunction<\n  TExisting = any,\n  TReadResult = TExisting,\n  TOptions extends FieldFunctionOptions = FieldFunctionOptions\n> = (\n  // When reading a field, one often needs to know about any existing\n  // value stored for that field. If the field is read before any value\n  // has been written to the cache, this existing parameter will be\n  // undefined, which makes it easy to use a default parameter expression\n  // to supply the initial value. This parameter is positional (rather\n  // than one of the named options) because that makes it possible for the\n  // developer to annotate it with a type, without also having to provide\n  // a whole new type for the options object.\n  existing: SafeReadonly<TExisting> | undefined,\n  options: TOptions,\n) => TReadResult | undefined;\n\nexport type FieldMergeFunction<\n  TExisting = any,\n  TIncoming = TExisting,\n  // Passing the whole FieldFunctionOptions makes the current definition\n  // independent from its implementation\n  TOptions extends FieldFunctionOptions = FieldFunctionOptions\n> = (\n  existing: SafeReadonly<TExisting> | undefined,\n  // The incoming parameter needs to be positional as well, for the same\n  // reasons discussed in FieldReadFunction above.\n  incoming: SafeReadonly<TIncoming>,\n  options: TOptions,\n) => SafeReadonly<TExisting>;\n\nconst nullKeyFieldsFn: KeyFieldsFunction = () => void 0;\nconst simpleKeyArgsFn: KeyArgsFunction = (_args, context) => context.fieldName;\n\n// These merge functions can be selected by specifying merge:true or\n// merge:false in a field policy.\nconst mergeTrueFn: FieldMergeFunction<any> =\n  (existing, incoming, { mergeObjects }) => mergeObjects(existing, incoming);\nconst mergeFalseFn: FieldMergeFunction<any> = (_, incoming) => incoming;\n\nexport type PossibleTypesMap = {\n  [supertype: string]: string[];\n};\n\nexport class Policies {\n  private typePolicies: {\n    [__typename: string]: {\n      keyFn?: KeyFieldsFunction;\n      merge?: FieldMergeFunction<any>;\n      fields: {\n        [fieldName: string]: {\n          keyFn?: KeyArgsFunction;\n          read?: FieldReadFunction<any>;\n          merge?: FieldMergeFunction<any>;\n        };\n      };\n    };\n  } = Object.create(null);\n\n  private toBeAdded: {\n    [__typename: string]: TypePolicy[];\n  } = Object.create(null);\n\n  // Map from subtype names to sets of supertype names. Note that this\n  // representation inverts the structure of possibleTypes (whose keys are\n  // supertypes and whose values are arrays of subtypes) because it tends\n  // to be much more efficient to search upwards than downwards.\n  private supertypeMap = new Map<string, Set<string>>();\n\n  // Any fuzzy subtypes specified by possibleTypes will be converted to\n  // RegExp objects and recorded here. Every key of this map can also be\n  // found in supertypeMap. In many cases this Map will be empty, which\n  // means no fuzzy subtype checking will happen in fragmentMatches.\n  private fuzzySubtypes = new Map<string, RegExp>();\n\n  public readonly cache: InMemoryCache;\n\n  public readonly rootIdsByTypename: Record<string, string> = Object.create(null);\n  public readonly rootTypenamesById: Record<string, string> = Object.create(null);\n\n  public readonly usingPossibleTypes = false;\n\n  constructor(private config: {\n    cache: InMemoryCache;\n    dataIdFromObject?: KeyFieldsFunction;\n    possibleTypes?: PossibleTypesMap;\n    typePolicies?: TypePolicies;\n  }) {\n    this.config = {\n      dataIdFromObject: defaultDataIdFromObject,\n      ...config,\n    };\n\n    this.cache = this.config.cache;\n\n    this.setRootTypename(\"Query\");\n    this.setRootTypename(\"Mutation\");\n    this.setRootTypename(\"Subscription\");\n\n    if (config.possibleTypes) {\n      this.addPossibleTypes(config.possibleTypes);\n    }\n\n    if (config.typePolicies) {\n      this.addTypePolicies(config.typePolicies);\n    }\n  }\n\n  public identify(\n    object: StoreObject,\n    partialContext?: Partial<KeyFieldsContext>,\n  ): [string?, StoreObject?] {\n    const policies = this;\n\n    const typename = partialContext && (\n      partialContext.typename ||\n      partialContext.storeObject?.__typename\n    ) || object.__typename;\n\n    // It should be possible to write root Query fields with writeFragment,\n    // using { __typename: \"Query\", ... } as the data, but it does not make\n    // sense to allow the same identification behavior for the Mutation and\n    // Subscription types, since application code should never be writing\n    // directly to (or reading directly from) those root objects.\n    if (typename === this.rootTypenamesById.ROOT_QUERY) {\n      return [\"ROOT_QUERY\"];\n    }\n\n    // Default context.storeObject to object if not otherwise provided.\n    const storeObject = partialContext && partialContext.storeObject || object;\n\n    const context: KeyFieldsContext = {\n      ...partialContext,\n      typename,\n      storeObject,\n      readField: partialContext && partialContext.readField || function () {\n        const options = normalizeReadFieldOptions(arguments, storeObject);\n        return policies.readField(options, {\n          store: policies.cache[\"data\"],\n          variables: options.variables,\n        });\n      },\n    };\n\n    let id: KeyFieldsResult;\n\n    const policy = typename && this.getTypePolicy(typename);\n    let keyFn = policy && policy.keyFn || this.config.dataIdFromObject;\n    while (keyFn) {\n      const specifierOrId = keyFn(object, context);\n      if (isArray(specifierOrId)) {\n        keyFn = keyFieldsFnFromSpecifier(specifierOrId);\n      } else {\n        id = specifierOrId;\n        break;\n      }\n    }\n\n    id = id ? String(id) : void 0;\n    return context.keyObject ? [id, context.keyObject] : [id];\n  }\n\n  public addTypePolicies(typePolicies: TypePolicies) {\n    Object.keys(typePolicies).forEach(typename => {\n      const {\n        queryType,\n        mutationType,\n        subscriptionType,\n        ...incoming\n      } = typePolicies[typename];\n\n      // Though {query,mutation,subscription}Type configurations are rare,\n      // it's important to call setRootTypename as early as possible,\n      // since these configurations should apply consistently for the\n      // entire lifetime of the cache. Also, since only one __typename can\n      // qualify as one of these root types, these three properties cannot\n      // be inherited, unlike the rest of the incoming properties. That\n      // restriction is convenient, because the purpose of this.toBeAdded\n      // is to delay the processing of type/field policies until the first\n      // time they're used, allowing policies to be added in any order as\n      // long as all relevant policies (including policies for supertypes)\n      // have been added by the time a given policy is used for the first\n      // time. In other words, since inheritance doesn't matter for these\n      // properties, there's also no need to delay their processing using\n      // the this.toBeAdded queue.\n      if (queryType) this.setRootTypename(\"Query\", typename);\n      if (mutationType) this.setRootTypename(\"Mutation\", typename);\n      if (subscriptionType) this.setRootTypename(\"Subscription\", typename);\n\n      if (hasOwn.call(this.toBeAdded, typename)) {\n        this.toBeAdded[typename].push(incoming);\n      } else {\n        this.toBeAdded[typename] = [incoming];\n      }\n    });\n  }\n\n  private updateTypePolicy(typename: string, incoming: TypePolicy) {\n    const existing = this.getTypePolicy(typename);\n    const { keyFields, fields } = incoming;\n\n    function setMerge(\n      existing: { merge?: FieldMergeFunction | boolean; },\n      merge?: FieldMergeFunction | boolean,\n    ) {\n      existing.merge =\n        typeof merge === \"function\" ? merge :\n        // Pass merge:true as a shorthand for a merge implementation\n        // that returns options.mergeObjects(existing, incoming).\n        merge === true ? mergeTrueFn :\n        // Pass merge:false to make incoming always replace existing\n        // without any warnings about data clobbering.\n        merge === false ? mergeFalseFn :\n        existing.merge;\n    }\n\n    // Type policies can define merge functions, as an alternative to\n    // using field policies to merge child objects.\n    setMerge(existing, incoming.merge);\n\n    existing.keyFn =\n      // Pass false to disable normalization for this typename.\n      keyFields === false ? nullKeyFieldsFn :\n      // Pass an array of strings to use those fields to compute a\n      // composite ID for objects of this typename.\n      isArray(keyFields) ? keyFieldsFnFromSpecifier(keyFields) :\n      // Pass a function to take full control over identification.\n      typeof keyFields === \"function\" ? keyFields :\n      // Leave existing.keyFn unchanged if above cases fail.\n      existing.keyFn;\n\n    if (fields) {\n      Object.keys(fields).forEach(fieldName => {\n        const existing = this.getFieldPolicy(typename, fieldName, true)!;\n        const incoming = fields[fieldName];\n\n        if (typeof incoming === \"function\") {\n          existing.read = incoming;\n        } else {\n          const { keyArgs, read, merge } = incoming;\n\n          existing.keyFn =\n            // Pass false to disable argument-based differentiation of\n            // field identities.\n            keyArgs === false ? simpleKeyArgsFn :\n            // Pass an array of strings to use named arguments to\n            // compute a composite identity for the field.\n            isArray(keyArgs) ? keyArgsFnFromSpecifier(keyArgs) :\n            // Pass a function to take full control over field identity.\n            typeof keyArgs === \"function\" ? keyArgs :\n            // Leave existing.keyFn unchanged if above cases fail.\n            existing.keyFn;\n\n          if (typeof read === \"function\") {\n            existing.read = read;\n          }\n\n          setMerge(existing, merge);\n        }\n\n        if (existing.read && existing.merge) {\n          // If we have both a read and a merge function, assume\n          // keyArgs:false, because read and merge together can take\n          // responsibility for interpreting arguments in and out. This\n          // default assumption can always be overridden by specifying\n          // keyArgs explicitly in the FieldPolicy.\n          existing.keyFn = existing.keyFn || simpleKeyArgsFn;\n        }\n      });\n    }\n  }\n\n  private setRootTypename(\n    which: \"Query\" | \"Mutation\" | \"Subscription\",\n    typename: string = which,\n  ) {\n    const rootId = \"ROOT_\" + which.toUpperCase();\n    const old = this.rootTypenamesById[rootId];\n    if (typename !== old) {\n      invariant(!old || old === which, `Cannot change root ${which} __typename more than once`);\n      // First, delete any old __typename associated with this rootId from\n      // rootIdsByTypename.\n      if (old) delete this.rootIdsByTypename[old];\n      // Now make this the only __typename that maps to this rootId.\n      this.rootIdsByTypename[typename] = rootId;\n      // Finally, update the __typename associated with this rootId.\n      this.rootTypenamesById[rootId] = typename;\n    }\n  }\n\n  public addPossibleTypes(possibleTypes: PossibleTypesMap) {\n    (this.usingPossibleTypes as boolean) = true;\n    Object.keys(possibleTypes).forEach(supertype => {\n      // Make sure all types have an entry in this.supertypeMap, even if\n      // their supertype set is empty, so we can return false immediately\n      // from policies.fragmentMatches for unknown supertypes.\n      this.getSupertypeSet(supertype, true);\n\n      possibleTypes[supertype].forEach(subtype => {\n        this.getSupertypeSet(subtype, true)!.add(supertype);\n        const match = subtype.match(TypeOrFieldNameRegExp);\n        if (!match || match[0] !== subtype) {\n          // TODO Don't interpret just any invalid typename as a RegExp.\n          this.fuzzySubtypes.set(subtype, new RegExp(subtype));\n        }\n      });\n    });\n  }\n\n  private getTypePolicy(typename: string): Policies[\"typePolicies\"][string] {\n    if (!hasOwn.call(this.typePolicies, typename)) {\n      const policy: Policies[\"typePolicies\"][string] =\n        this.typePolicies[typename] = Object.create(null);\n      policy.fields = Object.create(null);\n\n      // When the TypePolicy for typename is first accessed, instead of\n      // starting with an empty policy object, inherit any properties or\n      // fields from the type policies of the supertypes of typename.\n      //\n      // Any properties or fields defined explicitly within the TypePolicy\n      // for typename will take precedence, and if there are multiple\n      // supertypes, the properties of policies whose types were added\n      // later via addPossibleTypes will take precedence over those of\n      // earlier supertypes. TODO Perhaps we should warn about these\n      // conflicts in development, and recommend defining the property\n      // explicitly in the subtype policy?\n      //\n      // Field policy inheritance is atomic/shallow: you can't inherit a\n      // field policy and then override just its read function, since read\n      // and merge functions often need to cooperate, so changing only one\n      // of them would be a recipe for inconsistency.\n      //\n      // Once the TypePolicy for typename has been accessed, its\n      // properties can still be updated directly using addTypePolicies,\n      // but future changes to supertype policies will not be reflected in\n      // this policy, because this code runs at most once per typename.\n      const supertypes = this.supertypeMap.get(typename);\n      if (supertypes && supertypes.size) {\n        supertypes.forEach(supertype => {\n          const { fields, ...rest } = this.getTypePolicy(supertype);\n          Object.assign(policy, rest);\n          Object.assign(policy.fields, fields);\n        });\n      }\n    }\n\n    const inbox = this.toBeAdded[typename];\n    if (inbox && inbox.length) {\n      // Merge the pending policies into this.typePolicies, in the order they\n      // were originally passed to addTypePolicy.\n      inbox.splice(0).forEach(policy => {\n        this.updateTypePolicy(typename, policy);\n      });\n    }\n\n    return this.typePolicies[typename];\n  }\n\n  private getFieldPolicy(\n    typename: string | undefined,\n    fieldName: string,\n    createIfMissing: boolean,\n  ): {\n    keyFn?: KeyArgsFunction;\n    read?: FieldReadFunction<any>;\n    merge?: FieldMergeFunction<any>;\n  } | undefined {\n    if (typename) {\n      const fieldPolicies = this.getTypePolicy(typename).fields;\n      return fieldPolicies[fieldName] || (\n        createIfMissing && (fieldPolicies[fieldName] = Object.create(null)));\n    }\n  }\n\n  private getSupertypeSet(\n    subtype: string,\n    createIfMissing: boolean,\n  ): Set<string> | undefined {\n    let supertypeSet = this.supertypeMap.get(subtype);\n    if (!supertypeSet && createIfMissing) {\n      this.supertypeMap.set(subtype, supertypeSet = new Set<string>());\n    }\n    return supertypeSet;\n  }\n\n  public fragmentMatches(\n    fragment: InlineFragmentNode | FragmentDefinitionNode,\n    typename: string | undefined,\n    result?: Record<string, any>,\n    variables?: Record<string, any>,\n  ): boolean {\n    if (!fragment.typeCondition) return true;\n\n    // If the fragment has a type condition but the object we're matching\n    // against does not have a __typename, the fragment cannot match.\n    if (!typename) return false;\n\n    const supertype = fragment.typeCondition.name.value;\n    // Common case: fragment type condition and __typename are the same.\n    if (typename === supertype) return true;\n\n    if (this.usingPossibleTypes &&\n        this.supertypeMap.has(supertype)) {\n      const typenameSupertypeSet = this.getSupertypeSet(typename, true)!;\n      const workQueue = [typenameSupertypeSet];\n      const maybeEnqueue = (subtype: string) => {\n        const supertypeSet = this.getSupertypeSet(subtype, false);\n        if (supertypeSet &&\n            supertypeSet.size &&\n            workQueue.indexOf(supertypeSet) < 0) {\n          workQueue.push(supertypeSet);\n        }\n      };\n\n      // We need to check fuzzy subtypes only if we encountered fuzzy\n      // subtype strings in addPossibleTypes, and only while writing to\n      // the cache, since that's when selectionSetMatchesResult gives a\n      // strong signal of fragment matching. The StoreReader class calls\n      // policies.fragmentMatches without passing a result object, so\n      // needToCheckFuzzySubtypes is always false while reading.\n      let needToCheckFuzzySubtypes = !!(result && this.fuzzySubtypes.size);\n      let checkingFuzzySubtypes = false;\n\n      // It's important to keep evaluating workQueue.length each time through\n      // the loop, because the queue can grow while we're iterating over it.\n      for (let i = 0; i < workQueue.length; ++i) {\n        const supertypeSet = workQueue[i];\n\n        if (supertypeSet.has(supertype)) {\n          if (!typenameSupertypeSet.has(supertype)) {\n            if (checkingFuzzySubtypes) {\n              invariant.warn(`Inferring subtype ${typename} of supertype ${supertype}`);\n            }\n            // Record positive results for faster future lookup.\n            // Unfortunately, we cannot safely cache negative results,\n            // because new possibleTypes data could always be added to the\n            // Policies class.\n            typenameSupertypeSet.add(supertype);\n          }\n          return true;\n        }\n\n        supertypeSet.forEach(maybeEnqueue);\n\n        if (needToCheckFuzzySubtypes &&\n            // Start checking fuzzy subtypes only after exhausting all\n            // non-fuzzy subtypes (after the final iteration of the loop).\n            i === workQueue.length - 1 &&\n            // We could wait to compare fragment.selectionSet to result\n            // after we verify the supertype, but this check is often less\n            // expensive than that search, and we will have to do the\n            // comparison anyway whenever we find a potential match.\n            selectionSetMatchesResult(fragment.selectionSet, result!, variables)) {\n          // We don't always need to check fuzzy subtypes (if no result\n          // was provided, or !this.fuzzySubtypes.size), but, when we do,\n          // we only want to check them once.\n          needToCheckFuzzySubtypes = false;\n          checkingFuzzySubtypes = true;\n\n          // If we find any fuzzy subtypes that match typename, extend the\n          // workQueue to search through the supertypes of those fuzzy\n          // subtypes. Otherwise the for-loop will terminate and we'll\n          // return false below.\n          this.fuzzySubtypes.forEach((regExp, fuzzyString) => {\n            const match = typename.match(regExp);\n            if (match && match[0] === typename) {\n              maybeEnqueue(fuzzyString);\n            }\n          });\n        }\n      }\n    }\n\n    return false;\n  }\n\n  public hasKeyArgs(typename: string | undefined, fieldName: string) {\n    const policy = this.getFieldPolicy(typename, fieldName, false);\n    return !!(policy && policy.keyFn);\n  }\n\n  public getStoreFieldName(fieldSpec: FieldSpecifier): string {\n    const { typename, fieldName } = fieldSpec;\n    const policy = this.getFieldPolicy(typename, fieldName, false);\n    let storeFieldName: Exclude<ReturnType<KeyArgsFunction>, KeySpecifier>;\n\n    let keyFn = policy && policy.keyFn;\n    if (keyFn && typename) {\n      const context: Parameters<KeyArgsFunction>[1] = {\n        typename,\n        fieldName,\n        field: fieldSpec.field || null,\n        variables: fieldSpec.variables,\n      };\n      const args = argsFromFieldSpecifier(fieldSpec);\n      while (keyFn) {\n        const specifierOrString = keyFn(args, context);\n        if (isArray(specifierOrString)) {\n          keyFn = keyArgsFnFromSpecifier(specifierOrString);\n        } else {\n          // If the custom keyFn returns a falsy value, fall back to\n          // fieldName instead.\n          storeFieldName = specifierOrString || fieldName;\n          break;\n        }\n      }\n    }\n\n    if (storeFieldName === void 0) {\n      storeFieldName = fieldSpec.field\n        ? storeKeyNameFromField(fieldSpec.field, fieldSpec.variables)\n        : getStoreKeyName(fieldName, argsFromFieldSpecifier(fieldSpec));\n    }\n\n    // Returning false from a keyArgs function is like configuring\n    // keyArgs: false, but more dynamic.\n    if (storeFieldName === false) {\n      return fieldName;\n    }\n\n    // Make sure custom field names start with the actual field.name.value\n    // of the field, so we can always figure out which properties of a\n    // StoreObject correspond to which original field names.\n    return fieldName === fieldNameFromStoreName(storeFieldName)\n      ? storeFieldName\n      : fieldName + \":\" + storeFieldName;\n  }\n\n  public readField<V = StoreValue>(\n    options: ReadFieldOptions,\n    context: ReadMergeModifyContext,\n  ): SafeReadonly<V> | undefined {\n    const objectOrReference = options.from;\n    if (!objectOrReference) return;\n\n    const nameOrField = options.field || options.fieldName;\n    if (!nameOrField) return;\n\n    if (options.typename === void 0) {\n      const typename = context.store.getFieldValue<string>(objectOrReference, \"__typename\");\n      if (typename) options.typename = typename;\n    }\n\n    const storeFieldName = this.getStoreFieldName(options);\n    const fieldName = fieldNameFromStoreName(storeFieldName);\n    const existing = context.store.getFieldValue<V>(objectOrReference, storeFieldName);\n    const policy = this.getFieldPolicy(options.typename, fieldName, false);\n    const read = policy && policy.read;\n\n    if (read) {\n      const readOptions = makeFieldFunctionOptions(\n        this,\n        objectOrReference,\n        options,\n        context,\n        context.store.getStorage(\n          isReference(objectOrReference)\n            ? objectOrReference.__ref\n            : objectOrReference,\n          storeFieldName,\n        ),\n      );\n\n      // Call read(existing, readOptions) with cacheSlot holding this.cache.\n      return cacheSlot.withValue(\n        this.cache,\n        read,\n        [existing, readOptions],\n      ) as SafeReadonly<V>;\n    }\n\n    return existing;\n  }\n\n  public getReadFunction(\n    typename: string | undefined,\n    fieldName: string,\n  ): FieldReadFunction | undefined {\n    const policy = this.getFieldPolicy(typename, fieldName, false);\n    return policy && policy.read;\n  }\n\n  public getMergeFunction(\n    parentTypename: string | undefined,\n    fieldName: string,\n    childTypename: string | undefined,\n  ): FieldMergeFunction | undefined {\n    let policy:\n      | Policies[\"typePolicies\"][string]\n      | Policies[\"typePolicies\"][string][\"fields\"][string]\n      | undefined =\n      this.getFieldPolicy(parentTypename, fieldName, false);\n    let merge = policy && policy.merge;\n    if (!merge && childTypename) {\n      policy = this.getTypePolicy(childTypename);\n      merge = policy && policy.merge;\n    }\n    return merge;\n  }\n\n  public runMergeFunction(\n    existing: StoreValue,\n    incoming: StoreValue,\n    { field, typename, merge }: MergeInfo,\n    context: WriteContext,\n    storage?: StorageType,\n  ) {\n    if (merge === mergeTrueFn) {\n      // Instead of going to the trouble of creating a full\n      // FieldFunctionOptions object and calling mergeTrueFn, we can\n      // simply call mergeObjects, as mergeTrueFn would.\n      return makeMergeObjectsFunction(\n        context.store,\n      )(existing as StoreObject,\n        incoming as StoreObject);\n    }\n\n    if (merge === mergeFalseFn) {\n      // Likewise for mergeFalseFn, whose implementation is even simpler.\n      return incoming;\n    }\n\n    // If cache.writeQuery or cache.writeFragment was called with\n    // options.overwrite set to true, we still call merge functions, but\n    // the existing data is always undefined, so the merge function will\n    // not attempt to combine the incoming data with the existing data.\n    if (context.overwrite) {\n      existing = void 0;\n    }\n\n    return merge(existing, incoming, makeFieldFunctionOptions(\n      this,\n      // Unlike options.readField for read functions, we do not fall\n      // back to the current object if no foreignObjOrRef is provided,\n      // because it's not clear what the current object should be for\n      // merge functions: the (possibly undefined) existing object, or\n      // the incoming object? If you think your merge function needs\n      // to read sibling fields in order to produce a new value for\n      // the current field, you might want to rethink your strategy,\n      // because that's a recipe for making merge behavior sensitive\n      // to the order in which fields are written into the cache.\n      // However, readField(name, ref) is useful for merge functions\n      // that need to deduplicate child objects and references.\n      void 0,\n      { typename,\n        fieldName: field.name.value,\n        field,\n        variables: context.variables },\n      context,\n      storage || Object.create(null),\n    ));\n  }\n}\n\nfunction makeFieldFunctionOptions(\n  policies: Policies,\n  objectOrReference: StoreObject | Reference | undefined,\n  fieldSpec: FieldSpecifier,\n  context: ReadMergeModifyContext,\n  storage: StorageType,\n): FieldFunctionOptions {\n  const storeFieldName = policies.getStoreFieldName(fieldSpec);\n  const fieldName = fieldNameFromStoreName(storeFieldName);\n  const variables = fieldSpec.variables || context.variables;\n  const { toReference, canRead } = context.store;\n\n  return {\n    args: argsFromFieldSpecifier(fieldSpec),\n    field: fieldSpec.field || null,\n    fieldName,\n    storeFieldName,\n    variables,\n    isReference,\n    toReference,\n    storage,\n    cache: policies.cache,\n    canRead,\n    readField<T>() {\n      return policies.readField<T>(\n        normalizeReadFieldOptions(arguments, objectOrReference, context),\n        context,\n      );\n    },\n    mergeObjects: makeMergeObjectsFunction(context.store),\n  };\n}\n\nexport function normalizeReadFieldOptions(\n  readFieldArgs: IArguments,\n  objectOrReference: StoreObject | Reference | undefined,\n  variables?: ReadMergeModifyContext[\"variables\"],\n): ReadFieldOptions {\n  const {\n    0: fieldNameOrOptions,\n    1: from,\n    length: argc,\n  } = readFieldArgs;\n\n  let options: ReadFieldOptions;\n\n  if (typeof fieldNameOrOptions === \"string\") {\n    options = {\n      fieldName: fieldNameOrOptions,\n      // Default to objectOrReference only when no second argument was\n      // passed for the from parameter, not when undefined is explicitly\n      // passed as the second argument.\n      from: argc > 1 ? from : objectOrReference,\n    };\n  } else {\n    options = { ...fieldNameOrOptions };\n    // Default to objectOrReference only when fieldNameOrOptions.from is\n    // actually omitted, rather than just undefined.\n    if (!hasOwn.call(options, \"from\")) {\n      options.from = objectOrReference;\n    }\n  }\n\n  if (__DEV__ && options.from === void 0) {\n    invariant.warn(`Undefined 'from' passed to readField with arguments ${\n      stringifyForDisplay(Array.from(readFieldArgs))\n    }`);\n  }\n\n  if (void 0 === options.variables) {\n    options.variables = variables;\n  }\n\n  return options;\n}\n\nfunction makeMergeObjectsFunction(\n  store: NormalizedCache,\n): MergeObjectsFunction {\n  return function mergeObjects(existing, incoming) {\n    if (isArray(existing) || isArray(incoming)) {\n      throw new InvariantError(\"Cannot automatically merge arrays\");\n    }\n\n    // These dynamic checks are necessary because the parameters of a\n    // custom merge function can easily have the any type, so the type\n    // system cannot always enforce the StoreObject | Reference parameter\n    // types of options.mergeObjects.\n    if (isNonNullObject(existing) &&\n        isNonNullObject(incoming)) {\n      const eType = store.getFieldValue(existing, \"__typename\");\n      const iType = store.getFieldValue(incoming, \"__typename\");\n      const typesDiffer = eType && iType && eType !== iType;\n\n      if (typesDiffer) {\n        return incoming;\n      }\n\n      if (isReference(existing) &&\n          storeValueIsStoreObject(incoming)) {\n        // Update the normalized EntityStore for the entity identified by\n        // existing.__ref, preferring/overwriting any fields contributed by the\n        // newer incoming StoreObject.\n        store.merge(existing.__ref, incoming);\n        return existing;\n      }\n\n      if (storeValueIsStoreObject(existing) &&\n          isReference(incoming)) {\n        // Update the normalized EntityStore for the entity identified by\n        // incoming.__ref, taking fields from the older existing object only if\n        // those fields are not already present in the newer StoreObject\n        // identified by incoming.__ref.\n        store.merge(existing, incoming.__ref);\n        return incoming;\n      }\n\n      if (storeValueIsStoreObject(existing) &&\n          storeValueIsStoreObject(incoming)) {\n        return { ...existing, ...incoming };\n      }\n    }\n\n    return incoming;\n  };\n}\n", "import { invariant, InvariantError } from '../../utilities/globals';\nimport { equal } from '@wry/equality';\nimport { Trie } from '@wry/trie';\nimport {\n  SelectionSetNode,\n  FieldNode,\n} from 'graphql';\n\nimport {\n  createFragmentMap,\n  FragmentMap,\n  getFragmentFromSelection,\n  getDefaultValues,\n  getFragmentDefinitions,\n  getOperationDefinition,\n  getTypenameFromResult,\n  makeReference,\n  isField,\n  resultKeyNameFromField,\n  StoreValue,\n  StoreObject,\n  Reference,\n  isReference,\n  shouldInclude,\n  cloneDeep,\n  addTypenameToDocument,\n  isNonEmptyArray,\n  argumentsObjectFromField,\n} from '../../utilities';\n\nimport { NormalizedCache, ReadMergeModifyContext, MergeTree } from './types';\nimport { makeProcessedFieldsMerger, fieldNameFromStoreName, storeValueIsStoreObject, isArray } from './helpers';\nimport { StoreReader } from './readFromStore';\nimport { InMemoryCache } from './inMemoryCache';\nimport { EntityStore } from './entityStore';\nimport { Cache } from '../../core';\nimport { canonicalStringify } from './object-canon';\nimport { normalizeReadFieldOptions } from './policies';\nimport { ReadFieldFunction } from '../core/types/common';\n\nexport interface WriteContext extends ReadMergeModifyContext {\n  readonly written: {\n    [dataId: string]: SelectionSetNode[];\n  };\n  readonly fragmentMap?: FragmentMap;\n  // General-purpose deep-merge function for use during writes.\n  merge<T>(existing: T, incoming: T): T;\n  // If true, merge functions will be called with undefined existing data.\n  overwrite: boolean;\n  incomingById: Map<string, {\n    storeObject: StoreObject;\n    mergeTree?: MergeTree;\n    fieldNodeSet: Set<FieldNode>;\n  }>;\n  // Directive metadata for @client and @defer. We could use a bitfield for this\n  // information to save some space, and use that bitfield number as the keys in\n  // the context.flavors Map.\n  clientOnly: boolean;\n  deferred: boolean;\n  flavors: Map<string, FlavorableWriteContext>;\n};\n\ntype FlavorableWriteContext = Pick<\n  WriteContext,\n  | \"clientOnly\"\n  | \"deferred\"\n  | \"flavors\"\n>;\n\n// Since there are only four possible combinations of context.clientOnly and\n// context.deferred values, we should need at most four \"flavors\" of any given\n// WriteContext. To avoid creating multiple copies of the same context, we cache\n// the contexts in the context.flavors Map (shared by all flavors) according to\n// their clientOnly and deferred values (always in that order).\nfunction getContextFlavor<TContext extends FlavorableWriteContext>(\n  context: TContext,\n  clientOnly: TContext[\"clientOnly\"],\n  deferred: TContext[\"deferred\"],\n): TContext {\n  const key = `${clientOnly}${deferred}`;\n  let flavored = context.flavors.get(key);\n  if (!flavored) {\n    context.flavors.set(key, flavored = (\n      context.clientOnly === clientOnly &&\n      context.deferred === deferred\n    ) ? context : {\n      ...context,\n      clientOnly,\n      deferred,\n    });\n  }\n  return flavored as TContext;\n}\n\ninterface ProcessSelectionSetOptions {\n  dataId?: string,\n  result: Record<string, any>;\n  selectionSet: SelectionSetNode;\n  context: WriteContext;\n  mergeTree: MergeTree;\n}\n\nexport class StoreWriter {\n  constructor(\n    public readonly cache: InMemoryCache,\n    private reader?: StoreReader,\n  ) {}\n\n  public writeToStore(store: NormalizedCache, {\n    query,\n    result,\n    dataId,\n    variables,\n    overwrite,\n  }: Cache.WriteOptions): Reference | undefined {\n    const operationDefinition = getOperationDefinition(query)!;\n    const merger = makeProcessedFieldsMerger();\n\n    variables = {\n      ...getDefaultValues(operationDefinition),\n      ...variables!,\n    };\n\n    const context: WriteContext = {\n      store,\n      written: Object.create(null),\n      merge<T>(existing: T, incoming: T) {\n        return merger.merge(existing, incoming) as T;\n      },\n      variables,\n      varString: canonicalStringify(variables),\n      fragmentMap: createFragmentMap(getFragmentDefinitions(query)),\n      overwrite: !!overwrite,\n      incomingById: new Map,\n      clientOnly: false,\n      deferred: false,\n      flavors: new Map,\n    };\n\n    const ref = this.processSelectionSet({\n      result: result || Object.create(null),\n      dataId,\n      selectionSet: operationDefinition.selectionSet,\n      mergeTree: { map: new Map },\n      context,\n    });\n\n    if (!isReference(ref)) {\n      throw new InvariantError(`Could not identify object ${JSON.stringify(result)}`);\n    }\n\n    // So far, the store has not been modified, so now it's time to process\n    // context.incomingById and merge those incoming fields into context.store.\n    context.incomingById.forEach(({ storeObject, mergeTree, fieldNodeSet }, dataId) => {\n      const entityRef = makeReference(dataId);\n\n      if (mergeTree && mergeTree.map.size) {\n        const applied = this.applyMerges(mergeTree, entityRef, storeObject, context);\n        if (isReference(applied)) {\n          // Assume References returned by applyMerges have already been merged\n          // into the store. See makeMergeObjectsFunction in policies.ts for an\n          // example of how this can happen.\n          return;\n        }\n        // Otherwise, applyMerges returned a StoreObject, whose fields we should\n        // merge into the store (see store.merge statement below).\n        storeObject = applied;\n      }\n\n      if (__DEV__ && !context.overwrite) {\n        const fieldsWithSelectionSets: Record<string, true> = Object.create(null);\n        fieldNodeSet.forEach(field => {\n          if (field.selectionSet) {\n            fieldsWithSelectionSets[field.name.value] = true;\n          }\n        });\n\n        const hasSelectionSet = (storeFieldName: string) =>\n          fieldsWithSelectionSets[\n            fieldNameFromStoreName(storeFieldName)\n          ] === true;\n\n        const hasMergeFunction = (storeFieldName: string) => {\n          const childTree = mergeTree && mergeTree.map.get(storeFieldName);\n          return Boolean(childTree && childTree.info && childTree.info.merge);\n        };\n\n        Object.keys(storeObject).forEach(storeFieldName => {\n          // If a merge function was defined for this field, trust that it\n          // did the right thing about (not) clobbering data. If the field\n          // has no selection set, it's a scalar field, so it doesn't need\n          // a merge function (even if it's an object, like JSON data).\n          if (hasSelectionSet(storeFieldName) &&\n              !hasMergeFunction(storeFieldName)) {\n            warnAboutDataLoss(\n              entityRef,\n              storeObject,\n              storeFieldName,\n              context.store,\n            );\n          }\n        });\n      }\n\n      store.merge(dataId, storeObject);\n    });\n\n    // Any IDs written explicitly to the cache will be retained as\n    // reachable root IDs for garbage collection purposes. Although this\n    // logic includes root IDs like ROOT_QUERY and ROOT_MUTATION, their\n    // retainment counts are effectively ignored because cache.gc() always\n    // includes them in its root ID set.\n    store.retain(ref.__ref);\n\n    return ref;\n  }\n\n  private processSelectionSet({\n    dataId,\n    result,\n    selectionSet,\n    context,\n    // This object allows processSelectionSet to report useful information\n    // to its callers without explicitly returning that information.\n    mergeTree,\n  }: ProcessSelectionSetOptions): StoreObject | Reference {\n    const { policies } = this.cache;\n\n    // This variable will be repeatedly updated using context.merge to\n    // accumulate all fields that need to be written into the store.\n    let incoming: StoreObject = Object.create(null);\n\n    // If typename was not passed in, infer it. Note that typename is\n    // always passed in for tricky-to-infer cases such as \"Query\" for\n    // ROOT_QUERY.\n    const typename: string | undefined =\n      (dataId && policies.rootTypenamesById[dataId]) ||\n      getTypenameFromResult(result, selectionSet, context.fragmentMap) ||\n      (dataId && context.store.get(dataId, \"__typename\") as string);\n\n    if (\"string\" === typeof typename) {\n      incoming.__typename = typename;\n    }\n\n    // This readField function will be passed as context.readField in the\n    // KeyFieldsContext object created within policies.identify (called below).\n    // In addition to reading from the existing context.store (thanks to the\n    // policies.readField(options, context) line at the very bottom), this\n    // version of readField can read from Reference objects that are currently\n    // pending in context.incomingById, which is important whenever keyFields\n    // need to be extracted from a child object that processSelectionSet has\n    // turned into a Reference.\n    const readField: ReadFieldFunction = function (this: void) {\n      const options = normalizeReadFieldOptions(\n        arguments,\n        incoming,\n        context.variables,\n      );\n\n      if (isReference(options.from)) {\n        const info = context.incomingById.get(options.from.__ref);\n        if (info) {\n          const result = policies.readField({\n            ...options,\n            from: info.storeObject\n          }, context);\n\n          if (result !== void 0) {\n            return result;\n          }\n        }\n      }\n\n      return policies.readField(options, context);\n    };\n\n    const fieldNodeSet = new Set<FieldNode>();\n\n    this.flattenFields(\n      selectionSet,\n      result,\n      // This WriteContext will be the default context value for fields returned\n      // by the flattenFields method, but some fields may be assigned a modified\n      // context, depending on the presence of @client and other directives.\n      context,\n      typename,\n    ).forEach((context, field) => {\n      const resultFieldKey = resultKeyNameFromField(field);\n      const value = result[resultFieldKey];\n\n      fieldNodeSet.add(field);\n\n      if (value !== void 0) {\n        const storeFieldName = policies.getStoreFieldName({\n          typename,\n          fieldName: field.name.value,\n          field,\n          variables: context.variables,\n        });\n\n        const childTree = getChildMergeTree(mergeTree, storeFieldName);\n\n        let incomingValue = this.processFieldValue(\n          value,\n          field,\n          // Reset context.clientOnly and context.deferred to their default\n          // values before processing nested selection sets.\n          field.selectionSet\n            ? getContextFlavor(context, false, false)\n            : context,\n          childTree,\n        );\n\n        // To determine if this field holds a child object with a merge function\n        // defined in its type policy (see PR #7070), we need to figure out the\n        // child object's __typename.\n        let childTypename: string | undefined;\n\n        // The field's value can be an object that has a __typename only if the\n        // field has a selection set. Otherwise incomingValue is scalar.\n        if (field.selectionSet &&\n            (isReference(incomingValue) ||\n             storeValueIsStoreObject(incomingValue))) {\n          childTypename = readField<string>(\"__typename\", incomingValue);\n        }\n\n        const merge = policies.getMergeFunction(\n          typename,\n          field.name.value,\n          childTypename,\n        );\n\n        if (merge) {\n          childTree.info = {\n            // TODO Check compatibility against any existing childTree.field?\n            field,\n            typename,\n            merge,\n          };\n        } else {\n          maybeRecycleChildMergeTree(mergeTree, storeFieldName);\n        }\n\n        incoming = context.merge(incoming, {\n          [storeFieldName]: incomingValue,\n        });\n\n      } else if (\n        __DEV__ &&\n        !context.clientOnly &&\n        !context.deferred &&\n        !addTypenameToDocument.added(field) &&\n        // If the field has a read function, it may be a synthetic field or\n        // provide a default value, so its absence from the written data should\n        // not be cause for alarm.\n        !policies.getReadFunction(typename, field.name.value)\n      ) {\n        invariant.error(`Missing field '${\n          resultKeyNameFromField(field)\n        }' while writing result ${\n          JSON.stringify(result, null, 2)\n        }`.substring(0, 1000));\n      }\n    });\n\n    // Identify the result object, even if dataId was already provided,\n    // since we always need keyObject below.\n    try {\n      const [id, keyObject] = policies.identify(result, {\n        typename,\n        selectionSet,\n        fragmentMap: context.fragmentMap,\n        storeObject: incoming,\n        readField,\n      });\n\n      // If dataId was not provided, fall back to the id just generated by\n      // policies.identify.\n      dataId = dataId || id;\n\n      // Write any key fields that were used during identification, even if\n      // they were not mentioned in the original query.\n      if (keyObject) {\n        // TODO Reverse the order of the arguments?\n        incoming = context.merge(incoming, keyObject);\n      }\n    } catch (e) {\n      // If dataId was provided, tolerate failure of policies.identify.\n      if (!dataId) throw e;\n    }\n\n    if (\"string\" === typeof dataId) {\n      const dataRef = makeReference(dataId);\n\n      // Avoid processing the same entity object using the same selection\n      // set more than once. We use an array instead of a Set since most\n      // entity IDs will be written using only one selection set, so the\n      // size of this array is likely to be very small, meaning indexOf is\n      // likely to be faster than Set.prototype.has.\n      const sets = context.written[dataId] || (context.written[dataId] = []);\n      if (sets.indexOf(selectionSet) >= 0) return dataRef;\n      sets.push(selectionSet);\n\n      // If we're about to write a result object into the store, but we\n      // happen to know that the exact same (===) result object would be\n      // returned if we were to reread the result with the same inputs,\n      // then we can skip the rest of the processSelectionSet work for\n      // this object, and immediately return a Reference to it.\n      if (this.reader && this.reader.isFresh(\n        result,\n        dataRef,\n        selectionSet,\n        context,\n      )) {\n        return dataRef;\n      }\n\n      const previous = context.incomingById.get(dataId);\n      if (previous) {\n        previous.storeObject = context.merge(previous.storeObject, incoming);\n        previous.mergeTree = mergeMergeTrees(previous.mergeTree, mergeTree);\n        fieldNodeSet.forEach(field => previous.fieldNodeSet.add(field));\n      } else {\n        context.incomingById.set(dataId, {\n          storeObject: incoming,\n          // Save a reference to mergeTree only if it is not empty, because\n          // empty MergeTrees may be recycled by maybeRecycleChildMergeTree and\n          // reused for entirely different parts of the result tree.\n          mergeTree: mergeTreeIsEmpty(mergeTree) ? void 0 : mergeTree,\n          fieldNodeSet,\n        });\n      }\n\n      return dataRef;\n    }\n\n    return incoming;\n  }\n\n  private processFieldValue(\n    value: any,\n    field: FieldNode,\n    context: WriteContext,\n    mergeTree: MergeTree,\n  ): StoreValue {\n    if (!field.selectionSet || value === null) {\n      // In development, we need to clone scalar values so that they can be\n      // safely frozen with maybeDeepFreeze in readFromStore.ts. In production,\n      // it's cheaper to store the scalar values directly in the cache.\n      return __DEV__ ? cloneDeep(value) : value;\n    }\n\n    if (isArray(value)) {\n      return value.map((item, i) => {\n        const value = this.processFieldValue(\n          item, field, context, getChildMergeTree(mergeTree, i));\n        maybeRecycleChildMergeTree(mergeTree, i);\n        return value;\n      });\n    }\n\n    return this.processSelectionSet({\n      result: value,\n      selectionSet: field.selectionSet,\n      context,\n      mergeTree,\n    });\n  }\n\n  // Implements https://spec.graphql.org/draft/#sec-Field-Collection, but with\n  // some additions for tracking @client and @defer directives.\n  private flattenFields<TContext extends Pick<\n    WriteContext,\n    | \"clientOnly\"\n    | \"deferred\"\n    | \"flavors\"\n    | \"fragmentMap\"\n    | \"variables\"\n  >>(\n    selectionSet: SelectionSetNode,\n    result: Record<string, any>,\n    context: TContext,\n    typename = getTypenameFromResult(result, selectionSet, context.fragmentMap),\n  ): Map<FieldNode, TContext> {\n    const fieldMap = new Map<FieldNode, TContext>();\n    const { policies } = this.cache;\n\n    const limitingTrie = new Trie<{\n      // Tracks whether (selectionSet, clientOnly, deferred) has been flattened\n      // before. The GraphQL specification only uses the fragment name for\n      // skipping previously visited fragments, but the top-level fragment\n      // selection set corresponds 1:1 with the fagment name (and is slightly\n      // easier too work with), and we need to consider clientOnly and deferred\n      // values as well, potentially revisiting selection sets that were\n      // previously visited with different inherited configurations of those\n      // directives.\n      visited?: boolean;\n    }>(false); // No need for WeakMap, since limitingTrie does not escape.\n\n    (function flatten(\n      this: void,\n      selectionSet: SelectionSetNode,\n      inheritedContext: TContext,\n    ) {\n      const visitedNode = limitingTrie.lookup(\n        selectionSet,\n        // Because we take inheritedClientOnly and inheritedDeferred into\n        // consideration here (in addition to selectionSet), it's possible for\n        // the same selection set to be flattened more than once, if it appears\n        // in the query with different @client and/or @directive configurations.\n        inheritedContext.clientOnly,\n        inheritedContext.deferred,\n      );\n      if (visitedNode.visited) return;\n      visitedNode.visited = true;\n\n      selectionSet.selections.forEach(selection => {\n        if (!shouldInclude(selection, context.variables)) return;\n\n        let { clientOnly, deferred } = inheritedContext;\n        if (\n          // Since the presence of @client or @defer on this field can only\n          // cause clientOnly or deferred to become true, we can skip the\n          // forEach loop if both clientOnly and deferred are already true.\n          !(clientOnly && deferred) &&\n          isNonEmptyArray(selection.directives)\n        ) {\n          selection.directives.forEach(dir => {\n            const name = dir.name.value;\n            if (name === \"client\") clientOnly = true;\n            if (name === \"defer\") {\n              const args = argumentsObjectFromField(dir, context.variables);\n              // The @defer directive takes an optional args.if boolean\n              // argument, similar to @include(if: boolean). Note that\n              // @defer(if: false) does not make context.deferred false, but\n              // instead behaves as if there was no @defer directive.\n              if (!args || (args as { if?: boolean }).if !== false) {\n                deferred = true;\n              }\n              // TODO In the future, we may want to record args.label using\n              // context.deferred, if a label is specified.\n            }\n          });\n        }\n\n        if (isField(selection)) {\n          const existing = fieldMap.get(selection);\n          if (existing) {\n            // If this field has been visited along another recursive path\n            // before, the final context should have clientOnly or deferred set\n            // to true only if *all* paths have the directive (hence the &&).\n            clientOnly = clientOnly && existing.clientOnly;\n            deferred = deferred && existing.deferred;\n          }\n\n          fieldMap.set(\n            selection,\n            getContextFlavor(context, clientOnly, deferred),\n          );\n\n        } else {\n          const fragment =\n            getFragmentFromSelection(selection, context.fragmentMap);\n\n          if (fragment &&\n              policies.fragmentMatches(\n                fragment, typename, result, context.variables)) {\n\n            flatten(\n              fragment.selectionSet,\n              getContextFlavor(context, clientOnly, deferred),\n            );\n          }\n        }\n      });\n    })(selectionSet, context);\n\n    return fieldMap;\n  }\n\n  private applyMerges<T extends StoreValue>(\n    mergeTree: MergeTree,\n    existing: StoreValue,\n    incoming: T,\n    context: WriteContext,\n    getStorageArgs?: Parameters<EntityStore[\"getStorage\"]>,\n  ): T | Reference {\n    if (mergeTree.map.size && !isReference(incoming)) {\n      const e: StoreObject | Reference | undefined = (\n        // Items in the same position in different arrays are not\n        // necessarily related to each other, so when incoming is an array\n        // we process its elements as if there was no existing data.\n        !isArray(incoming) &&\n        // Likewise, existing must be either a Reference or a StoreObject\n        // in order for its fields to be safe to merge with the fields of\n        // the incoming object.\n        (isReference(existing) || storeValueIsStoreObject(existing))\n      ) ? existing : void 0;\n\n      // This narrowing is implied by mergeTree.map.size > 0 and\n      // !isReference(incoming), though TypeScript understandably cannot\n      // hope to infer this type.\n      const i = incoming as StoreObject | StoreValue[];\n\n      // The options.storage objects provided to read and merge functions\n      // are derived from the identity of the parent object plus a\n      // sequence of storeFieldName strings/numbers identifying the nested\n      // field name path of each field value to be merged.\n      if (e && !getStorageArgs) {\n        getStorageArgs = [isReference(e) ? e.__ref : e];\n      }\n\n      // It's possible that applying merge functions to this subtree will\n      // not change the incoming data, so this variable tracks the fields\n      // that did change, so we can create a new incoming object when (and\n      // only when) at least one incoming field has changed. We use a Map\n      // to preserve the type of numeric keys.\n      let changedFields: Map<string | number, StoreValue> | undefined;\n\n      const getValue = (\n        from: typeof e | typeof i,\n        name: string | number,\n      ): StoreValue => {\n        return isArray(from)\n          ? (typeof name === \"number\" ? from[name] : void 0)\n          : context.store.getFieldValue(from, String(name))\n      };\n\n      mergeTree.map.forEach((childTree, storeFieldName) => {\n        const eVal = getValue(e, storeFieldName);\n        const iVal = getValue(i, storeFieldName);\n        // If we have no incoming data, leave any existing data untouched.\n        if (void 0 === iVal) return;\n        if (getStorageArgs) {\n          getStorageArgs.push(storeFieldName);\n        }\n        const aVal = this.applyMerges(\n          childTree,\n          eVal,\n          iVal,\n          context,\n          getStorageArgs,\n        );\n        if (aVal !== iVal) {\n          changedFields = changedFields || new Map;\n          changedFields.set(storeFieldName, aVal);\n        }\n        if (getStorageArgs) {\n          invariant(getStorageArgs.pop() === storeFieldName);\n        }\n      });\n\n      if (changedFields) {\n        // Shallow clone i so we can add changed fields to it.\n        incoming = (isArray(i) ? i.slice(0) : { ...i }) as T;\n        changedFields.forEach((value, name) => {\n          (incoming as any)[name] = value;\n        });\n      }\n    }\n\n    if (mergeTree.info) {\n      return this.cache.policies.runMergeFunction(\n        existing,\n        incoming,\n        mergeTree.info,\n        context,\n        getStorageArgs && context.store.getStorage(...getStorageArgs),\n      );\n    }\n\n    return incoming;\n  }\n}\n\nconst emptyMergeTreePool: MergeTree[] = [];\n\nfunction getChildMergeTree(\n  { map }: MergeTree,\n  name: string | number,\n): MergeTree {\n  if (!map.has(name)) {\n    map.set(name, emptyMergeTreePool.pop() || { map: new Map });\n  }\n  return map.get(name)!;\n}\n\nfunction mergeMergeTrees(\n  left: MergeTree | undefined,\n  right: MergeTree | undefined,\n): MergeTree {\n  if (left === right || !right || mergeTreeIsEmpty(right)) return left!;\n  if (!left || mergeTreeIsEmpty(left)) return right;\n\n  const info = left.info && right.info ? {\n    ...left.info,\n    ...right.info,\n  } : left.info || right.info;\n\n  const needToMergeMaps = left.map.size && right.map.size;\n  const map = needToMergeMaps ? new Map :\n    left.map.size ? left.map : right.map;\n\n  const merged = { info, map };\n\n  if (needToMergeMaps) {\n    const remainingRightKeys = new Set(right.map.keys());\n\n    left.map.forEach((leftTree, key) => {\n      merged.map.set(\n        key,\n        mergeMergeTrees(leftTree, right.map.get(key)),\n      );\n      remainingRightKeys.delete(key);\n    });\n\n    remainingRightKeys.forEach(key => {\n      merged.map.set(\n        key,\n        mergeMergeTrees(\n          right.map.get(key),\n          left.map.get(key),\n        ),\n      );\n    });\n  }\n\n  return merged;\n}\n\nfunction mergeTreeIsEmpty(tree: MergeTree | undefined): boolean {\n  return !tree || !(tree.info || tree.map.size);\n}\n\nfunction maybeRecycleChildMergeTree(\n  { map }: MergeTree,\n  name: string | number,\n) {\n  const childTree = map.get(name);\n  if (childTree && mergeTreeIsEmpty(childTree)) {\n    emptyMergeTreePool.push(childTree);\n    map.delete(name);\n  }\n}\n\nconst warnings = new Set<string>();\n\n// Note that this function is unused in production, and thus should be\n// pruned by any well-configured minifier.\nfunction warnAboutDataLoss(\n  existingRef: Reference,\n  incomingObj: StoreObject,\n  storeFieldName: string,\n  store: NormalizedCache,\n) {\n  const getChild = (objOrRef: StoreObject | Reference): StoreObject | false => {\n    const child = store.getFieldValue<StoreObject>(objOrRef, storeFieldName);\n    return typeof child === \"object\" && child;\n  };\n\n  const existing = getChild(existingRef);\n  if (!existing) return;\n\n  const incoming = getChild(incomingObj);\n  if (!incoming) return;\n\n  // It's always safe to replace a reference, since it refers to data\n  // safely stored elsewhere.\n  if (isReference(existing)) return;\n\n  // If the values are structurally equivalent, we do not need to worry\n  // about incoming replacing existing.\n  if (equal(existing, incoming)) return;\n\n  // If we're replacing every key of the existing object, then the\n  // existing data would be overwritten even if the objects were\n  // normalized, so warning would not be helpful here.\n  if (Object.keys(existing).every(\n    key => store.getFieldValue(incoming, key) !== void 0)) {\n    return;\n  }\n\n  const parentType =\n    store.getFieldValue<string>(existingRef, \"__typename\") ||\n    store.getFieldValue<string>(incomingObj, \"__typename\");\n  const fieldName = fieldNameFromStoreName(storeFieldName);\n  const typeDotName = `${parentType}.${fieldName}`;\n  // Avoid warning more than once for the same type and field name.\n  if (warnings.has(typeDotName)) return;\n  warnings.add(typeDotName);\n\n  const childTypenames: string[] = [];\n  // Arrays do not have __typename fields, and always need a custom merge\n  // function, even if their elements are normalized entities.\n  if (!isArray(existing) &&\n      !isArray(incoming)) {\n    [existing, incoming].forEach(child => {\n      const typename = store.getFieldValue(child, \"__typename\");\n      if (typeof typename === \"string\" &&\n          !childTypenames.includes(typename)) {\n        childTypenames.push(typename);\n      }\n    });\n  }\n\n  invariant.warn(\n`Cache data may be lost when replacing the ${fieldName} field of a ${parentType} object.\n\nTo address this problem (which is not a bug in Apollo Client), ${\n  childTypenames.length\n    ? \"either ensure all objects of type \" +\n        childTypenames.join(\" and \") + \" have an ID or a custom merge function, or \"\n    : \"\"\n}define a custom merge function for the ${\n  typeDotName\n} field, so InMemoryCache can safely merge these objects:\n\n  existing: ${JSON.stringify(existing).slice(0, 1000)}\n  incoming: ${JSON.stringify(incoming).slice(0, 1000)}\n\nFor more information about these options, please refer to the documentation:\n\n  * Ensuring entity objects have IDs: https://go.apollo.dev/c/generating-unique-identifiers\n  * Defining custom merge functions: https://go.apollo.dev/c/merging-non-normalized-objects\n`);\n}\n", "import { invariant } from '../../utilities/globals';\n\n// Make builtins like Map and Set safe to use with non-extensible objects.\nimport './fixPolyfills';\n\nimport { DocumentNode } from 'graphql';\nimport { OptimisticWrapperFunction, wrap } from 'optimism';\nimport { equal } from '@wry/equality';\n\nimport { ApolloCache } from '../core/cache';\nimport { Cache } from '../core/types/Cache';\nimport { MissingFieldError } from '../core/types/common';\nimport {\n  addTypenameToDocument,\n  StoreObject,\n  Reference,\n  isReference,\n} from '../../utilities';\nimport { InMemoryCacheConfig, NormalizedCacheObject } from './types';\nimport { StoreReader } from './readFromStore';\nimport { StoreWriter } from './writeToStore';\nimport { EntityStore, supportsResultCaching } from './entityStore';\nimport { makeVar, forgetCache, recallCache } from './reactiveVars';\nimport { Policies } from './policies';\nimport { hasOwn, normalizeConfig, shouldCanonizeResults } from './helpers';\nimport { canonicalStringify } from './object-canon';\n\ntype BroadcastOptions = Pick<\n  Cache.BatchOptions<InMemoryCache>,\n  | \"optimistic\"\n  | \"onWatchUpdated\"\n>\n\nexport class InMemoryCache extends ApolloCache<NormalizedCacheObject> {\n  private data: EntityStore;\n  private optimisticData: EntityStore;\n\n  protected config: InMemoryCacheConfig;\n  private watches = new Set<Cache.WatchOptions>();\n  private addTypename: boolean;\n\n  private typenameDocumentCache = new Map<DocumentNode, DocumentNode>();\n  private storeReader: StoreReader;\n  private storeWriter: StoreWriter;\n\n  private maybeBroadcastWatch: OptimisticWrapperFunction<\n    [Cache.WatchOptions, BroadcastOptions?],\n    any,\n    [Cache.WatchOptions]>;\n\n  // Dynamically imported code can augment existing typePolicies or\n  // possibleTypes by calling cache.policies.addTypePolicies or\n  // cache.policies.addPossibletypes.\n  public readonly policies: Policies;\n\n  public readonly makeVar = makeVar;\n\n  constructor(config: InMemoryCacheConfig = {}) {\n    super();\n    this.config = normalizeConfig(config);\n    this.addTypename = !!this.config.addTypename;\n\n    this.policies = new Policies({\n      cache: this,\n      dataIdFromObject: this.config.dataIdFromObject,\n      possibleTypes: this.config.possibleTypes,\n      typePolicies: this.config.typePolicies,\n    });\n\n    this.init();\n  }\n\n  private init() {\n    // Passing { resultCaching: false } in the InMemoryCache constructor options\n    // will completely disable dependency tracking, which will improve memory\n    // usage but worsen the performance of repeated reads.\n    const rootStore = this.data = new EntityStore.Root({\n      policies: this.policies,\n      resultCaching: this.config.resultCaching,\n    });\n\n    // When no optimistic writes are currently active, cache.optimisticData ===\n    // cache.data, so there are no additional layers on top of the actual data.\n    // When an optimistic update happens, this.optimisticData will become a\n    // linked list of EntityStore Layer objects that terminates with the\n    // original this.data cache object.\n    this.optimisticData = rootStore.stump;\n\n    this.resetResultCache();\n  }\n\n  private resetResultCache(resetResultIdentities?: boolean) {\n    const previousReader = this.storeReader;\n\n    // The StoreWriter is mostly stateless and so doesn't really need to be\n    // reset, but it does need to have its writer.storeReader reference updated,\n    // so it's simpler to update this.storeWriter as well.\n    this.storeWriter = new StoreWriter(\n      this,\n      this.storeReader = new StoreReader({\n        cache: this,\n        addTypename: this.addTypename,\n        resultCacheMaxSize: this.config.resultCacheMaxSize,\n        canonizeResults: shouldCanonizeResults(this.config),\n        canon: resetResultIdentities\n          ? void 0\n          : previousReader && previousReader.canon,\n      }),\n    );\n\n    this.maybeBroadcastWatch = wrap((\n      c: Cache.WatchOptions,\n      options?: BroadcastOptions,\n    ) => {\n      return this.broadcastWatch(c, options);\n    }, {\n      max: this.config.resultCacheMaxSize,\n      makeCacheKey: (c: Cache.WatchOptions) => {\n        // Return a cache key (thus enabling result caching) only if we're\n        // currently using a data store that can track cache dependencies.\n        const store = c.optimistic ? this.optimisticData : this.data;\n        if (supportsResultCaching(store)) {\n          const { optimistic, rootId, variables } = c;\n          return store.makeCacheKey(\n            c.query,\n            // Different watches can have the same query, optimistic\n            // status, rootId, and variables, but if their callbacks are\n            // different, the (identical) result needs to be delivered to\n            // each distinct callback. The easiest way to achieve that\n            // separation is to include c.callback in the cache key for\n            // maybeBroadcastWatch calls. See issue #5733.\n            c.callback,\n            canonicalStringify({ optimistic, rootId, variables }),\n          );\n        }\n      }\n    });\n\n    // Since we have thrown away all the cached functions that depend on the\n    // CacheGroup dependencies maintained by EntityStore, we should also reset\n    // all CacheGroup dependency information.\n    new Set([\n      this.data.group,\n      this.optimisticData.group,\n    ]).forEach(group => group.resetCaching());\n  }\n\n  public restore(data: NormalizedCacheObject): this {\n    this.init();\n    // Since calling this.init() discards/replaces the entire StoreReader, along\n    // with the result caches it maintains, this.data.replace(data) won't have\n    // to bother deleting the old data.\n    if (data) this.data.replace(data);\n    return this;\n  }\n\n  public extract(optimistic: boolean = false): NormalizedCacheObject {\n    return (optimistic ? this.optimisticData : this.data).extract();\n  }\n\n  public read<T>(options: Cache.ReadOptions): T | null {\n    const {\n      // Since read returns data or null, without any additional metadata\n      // about whether/where there might have been missing fields, the\n      // default behavior cannot be returnPartialData = true (like it is\n      // for the diff method), since defaulting to true would violate the\n      // integrity of the T in the return type. However, partial data may\n      // be useful in some cases, so returnPartialData:true may be\n      // specified explicitly.\n      returnPartialData = false,\n    } = options;\n    try {\n      return this.storeReader.diffQueryAgainstStore<T>({\n        ...options,\n        store: options.optimistic ? this.optimisticData : this.data,\n        config: this.config,\n        returnPartialData,\n      }).result || null;\n    } catch (e) {\n      if (e instanceof MissingFieldError) {\n        // Swallow MissingFieldError and return null, so callers do not\n        // need to worry about catching \"normal\" exceptions resulting from\n        // incomplete cache data. Unexpected errors will be re-thrown. If\n        // you need more information about which fields were missing, use\n        // cache.diff instead, and examine diffResult.missing.\n        return null;\n      }\n      throw e;\n    }\n  }\n\n  public write(options: Cache.WriteOptions): Reference | undefined {\n    try {\n      ++this.txCount;\n      return this.storeWriter.writeToStore(this.data, options);\n    } finally {\n      if (!--this.txCount && options.broadcast !== false) {\n        this.broadcastWatches();\n      }\n    }\n  }\n\n  public modify(options: Cache.ModifyOptions): boolean {\n    if (hasOwn.call(options, \"id\") && !options.id) {\n      // To my knowledge, TypeScript does not currently provide a way to\n      // enforce that an optional property?:type must *not* be undefined\n      // when present. That ability would be useful here, because we want\n      // options.id to default to ROOT_QUERY only when no options.id was\n      // provided. If the caller attempts to pass options.id with a\n      // falsy/undefined value (perhaps because cache.identify failed), we\n      // should not assume the goal was to modify the ROOT_QUERY object.\n      // We could throw, but it seems natural to return false to indicate\n      // that nothing was modified.\n      return false;\n    }\n    const store = options.optimistic // Defaults to false.\n      ? this.optimisticData\n      : this.data;\n    try {\n      ++this.txCount;\n      return store.modify(options.id || \"ROOT_QUERY\", options.fields);\n    } finally {\n      if (!--this.txCount && options.broadcast !== false) {\n        this.broadcastWatches();\n      }\n    }\n  }\n\n  public diff<TData, TVariables = any>(\n    options: Cache.DiffOptions<TData, TVariables>,\n  ): Cache.DiffResult<TData> {\n    return this.storeReader.diffQueryAgainstStore({\n      ...options,\n      store: options.optimistic ? this.optimisticData : this.data,\n      rootId: options.id || \"ROOT_QUERY\",\n      config: this.config,\n    });\n  }\n\n  public watch<TData = any, TVariables = any>(\n    watch: Cache.WatchOptions<TData, TVariables>,\n  ): () => void {\n    if (!this.watches.size) {\n      // In case we previously called forgetCache(this) because\n      // this.watches became empty (see below), reattach this cache to any\n      // reactive variables on which it previously depended. It might seem\n      // paradoxical that we're able to recall something we supposedly\n      // forgot, but the point of calling forgetCache(this) is to silence\n      // useless broadcasts while this.watches is empty, and to allow the\n      // cache to be garbage collected. If, however, we manage to call\n      // recallCache(this) here, this cache object must not have been\n      // garbage collected yet, and should resume receiving updates from\n      // reactive variables, now that it has a watcher to notify.\n      recallCache(this);\n    }\n    this.watches.add(watch);\n    if (watch.immediate) {\n      this.maybeBroadcastWatch(watch);\n    }\n    return () => {\n      // Once we remove the last watch from this.watches, cache.broadcastWatches\n      // no longer does anything, so we preemptively tell the reactive variable\n      // system to exclude this cache from future broadcasts.\n      if (this.watches.delete(watch) && !this.watches.size) {\n        forgetCache(this);\n      }\n      // Remove this watch from the LRU cache managed by the\n      // maybeBroadcastWatch OptimisticWrapperFunction, to prevent memory\n      // leaks involving the closure of watch.callback.\n      this.maybeBroadcastWatch.forget(watch);\n    };\n  }\n\n  public gc(options?: {\n    // If true, also free non-essential result cache memory by bulk-releasing\n    // this.{store{Reader,Writer},maybeBroadcastWatch}. Defaults to false.\n    resetResultCache?: boolean;\n    // If resetResultCache is true, this.storeReader.canon will be preserved by\n    // default, but can also be discarded by passing resetResultIdentities:true.\n    // Defaults to false.\n    resetResultIdentities?: boolean;\n  }) {\n    canonicalStringify.reset();\n    const ids = this.optimisticData.gc();\n    if (options && !this.txCount) {\n      if (options.resetResultCache) {\n        this.resetResultCache(options.resetResultIdentities);\n      } else if (options.resetResultIdentities) {\n        this.storeReader.resetCanon();\n      }\n    }\n    return ids;\n  }\n\n  // Call this method to ensure the given root ID remains in the cache after\n  // garbage collection, along with its transitive child entities. Note that\n  // the cache automatically retains all directly written entities. By default,\n  // the retainment persists after optimistic updates are removed. Pass true\n  // for the optimistic argument if you would prefer for the retainment to be\n  // discarded when the top-most optimistic layer is removed. Returns the\n  // resulting (non-negative) retainment count.\n  public retain(rootId: string, optimistic?: boolean): number {\n    return (optimistic ? this.optimisticData : this.data).retain(rootId);\n  }\n\n  // Call this method to undo the effect of the retain method, above. Once the\n  // retainment count falls to zero, the given ID will no longer be preserved\n  // during garbage collection, though it may still be preserved by other safe\n  // entities that refer to it. Returns the resulting (non-negative) retainment\n  // count, in case that's useful.\n  public release(rootId: string, optimistic?: boolean): number {\n    return (optimistic ? this.optimisticData : this.data).release(rootId);\n  }\n\n  // Returns the canonical ID for a given StoreObject, obeying typePolicies\n  // and keyFields (and dataIdFromObject, if you still use that). At minimum,\n  // the object must contain a __typename and any primary key fields required\n  // to identify entities of that type. If you pass a query result object, be\n  // sure that none of the primary key fields have been renamed by aliasing.\n  // If you pass a Reference object, its __ref ID string will be returned.\n  public identify(object: StoreObject | Reference): string | undefined {\n    if (isReference(object)) return object.__ref;\n    try {\n      return this.policies.identify(object)[0];\n    } catch (e) {\n      invariant.warn(e);\n    }\n  }\n\n  public evict(options: Cache.EvictOptions): boolean {\n    if (!options.id) {\n      if (hasOwn.call(options, \"id\")) {\n        // See comment in modify method about why we return false when\n        // options.id exists but is falsy/undefined.\n        return false;\n      }\n      options = { ...options, id: \"ROOT_QUERY\" };\n    }\n    try {\n      // It's unlikely that the eviction will end up invoking any other\n      // cache update operations while it's running, but {in,de}crementing\n      // this.txCount still seems like a good idea, for uniformity with\n      // the other update methods.\n      ++this.txCount;\n      // Pass this.data as a limit on the depth of the eviction, so evictions\n      // during optimistic updates (when this.data is temporarily set equal to\n      // this.optimisticData) do not escape their optimistic Layer.\n      return this.optimisticData.evict(options, this.data);\n    } finally {\n      if (!--this.txCount && options.broadcast !== false) {\n        this.broadcastWatches();\n      }\n    }\n  }\n\n  public reset(options?: Cache.ResetOptions): Promise<void> {\n    this.init();\n\n    canonicalStringify.reset();\n\n    if (options && options.discardWatches) {\n      // Similar to what happens in the unsubscribe function returned by\n      // cache.watch, applied to all current watches.\n      this.watches.forEach(watch => this.maybeBroadcastWatch.forget(watch));\n      this.watches.clear();\n      forgetCache(this);\n    } else {\n      // Calling this.init() above unblocks all maybeBroadcastWatch caching, so\n      // this.broadcastWatches() triggers a broadcast to every current watcher\n      // (letting them know their data is now missing). This default behavior is\n      // convenient because it means the watches do not have to be manually\n      // reestablished after resetting the cache. To prevent this broadcast and\n      // cancel all watches, pass true for options.discardWatches.\n      this.broadcastWatches();\n    }\n\n    return Promise.resolve();\n  }\n\n  public removeOptimistic(idToRemove: string) {\n    const newOptimisticData = this.optimisticData.removeLayer(idToRemove);\n    if (newOptimisticData !== this.optimisticData) {\n      this.optimisticData = newOptimisticData;\n      this.broadcastWatches();\n    }\n  }\n\n  private txCount = 0;\n\n  public batch<TUpdateResult>(\n    options: Cache.BatchOptions<InMemoryCache, TUpdateResult>,\n  ): TUpdateResult {\n    const {\n      update,\n      optimistic = true,\n      removeOptimistic,\n      onWatchUpdated,\n    } = options;\n\n    let updateResult: TUpdateResult;\n    const perform = (layer?: EntityStore): TUpdateResult => {\n      const { data, optimisticData } = this;\n      ++this.txCount;\n      if (layer) {\n        this.data = this.optimisticData = layer;\n      }\n      try {\n        return updateResult = update(this);\n      } finally {\n        --this.txCount;\n        this.data = data;\n        this.optimisticData = optimisticData;\n      }\n    };\n\n    const alreadyDirty = new Set<Cache.WatchOptions>();\n\n    if (onWatchUpdated && !this.txCount) {\n      // If an options.onWatchUpdated callback is provided, we want to call it\n      // with only the Cache.WatchOptions objects affected by options.update,\n      // but there might be dirty watchers already waiting to be broadcast that\n      // have nothing to do with the update. To prevent including those watchers\n      // in the post-update broadcast, we perform this initial broadcast to\n      // collect the dirty watchers, so we can re-dirty them later, after the\n      // post-update broadcast, allowing them to receive their pending\n      // broadcasts the next time broadcastWatches is called, just as they would\n      // if we never called cache.batch.\n      this.broadcastWatches({\n        ...options,\n        onWatchUpdated(watch) {\n          alreadyDirty.add(watch);\n          return false;\n        },\n      });\n    }\n\n    if (typeof optimistic === 'string') {\n      // Note that there can be multiple layers with the same optimistic ID.\n      // When removeOptimistic(id) is called for that id, all matching layers\n      // will be removed, and the remaining layers will be reapplied.\n      this.optimisticData = this.optimisticData.addLayer(optimistic, perform);\n    } else if (optimistic === false) {\n      // Ensure both this.data and this.optimisticData refer to the root\n      // (non-optimistic) layer of the cache during the update. Note that\n      // this.data could be a Layer if we are currently executing an optimistic\n      // update function, but otherwise will always be an EntityStore.Root\n      // instance.\n      perform(this.data);\n    } else {\n      // Otherwise, leave this.data and this.optimisticData unchanged and run\n      // the update with broadcast batching.\n      perform();\n    }\n\n    if (typeof removeOptimistic === \"string\") {\n      this.optimisticData = this.optimisticData.removeLayer(removeOptimistic);\n    }\n\n    // Note: if this.txCount > 0, then alreadyDirty.size === 0, so this code\n    // takes the else branch and calls this.broadcastWatches(options), which\n    // does nothing when this.txCount > 0.\n    if (onWatchUpdated && alreadyDirty.size) {\n      this.broadcastWatches({\n        ...options,\n        onWatchUpdated(watch, diff) {\n          const result = onWatchUpdated.call(this, watch, diff);\n          if (result !== false) {\n            // Since onWatchUpdated did not return false, this diff is\n            // about to be broadcast to watch.callback, so we don't need\n            // to re-dirty it with the other alreadyDirty watches below.\n            alreadyDirty.delete(watch);\n          }\n          return result;\n        }\n      });\n      // Silently re-dirty any watches that were already dirty before the update\n      // was performed, and were not broadcast just now.\n      if (alreadyDirty.size) {\n        alreadyDirty.forEach(watch => this.maybeBroadcastWatch.dirty(watch));\n      }\n    } else {\n      // If alreadyDirty is empty or we don't have an onWatchUpdated\n      // function, we don't need to go to the trouble of wrapping\n      // options.onWatchUpdated.\n      this.broadcastWatches(options);\n    }\n\n    return updateResult!;\n  }\n\n  public performTransaction(\n    update: (cache: InMemoryCache) => any,\n    optimisticId?: string | null,\n  ) {\n    return this.batch({\n      update,\n      optimistic: optimisticId || (optimisticId !== null),\n    });\n  }\n\n  public transformDocument(document: DocumentNode): DocumentNode {\n    if (this.addTypename) {\n      let result = this.typenameDocumentCache.get(document);\n      if (!result) {\n        result = addTypenameToDocument(document);\n        this.typenameDocumentCache.set(document, result);\n        // If someone calls transformDocument and then mistakenly passes the\n        // result back into an API that also calls transformDocument, make sure\n        // we don't keep creating new query documents.\n        this.typenameDocumentCache.set(result, result);\n      }\n      return result;\n    }\n    return document;\n  }\n\n  protected broadcastWatches(options?: BroadcastOptions) {\n    if (!this.txCount) {\n      this.watches.forEach(c => this.maybeBroadcastWatch(c, options));\n    }\n  }\n\n  // This method is wrapped by maybeBroadcastWatch, which is called by\n  // broadcastWatches, so that we compute and broadcast results only when\n  // the data that would be broadcast might have changed. It would be\n  // simpler to check for changes after recomputing a result but before\n  // broadcasting it, but this wrapping approach allows us to skip both\n  // the recomputation and the broadcast, in most cases.\n  private broadcastWatch(\n    c: Cache.WatchOptions,\n    options?: BroadcastOptions,\n  ) {\n    const { lastDiff } = c;\n\n    // Both WatchOptions and DiffOptions extend ReadOptions, and DiffOptions\n    // currently requires no additional properties, so we can use c (a\n    // WatchOptions object) as DiffOptions, without having to allocate a new\n    // object, and without having to enumerate the relevant properties (query,\n    // variables, etc.) explicitly. There will be some additional properties\n    // (lastDiff, callback, etc.), but cache.diff ignores them.\n    const diff = this.diff<any>(c);\n\n    if (options) {\n      if (c.optimistic &&\n          typeof options.optimistic === \"string\") {\n        diff.fromOptimisticTransaction = true;\n      }\n\n      if (options.onWatchUpdated &&\n          options.onWatchUpdated.call(this, c, diff, lastDiff) === false) {\n        // Returning false from the onWatchUpdated callback will prevent\n        // calling c.callback(diff) for this watcher.\n        return;\n      }\n    }\n\n    if (!lastDiff || !equal(lastDiff.result, diff.result)) {\n      c.callback(c.lastDiff = diff, lastDiff);\n    }\n  }\n}\n", "import '../utilities/globals';\n\nimport { GraphQLError } from 'graphql';\n\nimport { isNonEmptyArray } from '../utilities';\nimport { ServerParseError } from '../link/http';\nimport { ServerError } from '../link/utils';\n\nexport function isApolloError(err: Error): err is ApolloError {\n  return err.hasOwnProperty('graphQLErrors');\n}\n\n// Sets the error message on this error according to the\n// the GraphQL and network errors that are present.\n// If the error message has already been set through the\n// constructor or otherwise, this function is a nop.\nconst generateErrorMessage = (err: ApolloError) => {\n  let message = '';\n  // If we have GraphQL errors present, add that to the error message.\n  if (isNonEmptyArray(err.graphQLErrors) || isNonEmptyArray(err.clientErrors)) {\n    const errors = ((err.graphQLErrors || []) as readonly Error[])\n      .concat(err.clientErrors || []);\n    errors.forEach((error: Error) => {\n      const errorMessage = error\n        ? error.message\n        : 'Error message not found.';\n      message += `${errorMessage}\\n`;\n    });\n  }\n\n  if (err.networkError) {\n    message += `${err.networkError.message}\\n`;\n  }\n\n  // strip newline from the end of the message\n  message = message.replace(/\\n$/, '');\n  return message;\n};\n\nexport type GraphQLErrors = ReadonlyArray<GraphQLError>;\n\nexport type NetworkError = Error | ServerParseError | ServerError | null;\n\nexport class ApolloError extends Error {\n  public message: string;\n  public graphQLErrors: GraphQLErrors;\n  public clientErrors: ReadonlyArray<Error>;\n  public networkError: Error | ServerParseError | ServerError | null;\n\n  // An object that can be used to provide some additional information\n  // about an error, e.g. specifying the type of error this is. Used\n  // internally within Apollo Client.\n  public extraInfo: any;\n\n  // Constructs an instance of ApolloError given a GraphQLError\n  // or a network error. Note that one of these has to be a valid\n  // value or the constructed error will be meaningless.\n  constructor({\n    graphQLErrors,\n    clientErrors,\n    networkError,\n    errorMessage,\n    extraInfo,\n  }: {\n    graphQLErrors?: ReadonlyArray<GraphQLError>;\n    clientErrors?: ReadonlyArray<Error>;\n    networkError?: Error | ServerParseError | ServerError | null;\n    errorMessage?: string;\n    extraInfo?: any;\n  }) {\n    super(errorMessage);\n    this.graphQLErrors = graphQLErrors || [];\n    this.clientErrors = clientErrors || [];\n    this.networkError = networkError || null;\n    this.message = errorMessage || generateErrorMessage(this);\n    this.extraInfo = extraInfo;\n\n    // We're not using `Object.setPrototypeOf` here as it isn't fully\n    // supported on Android (see issue #3236).\n    (this as any).__proto__ = ApolloError.prototype;\n  }\n}\n", "/**\n * The current status of a query\u2019s execution in our system.\n */\nexport enum NetworkStatus {\n  /**\n   * The query has never been run before and the query is now currently running. A query will still\n   * have this network status even if a partial data result was returned from the cache, but a\n   * query was dispatched anyway.\n   */\n  loading = 1,\n\n  /**\n   * If `setVariables` was called and a query was fired because of that then the network status\n   * will be `setVariables` until the result of that query comes back.\n   */\n  setVariables = 2,\n\n  /**\n   * Indicates that `fetchMore` was called on this query and that the query created is currently in\n   * flight.\n   */\n  fetchMore = 3,\n\n  /**\n   * Similar to the `setVariables` network status. It means that `refetch` was called on a query\n   * and the refetch request is currently in flight.\n   */\n  refetch = 4,\n\n  /**\n   * Indicates that a polling query is currently in flight. So for example if you are polling a\n   * query every 10 seconds then the network status will switch to `poll` every 10 seconds whenever\n   * a poll request has been sent but not resolved.\n   */\n  poll = 6,\n\n  /**\n   * No request is in flight for this query, and no errors happened. Everything is OK.\n   */\n  ready = 7,\n\n  /**\n   * No request is in flight for this query, but one or more errors were detected.\n   */\n  error = 8,\n}\n\n/**\n * Returns true if there is currently a network request in flight according to a given network\n * status.\n */\nexport function isNetworkRequestInFlight(\n  networkStatus?: NetworkStatus,\n): boolean {\n  return networkStatus ? networkStatus < 7 : false;\n}\n", "import { invariant } from '../utilities/globals';\n\nimport { equal } from '@wry/equality';\n\nimport { NetworkStatus, isNetworkRequestInFlight } from './networkStatus';\nimport {\n  Concast,\n  compact,\n  cloneDeep,\n  getOperationDefinition,\n  Observable,\n  Observer,\n  ObservableSubscription,\n  iterateObserversSafely,\n  isNonEmptyArray,\n  fixObservableSubclass,\n  getQueryDefinition,\n} from '../utilities';\nimport { ApolloError } from '../errors';\nimport { QueryManager } from './QueryManager';\nimport { ApolloQueryResult, OperationVariables } from './types';\nimport {\n  WatchQueryOptions,\n  FetchMoreQueryOptions,\n  SubscribeToMoreOptions,\n  WatchQueryFetchPolicy,\n} from './watchQueryOptions';\nimport { QueryInfo } from './QueryInfo';\nimport { MissingFieldError } from '../cache';\nimport { MissingTree } from '../cache/core/types/common';\n\nconst {\n  assign,\n  hasOwnProperty,\n} = Object;\n\nexport interface FetchMoreOptions<\n  TData = any,\n  TVariables = OperationVariables\n> {\n  updateQuery?: (\n    previousQueryResult: TData,\n    options: {\n      fetchMoreResult?: TData;\n      variables?: TVariables;\n    },\n  ) => TData;\n}\n\nexport interface UpdateQueryOptions<TVariables> {\n  variables?: TVariables;\n}\n\nlet warnedAboutUpdateQuery = false;\n\ninterface Last<TData, TVariables> {\n  result: ApolloQueryResult<TData>;\n  variables?: TVariables;\n  error?: ApolloError;\n}\n\nexport class ObservableQuery<\n  TData = any,\n  TVariables = OperationVariables\n> extends Observable<ApolloQueryResult<TData>> {\n  public readonly options: WatchQueryOptions<TVariables, TData>;\n  public readonly queryId: string;\n  public readonly queryName?: string;\n\n  // Computed shorthand for this.options.variables, preserved for\n  // backwards compatibility.\n  public get variables(): TVariables | undefined {\n    return this.options.variables;\n  }\n\n  // Original value of this.options.fetchPolicy (defaulting to \"cache-first\"),\n  // from whenever the ObservableQuery was first created.\n  private initialFetchPolicy: WatchQueryFetchPolicy;\n\n  private isTornDown: boolean;\n  private queryManager: QueryManager<any>;\n  private observers = new Set<Observer<ApolloQueryResult<TData>>>();\n  private subscriptions = new Set<ObservableSubscription>();\n\n  private last?: Last<TData, TVariables>;\n\n  private queryInfo: QueryInfo;\n\n  // When this.concast is defined, this.observer is the Observer currently\n  // subscribed to that Concast.\n  private concast?: Concast<ApolloQueryResult<TData>>;\n  private observer?: Observer<ApolloQueryResult<TData>>;\n\n  private pollingInfo?: {\n    interval: number;\n    timeout: ReturnType<typeof setTimeout>;\n  };\n\n  constructor({\n    queryManager,\n    queryInfo,\n    options,\n  }: {\n    queryManager: QueryManager<any>;\n    queryInfo: QueryInfo;\n    options: WatchQueryOptions<TVariables, TData>;\n  }) {\n    super((observer: Observer<ApolloQueryResult<TData>>) => {\n      // Zen Observable has its own error function, so in order to log correctly\n      // we need to provide a custom error callback.\n      try {\n        var subObserver = (observer as any)._subscription._observer;\n        if (subObserver && !subObserver.error) {\n          subObserver.error = defaultSubscriptionObserverErrorCallback;\n        }\n      } catch {}\n\n      const first = !this.observers.size;\n      this.observers.add(observer);\n\n      // Deliver most recent error or result.\n      const last = this.last;\n      if (last && last.error) {\n        observer.error && observer.error(last.error);\n      } else if (last && last.result) {\n        observer.next && observer.next(last.result);\n      }\n\n      // Initiate observation of this query if it hasn't been reported to\n      // the QueryManager yet.\n      if (first) {\n        // Blindly catching here prevents unhandled promise rejections,\n        // and is safe because the ObservableQuery handles this error with\n        // this.observer.error, so we're not just swallowing the error by\n        // ignoring it here.\n        this.reobserve().catch(() => {});\n      }\n\n      return () => {\n        if (this.observers.delete(observer) && !this.observers.size) {\n          this.tearDownQuery();\n        }\n      };\n    });\n\n    // active state\n    this.isTornDown = false;\n\n    // query information\n    this.options = options;\n    this.queryId = queryInfo.queryId || queryManager.generateQueryId();\n\n    const opDef = getOperationDefinition(options.query);\n    this.queryName = opDef && opDef.name && opDef.name.value;\n\n    this.initialFetchPolicy = options.fetchPolicy || \"cache-first\";\n\n    // related classes\n    this.queryManager = queryManager;\n    this.queryInfo = queryInfo;\n  }\n\n  public result(): Promise<ApolloQueryResult<TData>> {\n    return new Promise((resolve, reject) => {\n      // TODO: this code doesn\u2019t actually make sense insofar as the observer\n      // will never exist in this.observers due how zen-observable wraps observables.\n      // https://github.com/zenparsing/zen-observable/blob/master/src/Observable.js#L169\n      const observer: Observer<ApolloQueryResult<TData>> = {\n        next: (result: ApolloQueryResult<TData>) => {\n          resolve(result);\n\n          // Stop the query within the QueryManager if we can before\n          // this function returns.\n          //\n          // We do this in order to prevent observers piling up within\n          // the QueryManager. Notice that we only fully unsubscribe\n          // from the subscription in a setTimeout(..., 0)  call. This call can\n          // actually be handled by the browser at a much later time. If queries\n          // are fired in the meantime, observers that should have been removed\n          // from the QueryManager will continue to fire, causing an unnecessary\n          // performance hit.\n          this.observers.delete(observer);\n          if (!this.observers.size) {\n            this.queryManager.removeQuery(this.queryId);\n          }\n\n          setTimeout(() => {\n            subscription.unsubscribe();\n          }, 0);\n        },\n        error: reject,\n      };\n      const subscription = this.subscribe(observer);\n    });\n  }\n\n  public getCurrentResult(saveAsLastResult = true): ApolloQueryResult<TData> {\n    // Use the last result as long as the variables match this.variables.\n    const lastResult = this.getLastResult(true);\n\n    const networkStatus =\n      this.queryInfo.networkStatus ||\n      (lastResult && lastResult.networkStatus) ||\n      NetworkStatus.ready;\n\n    const result = {\n      ...lastResult,\n      loading: isNetworkRequestInFlight(networkStatus),\n      networkStatus,\n    } as ApolloQueryResult<TData>;\n\n    const { fetchPolicy = \"cache-first\" } = this.options;\n    if (\n      // These fetch policies should never deliver data from the cache, unless\n      // redelivering a previously delivered result.\n      fetchPolicy === 'network-only' ||\n      fetchPolicy === 'no-cache' ||\n      fetchPolicy === 'standby' ||\n      // If this.options.query has @client(always: true) fields, we cannot\n      // trust diff.result, since it was read from the cache without running\n      // local resolvers (and it's too late to run resolvers now, since we must\n      // return a result synchronously).\n      this.queryManager.transform(this.options.query).hasForcedResolvers\n    ) {\n      // Fall through.\n    } else {\n      const diff = this.queryInfo.getDiff();\n\n      if (diff.complete || this.options.returnPartialData) {\n        result.data = diff.result;\n      }\n\n      if (equal(result.data, {})) {\n        result.data = void 0 as any;\n      }\n\n      if (diff.complete) {\n        // Similar to setting result.partial to false, but taking advantage of the\n        // falsiness of missing fields.\n        delete result.partial;\n\n        // If the diff is complete, and we're using a FetchPolicy that\n        // terminates after a complete cache read, we can assume the next result\n        // we receive will have NetworkStatus.ready and !loading.\n        if (\n          diff.complete &&\n          result.networkStatus === NetworkStatus.loading &&\n          (fetchPolicy === 'cache-first' ||\n          fetchPolicy === 'cache-only')\n        ) {\n          result.networkStatus = NetworkStatus.ready;\n          result.loading = false;\n        }\n      } else {\n        result.partial = true;\n      }\n\n      if (\n        __DEV__ &&\n        !diff.complete &&\n        !this.options.partialRefetch &&\n        !result.loading &&\n        !result.data &&\n        !result.error\n      ) {\n        logMissingFieldErrors(diff.missing);\n      }\n    }\n\n    if (saveAsLastResult) {\n      this.updateLastResult(result);\n    }\n\n    return result;\n  }\n\n  // Compares newResult to the snapshot we took of this.lastResult when it was\n  // first received.\n  public isDifferentFromLastResult(newResult: ApolloQueryResult<TData>) {\n    return !this.last || !equal(this.last.result, newResult);\n  }\n\n  private getLast<K extends keyof Last<TData, TVariables>>(\n    key: K,\n    variablesMustMatch?: boolean,\n  ) {\n    const last = this.last;\n    if (\n      last &&\n      last[key] &&\n      (!variablesMustMatch || equal(last.variables, this.variables))\n    ) {\n      return last[key];\n    }\n  }\n\n  public getLastResult(variablesMustMatch?: boolean): ApolloQueryResult<TData> | undefined {\n    return this.getLast(\"result\", variablesMustMatch);\n  }\n\n  public getLastError(variablesMustMatch?: boolean): ApolloError | undefined {\n    return this.getLast(\"error\", variablesMustMatch);\n  }\n\n  public resetLastResults(): void {\n    delete this.last;\n    this.isTornDown = false;\n  }\n\n  public resetQueryStoreErrors() {\n    this.queryManager.resetErrors(this.queryId);\n  }\n\n  /**\n   * Update the variables of this observable query, and fetch the new results.\n   * This method should be preferred over `setVariables` in most use cases.\n   *\n   * @param variables: The new set of variables. If there are missing variables,\n   * the previous values of those variables will be used.\n   */\n  public refetch(variables?: Partial<TVariables>): Promise<ApolloQueryResult<TData>> {\n    const reobserveOptions: Partial<WatchQueryOptions<TVariables, TData>> = {\n      // Always disable polling for refetches.\n      pollInterval: 0,\n    };\n\n    // Unless the provided fetchPolicy always consults the network\n    // (no-cache, network-only, or cache-and-network), override it with\n    // network-only to force the refetch for this fetchQuery call.\n    const { fetchPolicy } = this.options;\n    if (fetchPolicy === 'cache-and-network') {\n      reobserveOptions.fetchPolicy = fetchPolicy;\n    } else if (fetchPolicy === 'no-cache') {\n      reobserveOptions.fetchPolicy = 'no-cache';\n    } else {\n      reobserveOptions.fetchPolicy = 'network-only';\n    }\n\n    if (__DEV__ && variables && hasOwnProperty.call(variables, \"variables\")) {\n      const queryDef = getQueryDefinition(this.options.query);\n      const vars = queryDef.variableDefinitions;\n      if (!vars || !vars.some(v => v.variable.name.value === \"variables\")) {\n        invariant.warn(`Called refetch(${\n          JSON.stringify(variables)\n        }) for query ${\n          queryDef.name?.value || JSON.stringify(queryDef)\n        }, which does not declare a $variables variable.\nDid you mean to call refetch(variables) instead of refetch({ variables })?`);\n      }\n    }\n\n    if (variables && !equal(this.options.variables, variables)) {\n      // Update the existing options with new variables\n      reobserveOptions.variables = this.options.variables = {\n        ...this.options.variables,\n        ...variables,\n      } as TVariables;\n    }\n\n    this.queryInfo.resetLastWrite();\n    return this.reobserve(reobserveOptions, NetworkStatus.refetch);\n  }\n\n  public fetchMore(\n    fetchMoreOptions: FetchMoreQueryOptions<TVariables, TData> &\n      FetchMoreOptions<TData, TVariables>,\n  ): Promise<ApolloQueryResult<TData>> {\n    const combinedOptions = {\n      ...(fetchMoreOptions.query ? fetchMoreOptions : {\n        ...this.options,\n        ...fetchMoreOptions,\n        variables: {\n          ...this.options.variables,\n          ...fetchMoreOptions.variables,\n        },\n      }),\n      // The fetchMore request goes immediately to the network and does\n      // not automatically write its result to the cache (hence no-cache\n      // instead of network-only), because we allow the caller of\n      // fetchMore to provide an updateQuery callback that determines how\n      // the data gets written to the cache.\n      fetchPolicy: \"no-cache\",\n    } as WatchQueryOptions;\n\n    const qid = this.queryManager.generateQueryId();\n\n    // Simulate a loading result for the original query with\n    // result.networkStatus === NetworkStatus.fetchMore.\n    if (combinedOptions.notifyOnNetworkStatusChange) {\n      this.queryInfo.networkStatus = NetworkStatus.fetchMore;\n      this.observe();\n    }\n\n    return this.queryManager.fetchQuery(\n      qid,\n      combinedOptions,\n      NetworkStatus.fetchMore,\n    ).then(fetchMoreResult => {\n      const data = fetchMoreResult.data as TData;\n      const { updateQuery } = fetchMoreOptions;\n\n      if (updateQuery) {\n        if (__DEV__ &&\n            !warnedAboutUpdateQuery) {\n          invariant.warn(\n`The updateQuery callback for fetchMore is deprecated, and will be removed\nin the next major version of Apollo Client.\n\nPlease convert updateQuery functions to field policies with appropriate\nread and merge functions, or use/adapt a helper function (such as\nconcatPagination, offsetLimitPagination, or relayStylePagination) from\n@apollo/client/utilities.\n\nThe field policy system handles pagination more effectively than a\nhand-written updateQuery function, and you only need to define the policy\nonce, rather than every time you call fetchMore.`);\n          warnedAboutUpdateQuery = true;\n        }\n        this.updateQuery(previous => updateQuery(previous, {\n          fetchMoreResult: data,\n          variables: combinedOptions.variables as TVariables,\n        }));\n      } else {\n        // If we're using a field policy instead of updateQuery, the only\n        // thing we need to do is write the new data to the cache using\n        // combinedOptions.variables (instead of this.variables, which is\n        // what this.updateQuery uses, because it works by abusing the\n        // original field value, keyed by the original variables).\n        this.queryManager.cache.writeQuery({\n          query: combinedOptions.query,\n          variables: combinedOptions.variables,\n          data,\n        });\n      }\n\n      return fetchMoreResult as ApolloQueryResult<TData>;\n\n    }).finally(() => {\n      this.queryManager.stopQuery(qid);\n      this.reobserve();\n    });\n  }\n\n  // XXX the subscription variables are separate from the query variables.\n  // if you want to update subscription variables, right now you have to do that separately,\n  // and you can only do it by stopping the subscription and then subscribing again with new variables.\n  public subscribeToMore<\n    TSubscriptionData = TData,\n    TSubscriptionVariables = TVariables\n  >(\n    options: SubscribeToMoreOptions<\n      TData,\n      TSubscriptionVariables,\n      TSubscriptionData\n    >,\n  ) {\n    const subscription = this.queryManager\n      .startGraphQLSubscription({\n        query: options.document,\n        variables: options.variables,\n        context: options.context,\n      })\n      .subscribe({\n        next: (subscriptionData: { data: TSubscriptionData }) => {\n          const { updateQuery } = options;\n          if (updateQuery) {\n            this.updateQuery<TSubscriptionVariables>(\n              (previous, { variables }) =>\n                updateQuery(previous, {\n                  subscriptionData,\n                  variables,\n                }),\n            );\n          }\n        },\n        error: (err: any) => {\n          if (options.onError) {\n            options.onError(err);\n            return;\n          }\n          invariant.error('Unhandled GraphQL subscription error', err);\n        },\n      });\n\n    this.subscriptions.add(subscription);\n\n    return () => {\n      if (this.subscriptions.delete(subscription)) {\n        subscription.unsubscribe();\n      }\n    };\n  }\n\n  public setOptions(\n    newOptions: Partial<WatchQueryOptions<TVariables, TData>>,\n  ): Promise<ApolloQueryResult<TData>> {\n    return this.reobserve(newOptions);\n  }\n\n  /**\n   * This is for *internal* use only. Most users should instead use `refetch`\n   * in order to be properly notified of results even when they come from cache.\n   *\n   * Update the variables of this observable query, and fetch the new results\n   * if they've changed. If you want to force new results, use `refetch`.\n   *\n   * Note: the `next` callback will *not* fire if the variables have not changed\n   * or if the result is coming from cache.\n   *\n   * Note: the promise will return the old results immediately if the variables\n   * have not changed.\n   *\n   * Note: the promise will return null immediately if the query is not active\n   * (there are no subscribers).\n   *\n   * @private\n   *\n   * @param variables: The new set of variables. If there are missing variables,\n   * the previous values of those variables will be used.\n   */\n  public setVariables(\n    variables: TVariables,\n  ): Promise<ApolloQueryResult<TData> | void> {\n    if (equal(this.variables, variables)) {\n      // If we have no observers, then we don't actually want to make a network\n      // request. As soon as someone observes the query, the request will kick\n      // off. For now, we just store any changes. (See #1077)\n      return this.observers.size\n        ? this.result()\n        : Promise.resolve();\n    }\n\n    this.options.variables = variables;\n\n    // See comment above\n    if (!this.observers.size) {\n      return Promise.resolve();\n    }\n\n    return this.reobserve({\n      // Reset options.fetchPolicy to its original value.\n      fetchPolicy: this.initialFetchPolicy,\n      variables,\n    }, NetworkStatus.setVariables);\n  }\n\n  public updateQuery<TVars = TVariables>(\n    mapFn: (\n      previousQueryResult: TData,\n      options: Pick<WatchQueryOptions<TVars, TData>, \"variables\">,\n    ) => TData,\n  ): void {\n    const { queryManager } = this;\n    const { result } = queryManager.cache.diff<TData>({\n      query: this.options.query,\n      variables: this.variables,\n      returnPartialData: true,\n      optimistic: false,\n    });\n\n    const newResult = mapFn(result!, {\n      variables: (this as any).variables,\n    });\n\n    if (newResult) {\n      queryManager.cache.writeQuery({\n        query: this.options.query,\n        data: newResult,\n        variables: this.variables,\n      });\n\n      queryManager.broadcastQueries();\n    }\n  }\n\n  public startPolling(pollInterval: number) {\n    this.options.pollInterval = pollInterval;\n    this.updatePolling();\n  }\n\n  public stopPolling() {\n    this.options.pollInterval = 0;\n    this.updatePolling();\n  }\n\n  private fetch(\n    options: WatchQueryOptions<TVariables, TData>,\n    newNetworkStatus?: NetworkStatus,\n  ): Concast<ApolloQueryResult<TData>> {\n    this.queryManager.setObservableQuery(this);\n    return this.queryManager.fetchQueryObservable(\n      this.queryId,\n      options,\n      newNetworkStatus,\n    );\n  }\n\n  // Turns polling on or off based on this.options.pollInterval.\n  private updatePolling() {\n    // Avoid polling in SSR mode\n    if (this.queryManager.ssrMode) {\n      return;\n    }\n\n    const {\n      pollingInfo,\n      options: {\n        pollInterval,\n      },\n    } = this;\n\n    if (!pollInterval) {\n      if (pollingInfo) {\n        clearTimeout(pollingInfo.timeout);\n        delete this.pollingInfo;\n      }\n      return;\n    }\n\n    if (pollingInfo &&\n        pollingInfo.interval === pollInterval) {\n      return;\n    }\n\n    invariant(\n      pollInterval,\n      'Attempted to start a polling query without a polling interval.',\n    );\n\n    const info = pollingInfo || (this.pollingInfo = {} as any);\n    info.interval = pollInterval;\n\n    const maybeFetch = () => {\n      if (this.pollingInfo) {\n        if (!isNetworkRequestInFlight(this.queryInfo.networkStatus)) {\n          this.reobserve({\n            fetchPolicy: \"network-only\",\n          }, NetworkStatus.poll).then(poll, poll);\n        } else {\n          poll();\n        }\n      };\n    };\n\n    const poll = () => {\n      const info = this.pollingInfo;\n      if (info) {\n        clearTimeout(info.timeout);\n        info.timeout = setTimeout(maybeFetch, info.interval);\n      }\n    };\n\n    poll();\n  }\n\n  private updateLastResult(\n    newResult: ApolloQueryResult<TData>,\n    variables = this.variables,\n  ) {\n    this.last = {\n      ...this.last,\n      result: this.queryManager.assumeImmutableResults\n        ? newResult\n        : cloneDeep(newResult),\n      variables,\n    };\n    if (!isNonEmptyArray(newResult.errors)) {\n      delete this.last.error;\n    }\n    return this.last;\n  }\n\n  public reobserve(\n    newOptions?: Partial<WatchQueryOptions<TVariables, TData>>,\n    newNetworkStatus?: NetworkStatus,\n  ): Promise<ApolloQueryResult<TData>> {\n    this.isTornDown = false;\n\n    const useDisposableConcast =\n      // Refetching uses a disposable Concast to allow refetches using different\n      // options/variables, without permanently altering the options of the\n      // original ObservableQuery.\n      newNetworkStatus === NetworkStatus.refetch ||\n      // The fetchMore method does not actually call the reobserve method, but,\n      // if it did, it would definitely use a disposable Concast.\n      newNetworkStatus === NetworkStatus.fetchMore ||\n      // Polling uses a disposable Concast so the polling options (which force\n      // fetchPolicy to be \"network-only\") won't override the original options.\n      newNetworkStatus === NetworkStatus.poll;\n\n    // Save the old variables, since Object.assign may modify them below.\n    const oldVariables = this.options.variables;\n\n    const options = useDisposableConcast\n      // Disposable Concast fetches receive a shallow copy of this.options\n      // (merged with newOptions), leaving this.options unmodified.\n      ? compact(this.options, newOptions)\n      : assign(this.options, compact(newOptions));\n\n    if (!useDisposableConcast) {\n      // We can skip calling updatePolling if we're not changing this.options.\n      this.updatePolling();\n\n      // Reset options.fetchPolicy to its original value when variables change,\n      // unless a new fetchPolicy was provided by newOptions.\n      if (\n        newOptions &&\n        newOptions.variables &&\n        !newOptions.fetchPolicy &&\n        !equal(newOptions.variables, oldVariables)\n      ) {\n        options.fetchPolicy = this.initialFetchPolicy;\n        if (newNetworkStatus === void 0) {\n          newNetworkStatus = NetworkStatus.setVariables;\n        }\n      }\n    }\n\n    const variables = options.variables && { ...options.variables };\n    const concast = this.fetch(options, newNetworkStatus);\n    const observer: Observer<ApolloQueryResult<TData>> = {\n      next: result => {\n        this.reportResult(result, variables);\n      },\n      error: error => {\n        this.reportError(error, variables);\n      },\n    };\n\n    if (!useDisposableConcast) {\n      // We use the {add,remove}Observer methods directly to avoid wrapping\n      // observer with an unnecessary SubscriptionObserver object, in part so\n      // that we can remove it here without triggering any unsubscriptions,\n      // because we just want to ignore the old observable, not prematurely shut\n      // it down, since other consumers may be awaiting this.concast.promise.\n      if (this.concast && this.observer) {\n        this.concast.removeObserver(this.observer, true);\n      }\n\n      this.concast = concast;\n      this.observer = observer;\n    }\n\n    concast.addObserver(observer);\n\n    return concast.promise;\n  }\n\n  // Pass the current result to this.observer.next without applying any\n  // fetch policies.\n  private observe() {\n    // Passing false is important so that this.getCurrentResult doesn't\n    // save the fetchMore result as this.lastResult, causing it to be\n    // ignored due to the this.isDifferentFromLastResult check in\n    // this.observer.next.\n    this.reportResult(\n      this.getCurrentResult(false),\n      this.variables,\n    );\n  }\n\n  private reportResult(\n    result: ApolloQueryResult<TData>,\n    variables: TVariables | undefined,\n  ) {\n    const lastError = this.getLastError();\n    if (lastError || this.isDifferentFromLastResult(result)) {\n      if (lastError || !result.partial || this.options.returnPartialData) {\n        this.updateLastResult(result, variables);\n      }\n\n      iterateObserversSafely(this.observers, 'next', result);\n    }\n  }\n\n  private reportError(\n    error: ApolloError,\n    variables: TVariables | undefined,\n  ) {\n    // Since we don't get the current result on errors, only the error, we\n    // must mirror the updates that occur in QueryStore.markQueryError here\n    const errorResult = {\n      ...this.getLastResult(),\n      error,\n      errors: error.graphQLErrors,\n      networkStatus: NetworkStatus.error,\n      loading: false,\n    } as ApolloQueryResult<TData>;\n\n    this.updateLastResult(errorResult, variables);\n\n    iterateObserversSafely(this.observers, 'error', this.last!.error = error);\n  }\n\n  public hasObservers() {\n    return this.observers.size > 0;\n  }\n\n  private tearDownQuery() {\n    if (this.isTornDown) return;\n    if (this.concast && this.observer) {\n      this.concast.removeObserver(this.observer);\n      delete this.concast;\n      delete this.observer;\n    }\n\n    this.stopPolling();\n    // stop all active GraphQL subscriptions\n    this.subscriptions.forEach(sub => sub.unsubscribe());\n    this.subscriptions.clear();\n    this.queryManager.stopQuery(this.queryId);\n    this.observers.clear();\n    this.isTornDown = true;\n  }\n}\n\n// Necessary because the ObservableQuery constructor has a different\n// signature than the Observable constructor.\nfixObservableSubclass(ObservableQuery);\n\nfunction defaultSubscriptionObserverErrorCallback(error: ApolloError) {\n  invariant.error('Unhandled error', error.message, error.stack);\n}\n\nexport function logMissingFieldErrors(\n  missing: MissingFieldError[] | MissingTree | undefined,\n) {\n  if (__DEV__ && missing) {\n    invariant.debug(`Missing cache result fields: ${\n      JSON.stringify(missing)\n    }`, missing);\n  }\n}\n\n// Adopt options.nextFetchPolicy (if defined) as a replacement for\n// options.fetchPolicy. Since this method also removes options.nextFetchPolicy\n// from options, the adoption tends to be idempotent, unless nextFetchPolicy\n// is a function that keeps setting options.nextFetchPolicy (uncommon).\nexport function applyNextFetchPolicy<TData, TVars>(\n  options: Pick<\n    WatchQueryOptions<TVars, TData>,\n    | \"fetchPolicy\"\n    | \"nextFetchPolicy\"\n  >,\n) {\n  const {\n    fetchPolicy = \"cache-first\",\n    nextFetchPolicy,\n  } = options;\n\n  if (nextFetchPolicy) {\n    // When someone chooses \"cache-and-network\" or \"network-only\" as their\n    // initial FetchPolicy, they often do not want future cache updates to\n    // trigger unconditional network requests, which is what repeatedly\n    // applying the \"cache-and-network\" or \"network-only\" policies would seem\n    // to imply. Instead, when the cache reports an update after the initial\n    // network request, it may be desirable for subsequent network requests to\n    // be triggered only if the cache result is incomplete. To that end, the\n    // options.nextFetchPolicy option provides an easy way to update\n    // options.fetchPolicy after the initial network request, without having to\n    // call observableQuery.setOptions.\n    options.fetchPolicy = typeof nextFetchPolicy === \"function\"\n      ? nextFetchPolicy.call(options, fetchPolicy)\n      : nextFetchPolicy;\n  }\n}\n", "import { invariant } from '../utilities/globals';\n\nimport {\n  DocumentNode,\n  OperationDefinitionNode,\n  SelectionSetNode,\n  SelectionNode,\n  InlineFragmentNode,\n  FragmentDefinitionNode,\n  FieldNode,\n  ASTNode,\n  visit,\n  BREAK,\n} from 'graphql';\n\nimport { ApolloCache } from '../cache';\nimport {\n  FragmentMap,\n  StoreObject,\n  argumentsObjectFromField,\n  buildQueryFromSelectionSet,\n  createFragmentMap,\n  getFragmentDefinitions,\n  getMainDefinition,\n  hasDirectives,\n  isField,\n  isInlineFragment,\n  mergeDeep,\n  mergeDeepArray,\n  removeClientSetsFromDocument,\n  resultKeyNameFromField,\n  shouldInclude,\n} from '../utilities';\nimport { ApolloClient } from './ApolloClient';\nimport { Resolvers, OperationVariables } from './types';\nimport { FetchResult } from '../link/core';\nimport { cacheSlot } from '../cache';\n\nexport type Resolver = (\n  rootValue?: any,\n  args?: any,\n  context?: any,\n  info?: {\n    field: FieldNode;\n    fragmentMap: FragmentMap;\n  },\n) => any;\n\nexport type VariableMap = { [name: string]: any };\n\nexport type FragmentMatcher = (\n  rootValue: any,\n  typeCondition: string,\n  context: any,\n) => boolean;\n\nexport type ExecContext = {\n  fragmentMap: FragmentMap;\n  context: any;\n  variables: VariableMap;\n  fragmentMatcher: FragmentMatcher;\n  defaultOperationType: string;\n  exportedVariables: Record<string, any>;\n  onlyRunForcedResolvers: boolean;\n};\n\nexport type LocalStateOptions<TCacheShape> = {\n  cache: ApolloCache<TCacheShape>;\n  client?: ApolloClient<TCacheShape>;\n  resolvers?: Resolvers | Resolvers[];\n  fragmentMatcher?: FragmentMatcher;\n};\n\nexport class LocalState<TCacheShape> {\n  private cache: ApolloCache<TCacheShape>;\n  private client: ApolloClient<TCacheShape>;\n  private resolvers?: Resolvers;\n  private fragmentMatcher: FragmentMatcher;\n\n  constructor({\n    cache,\n    client,\n    resolvers,\n    fragmentMatcher,\n  }: LocalStateOptions<TCacheShape>) {\n    this.cache = cache;\n\n    if (client) {\n      this.client = client;\n    }\n\n    if (resolvers) {\n      this.addResolvers(resolvers);\n    }\n\n    if (fragmentMatcher) {\n      this.setFragmentMatcher(fragmentMatcher);\n    }\n  }\n\n  public addResolvers(resolvers: Resolvers | Resolvers[]) {\n    this.resolvers = this.resolvers || {};\n    if (Array.isArray(resolvers)) {\n      resolvers.forEach(resolverGroup => {\n        this.resolvers = mergeDeep(this.resolvers, resolverGroup);\n      });\n    } else {\n      this.resolvers = mergeDeep(this.resolvers, resolvers);\n    }\n  }\n\n  public setResolvers(resolvers: Resolvers | Resolvers[]) {\n    this.resolvers = {};\n    this.addResolvers(resolvers);\n  }\n\n  public getResolvers() {\n    return this.resolvers || {};\n  }\n\n  // Run local client resolvers against the incoming query and remote data.\n  // Locally resolved field values are merged with the incoming remote data,\n  // and returned. Note that locally resolved fields will overwrite\n  // remote data using the same field name.\n  public async runResolvers<TData>({\n    document,\n    remoteResult,\n    context,\n    variables,\n    onlyRunForcedResolvers = false,\n  }: {\n    document: DocumentNode | null;\n    remoteResult: FetchResult<TData>;\n    context?: Record<string, any>;\n    variables?: Record<string, any>;\n    onlyRunForcedResolvers?: boolean;\n  }): Promise<FetchResult<TData>> {\n    if (document) {\n      return this.resolveDocument(\n        document,\n        remoteResult.data,\n        context,\n        variables,\n        this.fragmentMatcher,\n        onlyRunForcedResolvers,\n      ).then(localResult => ({\n        ...remoteResult,\n        data: localResult.result,\n      }));\n    }\n\n    return remoteResult;\n  }\n\n  public setFragmentMatcher(fragmentMatcher: FragmentMatcher) {\n    this.fragmentMatcher = fragmentMatcher;\n  }\n\n  public getFragmentMatcher(): FragmentMatcher {\n    return this.fragmentMatcher;\n  }\n\n  // Client queries contain everything in the incoming document (if a @client\n  // directive is found).\n  public clientQuery(document: DocumentNode) {\n    if (hasDirectives(['client'], document)) {\n      if (this.resolvers) {\n        return document;\n      }\n    }\n    return null;\n  }\n\n  // Server queries are stripped of all @client based selection sets.\n  public serverQuery(document: DocumentNode) {\n    return removeClientSetsFromDocument(document);\n  }\n\n  public prepareContext(context?: Record<string, any>) {\n    const { cache } = this;\n    return {\n      ...context,\n      cache,\n      // Getting an entry's cache key is useful for local state resolvers.\n      getCacheKey(obj: StoreObject) {\n        return cache.identify(obj);\n      },\n    };\n  }\n\n  // To support `@client @export(as: \"someVar\")` syntax, we'll first resolve\n  // @client @export fields locally, then pass the resolved values back to be\n  // used alongside the original operation variables.\n  public async addExportedVariables(\n    document: DocumentNode,\n    variables: OperationVariables = {},\n    context = {},\n  ) {\n    if (document) {\n      return this.resolveDocument(\n        document,\n        this.buildRootValueFromCache(document, variables) || {},\n        this.prepareContext(context),\n        variables,\n      ).then(data => ({\n        ...variables,\n        ...data.exportedVariables,\n      }));\n    }\n\n    return {\n      ...variables,\n    };\n  }\n\n  public shouldForceResolvers(document: ASTNode) {\n    let forceResolvers = false;\n    visit(document, {\n      Directive: {\n        enter(node) {\n          if (node.name.value === 'client' && node.arguments) {\n            forceResolvers = node.arguments.some(\n              arg =>\n                arg.name.value === 'always' &&\n                arg.value.kind === 'BooleanValue' &&\n                arg.value.value === true,\n            );\n            if (forceResolvers) {\n              return BREAK;\n            }\n          }\n        },\n      },\n    });\n    return forceResolvers;\n  }\n\n  // Query the cache and return matching data.\n  private buildRootValueFromCache(\n    document: DocumentNode,\n    variables?: Record<string, any>,\n  ) {\n    return this.cache.diff({\n      query: buildQueryFromSelectionSet(document),\n      variables,\n      returnPartialData: true,\n      optimistic: false,\n    }).result;\n  }\n\n  private async resolveDocument<TData>(\n    document: DocumentNode,\n    rootValue: TData,\n    context: any = {},\n    variables: VariableMap = {},\n    fragmentMatcher: FragmentMatcher = () => true,\n    onlyRunForcedResolvers: boolean = false,\n  ) {\n    const mainDefinition = getMainDefinition(document);\n    const fragments = getFragmentDefinitions(document);\n    const fragmentMap = createFragmentMap(fragments);\n\n    const definitionOperation = (mainDefinition as OperationDefinitionNode)\n      .operation;\n\n    const defaultOperationType = definitionOperation\n      ? definitionOperation.charAt(0).toUpperCase() +\n        definitionOperation.slice(1)\n      : 'Query';\n\n    const { cache, client } = this;\n    const execContext: ExecContext = {\n      fragmentMap,\n      context: {\n        ...context,\n        cache,\n        client,\n      },\n      variables,\n      fragmentMatcher,\n      defaultOperationType,\n      exportedVariables: {},\n      onlyRunForcedResolvers,\n    };\n\n    return this.resolveSelectionSet(\n      mainDefinition.selectionSet,\n      rootValue,\n      execContext,\n    ).then(result => ({\n      result,\n      exportedVariables: execContext.exportedVariables,\n    }));\n  }\n\n  private async resolveSelectionSet<TData>(\n    selectionSet: SelectionSetNode,\n    rootValue: TData,\n    execContext: ExecContext,\n  ) {\n    const { fragmentMap, context, variables } = execContext;\n    const resultsToMerge: TData[] = [rootValue];\n\n    const execute = async (selection: SelectionNode): Promise<void> => {\n      if (!shouldInclude(selection, variables)) {\n        // Skip this entirely.\n        return;\n      }\n\n      if (isField(selection)) {\n        return this.resolveField(selection, rootValue, execContext).then(\n          fieldResult => {\n            if (typeof fieldResult !== 'undefined') {\n              resultsToMerge.push({\n                [resultKeyNameFromField(selection)]: fieldResult,\n              } as TData);\n            }\n          },\n        );\n      }\n\n      let fragment: InlineFragmentNode | FragmentDefinitionNode;\n\n      if (isInlineFragment(selection)) {\n        fragment = selection;\n      } else {\n        // This is a named fragment.\n        fragment = fragmentMap[selection.name.value];\n        invariant(fragment, `No fragment named ${selection.name.value}`);\n      }\n\n      if (fragment && fragment.typeCondition) {\n        const typeCondition = fragment.typeCondition.name.value;\n        if (execContext.fragmentMatcher(rootValue, typeCondition, context)) {\n          return this.resolveSelectionSet(\n            fragment.selectionSet,\n            rootValue,\n            execContext,\n          ).then(fragmentResult => {\n            resultsToMerge.push(fragmentResult);\n          });\n        }\n      }\n    };\n\n    return Promise.all(selectionSet.selections.map(execute)).then(function() {\n      return mergeDeepArray(resultsToMerge);\n    });\n  }\n\n  private async resolveField(\n    field: FieldNode,\n    rootValue: any,\n    execContext: ExecContext,\n  ): Promise<any> {\n    const { variables } = execContext;\n    const fieldName = field.name.value;\n    const aliasedFieldName = resultKeyNameFromField(field);\n    const aliasUsed = fieldName !== aliasedFieldName;\n    const defaultResult = rootValue[aliasedFieldName] || rootValue[fieldName];\n    let resultPromise = Promise.resolve(defaultResult);\n\n    // Usually all local resolvers are run when passing through here, but\n    // if we've specifically identified that we only want to run forced\n    // resolvers (that is, resolvers for fields marked with\n    // `@client(always: true)`), then we'll skip running non-forced resolvers.\n    if (\n      !execContext.onlyRunForcedResolvers ||\n      this.shouldForceResolvers(field)\n    ) {\n      const resolverType =\n        rootValue.__typename || execContext.defaultOperationType;\n      const resolverMap = this.resolvers && this.resolvers[resolverType];\n      if (resolverMap) {\n        const resolve = resolverMap[aliasUsed ? fieldName : aliasedFieldName];\n        if (resolve) {\n          resultPromise = Promise.resolve(\n            // In case the resolve function accesses reactive variables,\n            // set cacheSlot to the current cache instance.\n            cacheSlot.withValue(this.cache, resolve, [\n              rootValue,\n              argumentsObjectFromField(field, variables),\n              execContext.context,\n              { field, fragmentMap: execContext.fragmentMap },\n            ])\n          );\n        }\n      }\n    }\n\n    return resultPromise.then((result = defaultResult) => {\n      // If an @export directive is associated with the current field, store\n      // the `as` export variable name and current result for later use.\n      if (field.directives) {\n        field.directives.forEach(directive => {\n          if (directive.name.value === 'export' && directive.arguments) {\n            directive.arguments.forEach(arg => {\n              if (arg.name.value === 'as' && arg.value.kind === 'StringValue') {\n                execContext.exportedVariables[arg.value.value] = result;\n              }\n            });\n          }\n        });\n      }\n\n      // Handle all scalar types here.\n      if (!field.selectionSet) {\n        return result;\n      }\n\n      // From here down, the field has a selection set, which means it's trying\n      // to query a GraphQLObjectType.\n      if (result == null) {\n        // Basically any field in a GraphQL response can be null, or missing\n        return result;\n      }\n\n      if (Array.isArray(result)) {\n        return this.resolveSubSelectedArray(field, result, execContext);\n      }\n\n      // Returned value is an object, and the query has a sub-selection. Recurse.\n      if (field.selectionSet) {\n        return this.resolveSelectionSet(\n          field.selectionSet,\n          result,\n          execContext,\n        );\n      }\n    });\n  }\n\n  private resolveSubSelectedArray(\n    field: FieldNode,\n    result: any[],\n    execContext: ExecContext,\n  ): any {\n    return Promise.all(\n      result.map(item => {\n        if (item === null) {\n          return null;\n        }\n\n        // This is a nested array, recurse.\n        if (Array.isArray(item)) {\n          return this.resolveSubSelectedArray(field, item, execContext);\n        }\n\n        // This is an object, run the selection set on it.\n        if (field.selectionSet) {\n          return this.resolveSelectionSet(field.selectionSet, item, execContext);\n        }\n      }),\n    );\n  }\n}\n", "import { DocumentNode, GraphQLError } from 'graphql';\nimport { equal } from \"@wry/equality\";\n\nimport { Cache, ApolloCache } from '../cache';\nimport { WatchQueryOptions, ErrorPolicy } from './watchQueryOptions';\nimport { ObservableQuery } from './ObservableQuery';\nimport { QueryListener } from './types';\nimport { FetchResult } from '../link/core';\nimport {\n  ObservableSubscription,\n  isNonEmptyArray,\n  graphQLResultHasError,\n  canUseWeakMap,\n} from '../utilities';\nimport {\n  NetworkStatus,\n  isNetworkRequestInFlight,\n} from './networkStatus';\nimport { ApolloError } from '../errors';\nimport { QueryManager } from './QueryManager';\n\nexport type QueryStoreValue = Pick<QueryInfo,\n  | \"variables\"\n  | \"networkStatus\"\n  | \"networkError\"\n  | \"graphQLErrors\"\n  >;\n\nexport const enum CacheWriteBehavior {\n  FORBID,\n  OVERWRITE,\n  MERGE,\n};\n\nconst destructiveMethodCounts = new (\n  canUseWeakMap ? WeakMap : Map\n)<ApolloCache<any>, number>();\n\nfunction wrapDestructiveCacheMethod(\n  cache: ApolloCache<any>,\n  methodName: keyof ApolloCache<any>,\n) {\n  const original = cache[methodName];\n  if (typeof original === \"function\") {\n    cache[methodName] = function () {\n      destructiveMethodCounts.set(\n        cache,\n        // The %1e15 allows the count to wrap around to 0 safely every\n        // quadrillion evictions, so there's no risk of overflow. To be\n        // clear, this is more of a pedantic principle than something\n        // that matters in any conceivable practical scenario.\n        (destructiveMethodCounts.get(cache)! + 1) % 1e15,\n      );\n      return original.apply(this, arguments);\n    };\n  }\n}\n\nfunction cancelNotifyTimeout(info: QueryInfo) {\n  if (info[\"notifyTimeout\"]) {\n    clearTimeout(info[\"notifyTimeout\"]);\n    info[\"notifyTimeout\"] = void 0;\n  }\n}\n\n// A QueryInfo object represents a single query managed by the\n// QueryManager, which tracks all QueryInfo objects by queryId in its\n// this.queries Map. QueryInfo objects store the latest results and errors\n// for the given query, and are responsible for reporting those results to\n// the corresponding ObservableQuery, via the QueryInfo.notify method.\n// Results are reported asynchronously whenever setDiff marks the\n// QueryInfo object as dirty, though a call to the QueryManager's\n// broadcastQueries method may trigger the notification before it happens\n// automatically. This class used to be a simple interface type without\n// any field privacy or meaningful methods, which is why it still has so\n// many public fields. The effort to lock down and simplify the QueryInfo\n// interface is ongoing, and further improvements are welcome.\nexport class QueryInfo {\n  listeners = new Set<QueryListener>();\n  document: DocumentNode | null = null;\n  lastRequestId = 1;\n  subscriptions = new Set<ObservableSubscription>();\n  variables?: Record<string, any>;\n  networkStatus?: NetworkStatus;\n  networkError?: Error | null;\n  graphQLErrors?: ReadonlyArray<GraphQLError>;\n  stopped = false;\n\n  private cache: ApolloCache<any>;\n\n  constructor(\n    queryManager: QueryManager<any>,\n    public readonly queryId = queryManager.generateQueryId(),\n  ) {\n    const cache = this.cache = queryManager.cache;\n\n    // Track how often cache.evict is called, since we want eviction to\n    // override the feud-stopping logic in the markResult method, by\n    // causing shouldWrite to return true. Wrapping the cache.evict method\n    // is a bit of a hack, but it saves us from having to make eviction\n    // counting an official part of the ApolloCache API.\n    if (!destructiveMethodCounts.has(cache)) {\n      destructiveMethodCounts.set(cache, 0);\n      wrapDestructiveCacheMethod(cache, \"evict\");\n      wrapDestructiveCacheMethod(cache, \"modify\");\n      wrapDestructiveCacheMethod(cache, \"reset\");\n    }\n  }\n\n  public init(query: {\n    document: DocumentNode;\n    variables: Record<string, any> | undefined,\n    // The initial networkStatus for this fetch, most often\n    // NetworkStatus.loading, but also possibly fetchMore, poll, refetch,\n    // or setVariables.\n    networkStatus?: NetworkStatus,\n    observableQuery?: ObservableQuery<any>;\n    lastRequestId?: number;\n  }): this {\n    let networkStatus = query.networkStatus || NetworkStatus.loading;\n    if (this.variables &&\n        this.networkStatus !== NetworkStatus.loading &&\n        !equal(this.variables, query.variables)) {\n      networkStatus = NetworkStatus.setVariables;\n    }\n\n    if (!equal(query.variables, this.variables)) {\n      this.lastDiff = void 0;\n    }\n\n    Object.assign(this, {\n      document: query.document,\n      variables: query.variables,\n      networkError: null,\n      graphQLErrors: this.graphQLErrors || [],\n      networkStatus,\n    });\n\n    if (query.observableQuery) {\n      this.setObservableQuery(query.observableQuery);\n    }\n\n    if (query.lastRequestId) {\n      this.lastRequestId = query.lastRequestId;\n    }\n\n    return this;\n  }\n\n  private dirty: boolean = false;\n\n  private notifyTimeout?: ReturnType<typeof setTimeout>;\n\n  reset() {\n    cancelNotifyTimeout(this);\n    this.lastDiff = void 0;\n    this.dirty = false;\n  }\n\n  getDiff(variables = this.variables): Cache.DiffResult<any> {\n    const options = this.getDiffOptions(variables);\n\n    if (this.lastDiff && equal(options, this.lastDiff.options)) {\n      return this.lastDiff.diff;\n    }\n\n    this.updateWatch(this.variables = variables);\n\n    const oq = this.observableQuery;\n    if (oq && oq.options.fetchPolicy === \"no-cache\") {\n      return { complete: false };\n    }\n\n    const diff = this.cache.diff(options);\n    this.updateLastDiff(diff, options);\n    return diff;\n  }\n\n  private lastDiff?: {\n    diff: Cache.DiffResult<any>,\n    options: Cache.DiffOptions,\n  };\n\n  private updateLastDiff(\n    diff: Cache.DiffResult<any> | null,\n    options?: Cache.DiffOptions,\n  ) {\n    this.lastDiff = diff ? {\n      diff,\n      options: options || this.getDiffOptions(),\n    } : void 0;\n  }\n\n  private getDiffOptions(variables = this.variables): Cache.DiffOptions {\n    return {\n      query: this.document!,\n      variables,\n      returnPartialData: true,\n      optimistic: true,\n      canonizeResults: this.observableQuery?.options.canonizeResults,\n    };\n  }\n\n  setDiff(diff: Cache.DiffResult<any> | null) {\n    const oldDiff = this.lastDiff && this.lastDiff.diff;\n    this.updateLastDiff(diff);\n    if (!this.dirty &&\n        !equal(oldDiff && oldDiff.result,\n               diff && diff.result)) {\n      this.dirty = true;\n      if (!this.notifyTimeout) {\n        this.notifyTimeout = setTimeout(() => this.notify(), 0);\n      }\n    }\n  }\n\n  public readonly observableQuery: ObservableQuery<any> | null = null;\n  private oqListener?: QueryListener;\n\n  setObservableQuery(oq: ObservableQuery<any> | null) {\n    if (oq === this.observableQuery) return;\n\n    if (this.oqListener) {\n      this.listeners.delete(this.oqListener);\n    }\n\n    (this as any).observableQuery = oq;\n\n    if (oq) {\n      oq[\"queryInfo\"] = this;\n      this.listeners.add(this.oqListener = () => {\n        // If this.diff came from an optimistic transaction, deliver the\n        // current cache data to the ObservableQuery, but don't perform a\n        // full reobservation, since oq.reobserve might make a network\n        // request, and we don't want to trigger network requests for\n        // optimistic updates.\n        if (this.getDiff().fromOptimisticTransaction) {\n          oq[\"observe\"]();\n        } else {\n          oq.reobserve();\n        }\n      });\n    } else {\n      delete this.oqListener;\n    }\n  }\n\n  notify() {\n    cancelNotifyTimeout(this);\n\n    if (this.shouldNotify()) {\n      this.listeners.forEach(listener => listener(this));\n    }\n\n    this.dirty = false;\n  }\n\n  private shouldNotify() {\n    if (!this.dirty || !this.listeners.size) {\n      return false;\n    }\n\n    if (isNetworkRequestInFlight(this.networkStatus) &&\n        this.observableQuery) {\n      const { fetchPolicy } = this.observableQuery.options;\n      if (fetchPolicy !== \"cache-only\" &&\n          fetchPolicy !== \"cache-and-network\") {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  public stop() {\n    if (!this.stopped) {\n      this.stopped = true;\n\n      // Cancel the pending notify timeout\n      this.reset();\n\n      this.cancel();\n      // Revert back to the no-op version of cancel inherited from\n      // QueryInfo.prototype.\n      this.cancel = QueryInfo.prototype.cancel;\n\n      this.subscriptions.forEach(sub => sub.unsubscribe());\n\n      const oq = this.observableQuery;\n      if (oq) oq.stopPolling();\n    }\n  }\n\n  // This method is a no-op by default, until/unless overridden by the\n  // updateWatch method.\n  private cancel() {}\n\n  private lastWatch?: Cache.WatchOptions;\n\n  private updateWatch(variables = this.variables) {\n    const oq = this.observableQuery;\n    if (oq && oq.options.fetchPolicy === \"no-cache\") {\n      return;\n    }\n\n    const watchOptions: Cache.WatchOptions = {\n      // Although this.getDiffOptions returns Cache.DiffOptions instead of\n      // Cache.WatchOptions, all the overlapping options should be the same, so\n      // we can reuse getDiffOptions here, for consistency.\n      ...this.getDiffOptions(variables),\n      watcher: this,\n      callback: diff => this.setDiff(diff),\n    };\n\n    if (!this.lastWatch ||\n        !equal(watchOptions, this.lastWatch)) {\n      this.cancel();\n      this.cancel = this.cache.watch(this.lastWatch = watchOptions);\n    }\n  }\n\n  private lastWrite?: {\n    result: FetchResult<any>;\n    variables: WatchQueryOptions[\"variables\"];\n    dmCount: number | undefined;\n  };\n\n  public resetLastWrite() {\n    this.lastWrite = void 0;\n  }\n\n  private shouldWrite(\n    result: FetchResult<any>,\n    variables: WatchQueryOptions[\"variables\"],\n  ) {\n    const { lastWrite } = this;\n    return !(\n      lastWrite &&\n      // If cache.evict has been called since the last time we wrote this\n      // data into the cache, there's a chance writing this result into\n      // the cache will repair what was evicted.\n      lastWrite.dmCount === destructiveMethodCounts.get(this.cache) &&\n      equal(variables, lastWrite.variables) &&\n      equal(result.data, lastWrite.result.data)\n    );\n  }\n\n  public markResult<T>(\n    result: FetchResult<T>,\n    options: Pick<WatchQueryOptions,\n      | \"variables\"\n      | \"fetchPolicy\"\n      | \"errorPolicy\">,\n    cacheWriteBehavior: CacheWriteBehavior,\n  ) {\n    this.graphQLErrors = isNonEmptyArray(result.errors) ? result.errors : [];\n\n    // Cancel the pending notify timeout (if it exists) to prevent extraneous network\n    // requests. To allow future notify timeouts, diff and dirty are reset as well.\n    this.reset();\n\n    if (options.fetchPolicy === 'no-cache') {\n      this.updateLastDiff(\n        { result: result.data, complete: true },\n        this.getDiffOptions(options.variables),\n      );\n\n    } else if (cacheWriteBehavior !== CacheWriteBehavior.FORBID) {\n      if (shouldWriteResult(result, options.errorPolicy)) {\n        // Using a transaction here so we have a chance to read the result\n        // back from the cache before the watch callback fires as a result\n        // of writeQuery, so we can store the new diff quietly and ignore\n        // it when we receive it redundantly from the watch callback.\n        this.cache.performTransaction(cache => {\n          if (this.shouldWrite(result, options.variables)) {\n            cache.writeQuery({\n              query: this.document!,\n              data: result.data as T,\n              variables: options.variables,\n              overwrite: cacheWriteBehavior === CacheWriteBehavior.OVERWRITE,\n            });\n\n            this.lastWrite = {\n              result,\n              variables: options.variables,\n              dmCount: destructiveMethodCounts.get(this.cache),\n            };\n          } else {\n            // If result is the same as the last result we received from\n            // the network (and the variables match too), avoid writing\n            // result into the cache again. The wisdom of skipping this\n            // cache write is far from obvious, since any cache write\n            // could be the one that puts the cache back into a desired\n            // state, fixing corruption or missing data. However, if we\n            // always write every network result into the cache, we enable\n            // feuds between queries competing to update the same data in\n            // incompatible ways, which can lead to an endless cycle of\n            // cache broadcasts and useless network requests. As with any\n            // feud, eventually one side must step back from the brink,\n            // letting the other side(s) have the last word(s). There may\n            // be other points where we could break this cycle, such as\n            // silencing the broadcast for cache.writeQuery (not a good\n            // idea, since it just delays the feud a bit) or somehow\n            // avoiding the network request that just happened (also bad,\n            // because the server could return useful new data). All\n            // options considered, skipping this cache write seems to be\n            // the least damaging place to break the cycle, because it\n            // reflects the intuition that we recently wrote this exact\n            // result into the cache, so the cache *should* already/still\n            // contain this data. If some other query has clobbered that\n            // data in the meantime, that's too bad, but there will be no\n            // winners if every query blindly reverts to its own version\n            // of the data. This approach also gives the network a chance\n            // to return new data, which will be written into the cache as\n            // usual, notifying only those queries that are directly\n            // affected by the cache updates, as usual. In the future, an\n            // even more sophisticated cache could perhaps prevent or\n            // mitigate the clobbering somehow, but that would make this\n            // particular cache write even less important, and thus\n            // skipping it would be even safer than it is today.\n            if (this.lastDiff &&\n                this.lastDiff.diff.complete) {\n              // Reuse data from the last good (complete) diff that we\n              // received, when possible.\n              result.data = this.lastDiff.diff.result;\n              return;\n            }\n            // If the previous this.diff was incomplete, fall through to\n            // re-reading the latest data with cache.diff, below.\n          }\n\n          const diffOptions = this.getDiffOptions(options.variables);\n          const diff = cache.diff<T>(diffOptions);\n\n          // In case the QueryManager stops this QueryInfo before its\n          // results are delivered, it's important to avoid restarting the\n          // cache watch when markResult is called.\n          if (!this.stopped) {\n            // Any time we're about to update this.diff, we need to make\n            // sure we've started watching the cache.\n            this.updateWatch(options.variables);\n          }\n\n          // If we're allowed to write to the cache, and we can read a\n          // complete result from the cache, update result.data to be the\n          // result from the cache, rather than the raw network result.\n          // Set without setDiff to avoid triggering a notify call, since\n          // we have other ways of notifying for this result.\n          this.updateLastDiff(diff, diffOptions);\n          if (diff.complete) {\n            result.data = diff.result;\n          }\n        });\n      } else {\n        this.lastWrite = void 0;\n      }\n    }\n  }\n\n  public markReady() {\n    this.networkError = null;\n    return this.networkStatus = NetworkStatus.ready;\n  }\n\n  public markError(error: ApolloError) {\n    this.networkStatus = NetworkStatus.error;\n    this.lastWrite = void 0;\n\n    this.reset();\n\n    if (error.graphQLErrors) {\n      this.graphQLErrors = error.graphQLErrors;\n    }\n\n    if (error.networkError) {\n      this.networkError = error.networkError;\n    }\n\n    return error;\n  }\n}\n\nexport function shouldWriteResult<T>(\n  result: FetchResult<T>,\n  errorPolicy: ErrorPolicy = \"none\",\n) {\n  const ignoreErrors =\n    errorPolicy === \"ignore\" ||\n    errorPolicy === \"all\";\n  let writeWithErrors = !graphQLResultHasError(result);\n  if (!writeWithErrors && ignoreErrors && result.data) {\n    writeWithErrors = true;\n  }\n  return writeWithErrors;\n}\n", "import { invariant, InvariantError } from '../utilities/globals';\n\nimport { DocumentNode } from 'graphql';\n// TODO(brian): A hack until this issue is resolved (https://github.com/graphql/graphql-js/issues/3356)\ntype OperationTypeNode = any;\nimport { equal } from '@wry/equality';\n\nimport { ApolloLink, execute, FetchResult } from '../link/core';\nimport { Cache, ApolloCache, canonicalStringify } from '../cache';\n\nimport {\n  getDefaultValues,\n  getOperationDefinition,\n  getOperationName,\n  hasClientExports,\n  graphQLResultHasError,\n  removeConnectionDirectiveFromDocument,\n  canUseWeakMap,\n  ObservableSubscription,\n  Observable,\n  asyncMap,\n  isNonEmptyArray,\n  Concast,\n  ConcastSourcesIterable,\n  makeUniqueId,\n  isDocumentNode,\n  isNonNullObject,\n} from '../utilities';\nimport { ApolloError, isApolloError } from '../errors';\nimport {\n  QueryOptions,\n  WatchQueryOptions,\n  SubscriptionOptions,\n  MutationOptions,\n  WatchQueryFetchPolicy,\n  ErrorPolicy,\n  MutationFetchPolicy,\n} from './watchQueryOptions';\nimport { ObservableQuery, applyNextFetchPolicy, logMissingFieldErrors } from './ObservableQuery';\nimport { NetworkStatus, isNetworkRequestInFlight } from './networkStatus';\nimport {\n  ApolloQueryResult,\n  OperationVariables,\n  MutationUpdaterFunction,\n  OnQueryUpdated,\n  InternalRefetchQueriesInclude,\n  InternalRefetchQueriesOptions,\n  InternalRefetchQueriesResult,\n  InternalRefetchQueriesMap,\n} from './types';\nimport { LocalState } from './LocalState';\n\nimport {\n  QueryInfo,\n  QueryStoreValue,\n  shouldWriteResult,\n  CacheWriteBehavior,\n} from './QueryInfo';\n\nconst { hasOwnProperty } = Object.prototype;\n\ninterface MutationStoreValue {\n  mutation: DocumentNode;\n  variables: Record<string, any>;\n  loading: boolean;\n  error: Error | null;\n}\n\ntype UpdateQueries<TData> = MutationOptions<TData, any, any>[\"updateQueries\"];\n\ninterface TransformCacheEntry {\n  document: DocumentNode;\n  hasClientExports: boolean;\n  hasForcedResolvers: boolean;\n  clientQuery: DocumentNode | null;\n  serverQuery: DocumentNode | null;\n  defaultVars: OperationVariables;\n  asQuery: DocumentNode;\n}\n\nexport class QueryManager<TStore> {\n  public cache: ApolloCache<TStore>;\n  public link: ApolloLink;\n  public readonly assumeImmutableResults: boolean;\n  public readonly ssrMode: boolean;\n\n  private queryDeduplication: boolean;\n  private clientAwareness: Record<string, string> = {};\n  private localState: LocalState<TStore>;\n\n  private onBroadcast?: () => void;\n  public mutationStore?: {\n    [mutationId: string]: MutationStoreValue;\n  };\n\n  // All the queries that the QueryManager is currently managing (not\n  // including mutations and subscriptions).\n  private queries = new Map<string, QueryInfo>();\n\n  // Maps from queryId strings to Promise rejection functions for\n  // currently active queries and fetches.\n  private fetchCancelFns = new Map<string, (error: any) => any>();\n\n  constructor({\n    cache,\n    link,\n    queryDeduplication = false,\n    onBroadcast,\n    ssrMode = false,\n    clientAwareness = {},\n    localState,\n    assumeImmutableResults,\n  }: {\n    cache: ApolloCache<TStore>;\n    link: ApolloLink;\n    queryDeduplication?: boolean;\n    onBroadcast?: () => void;\n    ssrMode?: boolean;\n    clientAwareness?: Record<string, string>;\n    localState?: LocalState<TStore>;\n    assumeImmutableResults?: boolean;\n  }) {\n    this.cache = cache;\n    this.link = link;\n    this.queryDeduplication = queryDeduplication;\n    this.clientAwareness = clientAwareness;\n    this.localState = localState || new LocalState({ cache });\n    this.ssrMode = ssrMode;\n    this.assumeImmutableResults = !!assumeImmutableResults;\n    if ((this.onBroadcast = onBroadcast)) {\n      this.mutationStore = Object.create(null);\n    }\n  }\n\n  /**\n   * Call this method to terminate any active query processes, making it safe\n   * to dispose of this QueryManager instance.\n   */\n  public stop() {\n    this.queries.forEach((_info, queryId) => {\n      this.stopQueryNoBroadcast(queryId);\n    });\n\n    this.cancelPendingFetches(\n      new InvariantError('QueryManager stopped while query was in flight'),\n    );\n  }\n\n  private cancelPendingFetches(error: Error) {\n    this.fetchCancelFns.forEach(cancel => cancel(error));\n    this.fetchCancelFns.clear();\n  }\n\n  public async mutate<\n    TData,\n    TVariables,\n    TContext,\n    TCache extends ApolloCache<any>\n  >({\n    mutation,\n    variables,\n    optimisticResponse,\n    updateQueries,\n    refetchQueries = [],\n    awaitRefetchQueries = false,\n    update: updateWithProxyFn,\n    onQueryUpdated,\n    errorPolicy = 'none',\n    fetchPolicy = 'network-only',\n    keepRootFields,\n    context,\n  }: MutationOptions<TData, TVariables, TContext>): Promise<FetchResult<TData>> {\n    invariant(\n      mutation,\n      'mutation option is required. You must specify your GraphQL document in the mutation option.',\n    );\n\n    invariant(\n      fetchPolicy === 'network-only' ||\n      fetchPolicy === 'no-cache',\n      \"Mutations support only 'network-only' or 'no-cache' fetchPolicy strings. The default `network-only` behavior automatically writes mutation results to the cache. Passing `no-cache` skips the cache write.\"\n    );\n\n    const mutationId = this.generateMutationId();\n    mutation = this.transform(mutation).document;\n\n    variables = this.getVariables(mutation, variables) as TVariables;\n\n    if (this.transform(mutation).hasClientExports) {\n      variables = await this.localState.addExportedVariables(mutation, variables, context) as TVariables;\n    }\n\n    const mutationStoreValue =\n      this.mutationStore &&\n      (this.mutationStore[mutationId] = {\n        mutation,\n        variables,\n        loading: true,\n        error: null,\n      } as MutationStoreValue);\n\n    if (optimisticResponse) {\n      this.markMutationOptimistic<\n        TData,\n        TVariables,\n        TContext,\n        TCache\n      >(optimisticResponse, {\n        mutationId,\n        document: mutation,\n        variables,\n        fetchPolicy,\n        errorPolicy,\n        context,\n        updateQueries,\n        update: updateWithProxyFn,\n        keepRootFields,\n      });\n    }\n\n    this.broadcastQueries();\n\n    const self = this;\n\n    return new Promise((resolve, reject) => {\n      return asyncMap(\n        self.getObservableFromLink(\n          mutation,\n          {\n            ...context,\n            optimisticResponse,\n          },\n          variables,\n          false,\n        ),\n\n        (result: FetchResult<TData>) => {\n          if (graphQLResultHasError(result) && errorPolicy === 'none') {\n            throw new ApolloError({\n              graphQLErrors: result.errors,\n            });\n          }\n\n          if (mutationStoreValue) {\n            mutationStoreValue.loading = false;\n            mutationStoreValue.error = null;\n          }\n\n          const storeResult: typeof result = { ...result };\n\n          if (typeof refetchQueries === \"function\") {\n            refetchQueries = refetchQueries(storeResult);\n          }\n\n          if (errorPolicy === 'ignore' &&\n              graphQLResultHasError(storeResult)) {\n            delete storeResult.errors;\n          }\n\n          return self.markMutationResult<\n            TData,\n            TVariables,\n            TContext,\n            TCache\n          >({\n            mutationId,\n            result: storeResult,\n            document: mutation,\n            variables,\n            fetchPolicy,\n            errorPolicy,\n            context,\n            update: updateWithProxyFn,\n            updateQueries,\n            awaitRefetchQueries,\n            refetchQueries,\n            removeOptimistic: optimisticResponse ? mutationId : void 0,\n            onQueryUpdated,\n            keepRootFields,\n          });\n        },\n\n      ).subscribe({\n        next(storeResult) {\n          self.broadcastQueries();\n\n          // At the moment, a mutation can have only one result, so we can\n          // immediately resolve upon receiving the first result. In the future,\n          // mutations containing @defer or @stream directives might receive\n          // multiple FetchResult payloads from the ApolloLink chain, so we will\n          // probably need to collect those results in this next method and call\n          // resolve only later, in an observer.complete function.\n          resolve(storeResult);\n        },\n\n        error(err: Error) {\n          if (mutationStoreValue) {\n            mutationStoreValue.loading = false;\n            mutationStoreValue.error = err;\n          }\n\n          if (optimisticResponse) {\n            self.cache.removeOptimistic(mutationId);\n          }\n\n          self.broadcastQueries();\n\n          reject(\n            err instanceof ApolloError ? err : new ApolloError({\n              networkError: err,\n            }),\n          );\n        },\n      });\n    });\n  }\n\n  public markMutationResult<\n    TData,\n    TVariables,\n    TContext,\n    TCache extends ApolloCache<any>\n  >(\n    mutation: {\n      mutationId: string;\n      result: FetchResult<TData>;\n      document: DocumentNode;\n      variables?: TVariables;\n      fetchPolicy?: MutationFetchPolicy;\n      errorPolicy: ErrorPolicy;\n      context?: TContext;\n      updateQueries: UpdateQueries<TData>;\n      update?: MutationUpdaterFunction<TData, TVariables, TContext, TCache>;\n      awaitRefetchQueries?: boolean;\n      refetchQueries?: InternalRefetchQueriesInclude;\n      removeOptimistic?: string;\n      onQueryUpdated?: OnQueryUpdated<any>;\n      keepRootFields?: boolean;\n    },\n    cache = this.cache,\n  ): Promise<FetchResult<TData>> {\n    let { result } = mutation;\n    const cacheWrites: Cache.WriteOptions[] = [];\n    const skipCache = mutation.fetchPolicy === \"no-cache\";\n\n    if (!skipCache && shouldWriteResult(result, mutation.errorPolicy)) {\n      cacheWrites.push({\n        result: result.data,\n        dataId: 'ROOT_MUTATION',\n        query: mutation.document,\n        variables: mutation.variables,\n      });\n\n      const { updateQueries } = mutation;\n      if (updateQueries) {\n        this.queries.forEach(({ observableQuery }, queryId) => {\n          const queryName = observableQuery && observableQuery.queryName;\n          if (!queryName || !hasOwnProperty.call(updateQueries, queryName)) {\n            return;\n          }\n          const updater = updateQueries[queryName];\n          const { document, variables } = this.queries.get(queryId)!;\n\n          // Read the current query result from the store.\n          const { result: currentQueryResult, complete } = cache.diff<TData>({\n            query: document!,\n            variables,\n            returnPartialData: true,\n            optimistic: false,\n          });\n\n          if (complete && currentQueryResult) {\n            // Run our reducer using the current query result and the mutation result.\n            const nextQueryResult = updater(currentQueryResult, {\n              mutationResult: result,\n              queryName: document && getOperationName(document) || void 0,\n              queryVariables: variables!,\n            });\n\n            // Write the modified result back into the store if we got a new result.\n            if (nextQueryResult) {\n              cacheWrites.push({\n                result: nextQueryResult,\n                dataId: 'ROOT_QUERY',\n                query: document!,\n                variables,\n              });\n            }\n          }\n        });\n      }\n    }\n\n    if (\n      cacheWrites.length > 0 ||\n      mutation.refetchQueries ||\n      mutation.update ||\n      mutation.onQueryUpdated ||\n      mutation.removeOptimistic\n    ) {\n      const results: any[] = [];\n\n      this.refetchQueries({\n        updateCache: (cache: TCache) => {\n          if (!skipCache) {\n            cacheWrites.forEach(write => cache.write(write));\n          }\n\n          // If the mutation has some writes associated with it then we need to\n          // apply those writes to the store by running this reducer again with\n          // a write action.\n          const { update } = mutation;\n          if (update) {\n            if (!skipCache) {\n              // Re-read the ROOT_MUTATION data we just wrote into the cache\n              // (the first cache.write call in the cacheWrites.forEach loop\n              // above), so field read functions have a chance to run for\n              // fields within mutation result objects.\n              const diff = cache.diff<TData>({\n                id: \"ROOT_MUTATION\",\n                // The cache complains if passed a mutation where it expects a\n                // query, so we transform mutations and subscriptions to queries\n                // (only once, thanks to this.transformCache).\n                query: this.transform(mutation.document).asQuery,\n                variables: mutation.variables,\n                optimistic: false,\n                returnPartialData: true,\n              });\n\n              if (diff.complete) {\n                result = { ...result, data: diff.result };\n              }\n            }\n\n            update(cache, result, {\n              context: mutation.context,\n              variables: mutation.variables,\n            });\n          }\n\n          // TODO Do this with cache.evict({ id: 'ROOT_MUTATION' }) but make it\n          // shallow to allow rolling back optimistic evictions.\n          if (!skipCache && !mutation.keepRootFields) {\n            cache.modify({\n              id: 'ROOT_MUTATION',\n              fields(value, { fieldName, DELETE }) {\n                return fieldName === \"__typename\" ? value : DELETE;\n              },\n            });\n          }\n        },\n\n        include: mutation.refetchQueries,\n\n        // Write the final mutation.result to the root layer of the cache.\n        optimistic: false,\n\n        // Remove the corresponding optimistic layer at the same time as we\n        // write the final non-optimistic result.\n        removeOptimistic: mutation.removeOptimistic,\n\n        // Let the caller of client.mutate optionally determine the refetching\n        // behavior for watched queries after the mutation.update function runs.\n        // If no onQueryUpdated function was provided for this mutation, pass\n        // null instead of undefined to disable the default refetching behavior.\n        onQueryUpdated: mutation.onQueryUpdated || null,\n\n      }).forEach(result => results.push(result));\n\n      if (mutation.awaitRefetchQueries || mutation.onQueryUpdated) {\n        // Returning a promise here makes the mutation await that promise, so we\n        // include results in that promise's work if awaitRefetchQueries or an\n        // onQueryUpdated function was specified.\n        return Promise.all(results).then(() => result);\n      }\n    }\n\n    return Promise.resolve(result);\n  }\n\n  public markMutationOptimistic<TData, TVariables, TContext, TCache extends ApolloCache<any>>(\n    optimisticResponse: any,\n    mutation: {\n      mutationId: string;\n      document: DocumentNode;\n      variables?: TVariables;\n      fetchPolicy?: MutationFetchPolicy;\n      errorPolicy: ErrorPolicy;\n      context?: TContext;\n      updateQueries: UpdateQueries<TData>,\n      update?: MutationUpdaterFunction<TData, TVariables, TContext, TCache>;\n      keepRootFields?: boolean,\n    },\n  ) {\n    const data = typeof optimisticResponse === \"function\"\n      ? optimisticResponse(mutation.variables)\n      : optimisticResponse;\n\n    return this.cache.recordOptimisticTransaction(cache => {\n      try {\n        this.markMutationResult<TData, TVariables, TContext, TCache>({\n          ...mutation,\n          result: { data },\n        }, cache);\n      } catch (error) {\n        invariant.error(error);\n      }\n    }, mutation.mutationId);\n  }\n\n  public fetchQuery<TData, TVars>(\n    queryId: string,\n    options: WatchQueryOptions<TVars, TData>,\n    networkStatus?: NetworkStatus,\n  ): Promise<ApolloQueryResult<TData>> {\n    return this.fetchQueryObservable<TData, TVars>(\n      queryId,\n      options,\n      networkStatus,\n    ).promise;\n  }\n\n  public getQueryStore() {\n    const store: Record<string, QueryStoreValue> = Object.create(null);\n    this.queries.forEach((info, queryId) => {\n      store[queryId] = {\n        variables: info.variables,\n        networkStatus: info.networkStatus,\n        networkError: info.networkError,\n        graphQLErrors: info.graphQLErrors,\n      };\n    });\n    return store;\n  }\n\n  public resetErrors(queryId: string) {\n    const queryInfo = this.queries.get(queryId);\n    if (queryInfo) {\n      queryInfo.networkError = undefined;\n      queryInfo.graphQLErrors = [];\n    }\n  }\n\n  private transformCache = new (\n    canUseWeakMap ? WeakMap : Map\n  )<DocumentNode, TransformCacheEntry>();\n\n  public transform(document: DocumentNode) {\n    const { transformCache } = this;\n\n    if (!transformCache.has(document)) {\n      const transformed = this.cache.transformDocument(document);\n      const forLink = removeConnectionDirectiveFromDocument(\n        this.cache.transformForLink(transformed));\n\n      const clientQuery = this.localState.clientQuery(transformed);\n      const serverQuery = forLink && this.localState.serverQuery(forLink);\n\n      const cacheEntry: TransformCacheEntry = {\n        document: transformed,\n        // TODO These two calls (hasClientExports and shouldForceResolvers)\n        // could probably be merged into a single traversal.\n        hasClientExports: hasClientExports(transformed),\n        hasForcedResolvers: this.localState.shouldForceResolvers(transformed),\n        clientQuery,\n        serverQuery,\n        defaultVars: getDefaultValues(\n          getOperationDefinition(transformed)\n        ) as OperationVariables,\n        // Transform any mutation or subscription operations to query operations\n        // so we can read/write them from/to the cache.\n        asQuery: {\n          ...transformed,\n          definitions: transformed.definitions.map(def => {\n            if (def.kind === \"OperationDefinition\" &&\n                def.operation !== \"query\") {\n              return { ...def, operation: \"query\" as OperationTypeNode };\n            }\n            return def;\n          }),\n        }\n      };\n\n      const add = (doc: DocumentNode | null) => {\n        if (doc && !transformCache.has(doc)) {\n          transformCache.set(doc, cacheEntry);\n        }\n      }\n      // Add cacheEntry to the transformCache using several different keys,\n      // since any one of these documents could end up getting passed to the\n      // transform method again in the future.\n      add(document);\n      add(transformed);\n      add(clientQuery);\n      add(serverQuery);\n    }\n\n    return transformCache.get(document)!;\n  }\n\n  private getVariables<TVariables>(\n    document: DocumentNode,\n    variables?: TVariables,\n  ): OperationVariables {\n    return {\n      ...this.transform(document).defaultVars,\n      ...variables,\n    };\n  }\n\n  public watchQuery<T, TVariables = OperationVariables>(\n    options: WatchQueryOptions<TVariables, T>,\n  ): ObservableQuery<T, TVariables> {\n    // assign variable default values if supplied\n    options = {\n      ...options,\n      variables: this.getVariables(\n        options.query,\n        options.variables,\n      ) as TVariables,\n    };\n\n    if (typeof options.notifyOnNetworkStatusChange === 'undefined') {\n      options.notifyOnNetworkStatusChange = false;\n    }\n\n    const queryInfo = new QueryInfo(this);\n    const observable = new ObservableQuery<T, TVariables>({\n      queryManager: this,\n      queryInfo,\n      options,\n    });\n\n    this.queries.set(observable.queryId, queryInfo);\n\n    queryInfo.init({\n      document: options.query,\n      observableQuery: observable,\n      variables: options.variables,\n    });\n\n    return observable;\n  }\n\n  public query<TData, TVars = OperationVariables>(\n    options: QueryOptions<TVars, TData>,\n    queryId = this.generateQueryId(),\n  ): Promise<ApolloQueryResult<TData>> {\n    invariant(\n      options.query,\n      'query option is required. You must specify your GraphQL document ' +\n        'in the query option.',\n    );\n\n    invariant(\n      options.query.kind === 'Document',\n      'You must wrap the query string in a \"gql\" tag.',\n    );\n\n    invariant(\n      !(options as any).returnPartialData,\n      'returnPartialData option only supported on watchQuery.',\n    );\n\n    invariant(\n      !(options as any).pollInterval,\n      'pollInterval option only supported on watchQuery.',\n    );\n\n    return this.fetchQuery<TData, TVars>(\n      queryId,\n      options,\n    ).finally(() => this.stopQuery(queryId));\n  }\n\n  private queryIdCounter = 1;\n  public generateQueryId() {\n    return String(this.queryIdCounter++);\n  }\n\n  private requestIdCounter = 1;\n  public generateRequestId() {\n    return this.requestIdCounter++;\n  }\n\n  private mutationIdCounter = 1;\n  public generateMutationId() {\n    return String(this.mutationIdCounter++);\n  }\n\n  public stopQueryInStore(queryId: string) {\n    this.stopQueryInStoreNoBroadcast(queryId);\n    this.broadcastQueries();\n  }\n\n  private stopQueryInStoreNoBroadcast(queryId: string) {\n    const queryInfo = this.queries.get(queryId);\n    if (queryInfo) queryInfo.stop();\n  }\n\n  public clearStore(options: Cache.ResetOptions = {\n    discardWatches: true,\n  }): Promise<void> {\n    // Before we have sent the reset action to the store, we can no longer\n    // rely on the results returned by in-flight requests since these may\n    // depend on values that previously existed in the data portion of the\n    // store. So, we cancel the promises and observers that we have issued\n    // so far and not yet resolved (in the case of queries).\n    this.cancelPendingFetches(new InvariantError(\n      'Store reset while query was in flight (not completed in link chain)',\n    ));\n\n    this.queries.forEach(queryInfo => {\n      if (queryInfo.observableQuery) {\n        // Set loading to true so listeners don't trigger unless they want\n        // results with partial data.\n        queryInfo.networkStatus = NetworkStatus.loading;\n      } else {\n        queryInfo.stop();\n      }\n    });\n\n    if (this.mutationStore) {\n      this.mutationStore = Object.create(null);\n    }\n\n    // begin removing data from the store\n    return this.cache.reset(options);\n  }\n\n  public getObservableQueries(\n    include: InternalRefetchQueriesInclude = \"active\",\n  ) {\n    const queries = new Map<string, ObservableQuery<any>>();\n    const queryNamesAndDocs = new Map<string | DocumentNode, boolean>();\n    const legacyQueryOptions = new Set<QueryOptions>();\n\n    if (Array.isArray(include)) {\n      include.forEach(desc => {\n        if (typeof desc === \"string\") {\n          queryNamesAndDocs.set(desc, false);\n        } else if (isDocumentNode(desc)) {\n          queryNamesAndDocs.set(this.transform(desc).document, false);\n        } else if (isNonNullObject(desc) && desc.query) {\n          legacyQueryOptions.add(desc);\n        }\n      });\n    }\n\n    this.queries.forEach(({ observableQuery: oq, document }, queryId) => {\n      if (oq) {\n        if (include === \"all\") {\n          queries.set(queryId, oq);\n          return;\n        }\n\n        const {\n          queryName,\n          options: { fetchPolicy },\n        } = oq;\n\n        if (\n          fetchPolicy === \"standby\" ||\n          (include === \"active\" && !oq.hasObservers())\n        ) {\n          return;\n        }\n\n        if (\n          include === \"active\" ||\n          (queryName && queryNamesAndDocs.has(queryName)) ||\n          (document && queryNamesAndDocs.has(document))\n        ) {\n          queries.set(queryId, oq);\n          if (queryName) queryNamesAndDocs.set(queryName, true);\n          if (document) queryNamesAndDocs.set(document, true);\n        }\n      }\n    });\n\n    if (legacyQueryOptions.size) {\n      legacyQueryOptions.forEach((options: QueryOptions) => {\n        // We will be issuing a fresh network request for this query, so we\n        // pre-allocate a new query ID here, using a special prefix to enable\n        // cleaning up these temporary queries later, after fetching.\n        const queryId = makeUniqueId(\"legacyOneTimeQuery\");\n        const queryInfo = this.getQuery(queryId).init({\n          document: options.query,\n          variables: options.variables,\n        });\n        const oq = new ObservableQuery({\n          queryManager: this,\n          queryInfo,\n          options: {\n            ...options,\n            fetchPolicy: \"network-only\",\n          },\n        });\n        invariant(oq.queryId === queryId);\n        queryInfo.setObservableQuery(oq);\n        queries.set(queryId, oq);\n      });\n    }\n\n    if (__DEV__ && queryNamesAndDocs.size) {\n      queryNamesAndDocs.forEach((included, nameOrDoc) => {\n        if (!included) {\n          invariant.warn(`Unknown query ${\n            typeof nameOrDoc === \"string\" ? \"named \" : \"\"\n          }${\n            JSON.stringify(nameOrDoc, null, 2)\n          } requested in refetchQueries options.include array`);\n        }\n      });\n    }\n\n    return queries;\n  }\n\n  public reFetchObservableQueries(\n    includeStandby: boolean = false,\n  ): Promise<ApolloQueryResult<any>[]> {\n    const observableQueryPromises: Promise<ApolloQueryResult<any>>[] = [];\n\n    this.getObservableQueries(\n      includeStandby ? \"all\" : \"active\"\n    ).forEach((observableQuery, queryId) => {\n      const { fetchPolicy } = observableQuery.options;\n      observableQuery.resetLastResults();\n      if (includeStandby ||\n          (fetchPolicy !== \"standby\" &&\n           fetchPolicy !== \"cache-only\")) {\n        observableQueryPromises.push(observableQuery.refetch());\n      }\n      this.getQuery(queryId).setDiff(null);\n    });\n\n    this.broadcastQueries();\n\n    return Promise.all(observableQueryPromises);\n  }\n\n  public setObservableQuery(observableQuery: ObservableQuery<any, any>) {\n    this.getQuery(observableQuery.queryId).setObservableQuery(observableQuery);\n  }\n\n  public startGraphQLSubscription<T = any>({\n    query,\n    fetchPolicy,\n    errorPolicy,\n    variables,\n    context = {},\n  }: SubscriptionOptions): Observable<FetchResult<T>> {\n    query = this.transform(query).document;\n    variables = this.getVariables(query, variables);\n\n    const makeObservable = (variables: OperationVariables) =>\n      this.getObservableFromLink<T>(\n        query,\n        context,\n        variables,\n      ).map(result => {\n        if (fetchPolicy !== 'no-cache') {\n          // the subscription interface should handle not sending us results we no longer subscribe to.\n          // XXX I don't think we ever send in an object with errors, but we might in the future...\n          if (shouldWriteResult(result, errorPolicy)) {\n            this.cache.write({\n              query,\n              result: result.data,\n              dataId: 'ROOT_SUBSCRIPTION',\n              variables: variables,\n            });\n          }\n\n          this.broadcastQueries();\n        }\n\n        if (graphQLResultHasError(result)) {\n          throw new ApolloError({\n            graphQLErrors: result.errors,\n          });\n        }\n\n        return result;\n      });\n\n    if (this.transform(query).hasClientExports) {\n      const observablePromise = this.localState.addExportedVariables(\n        query,\n        variables,\n        context,\n      ).then(makeObservable);\n\n      return new Observable<FetchResult<T>>(observer => {\n        let sub: ObservableSubscription | null = null;\n        observablePromise.then(\n          observable => sub = observable.subscribe(observer),\n          observer.error,\n        );\n        return () => sub && sub.unsubscribe();\n      });\n    }\n\n    return makeObservable(variables);\n  }\n\n  public stopQuery(queryId: string) {\n    this.stopQueryNoBroadcast(queryId);\n    this.broadcastQueries();\n  }\n\n  private stopQueryNoBroadcast(queryId: string) {\n    this.stopQueryInStoreNoBroadcast(queryId);\n    this.removeQuery(queryId);\n  }\n\n  public removeQuery(queryId: string) {\n    // teardown all links\n    // Both `QueryManager.fetchRequest` and `QueryManager.query` create separate promises\n    // that each add their reject functions to fetchCancelFns.\n    // A query created with `QueryManager.query()` could trigger a `QueryManager.fetchRequest`.\n    // The same queryId could have two rejection fns for two promises\n    this.fetchCancelFns.delete(queryId);\n    this.getQuery(queryId).stop();\n    this.queries.delete(queryId);\n  }\n\n  public broadcastQueries() {\n    if (this.onBroadcast) this.onBroadcast();\n    this.queries.forEach(info => info.notify());\n  }\n\n  public getLocalState(): LocalState<TStore> {\n    return this.localState;\n  }\n\n  private inFlightLinkObservables = new Map<\n    DocumentNode,\n    Map<string, Observable<FetchResult>>\n  >();\n\n  private getObservableFromLink<T = any>(\n    query: DocumentNode,\n    context: any,\n    variables?: OperationVariables,\n    deduplication: boolean =\n      // Prefer context.queryDeduplication if specified.\n      context?.queryDeduplication ??\n      this.queryDeduplication,\n  ): Observable<FetchResult<T>> {\n    let observable: Observable<FetchResult<T>>;\n\n    const { serverQuery } = this.transform(query);\n    if (serverQuery) {\n      const { inFlightLinkObservables, link } = this;\n\n      const operation = {\n        query: serverQuery,\n        variables,\n        operationName: getOperationName(serverQuery) || void 0,\n        context: this.prepareContext({\n          ...context,\n          forceFetch: !deduplication\n        }),\n      };\n\n      context = operation.context;\n\n      if (deduplication) {\n        const byVariables = inFlightLinkObservables.get(serverQuery) || new Map();\n        inFlightLinkObservables.set(serverQuery, byVariables);\n\n        const varJson = canonicalStringify(variables);\n        observable = byVariables.get(varJson);\n\n        if (!observable) {\n          const concast = new Concast([\n            execute(link, operation) as Observable<FetchResult<T>>\n          ]);\n\n          byVariables.set(varJson, observable = concast);\n\n          concast.cleanup(() => {\n            if (byVariables.delete(varJson) &&\n                byVariables.size < 1) {\n              inFlightLinkObservables.delete(serverQuery);\n            }\n          });\n        }\n\n      } else {\n        observable = new Concast([\n          execute(link, operation) as Observable<FetchResult<T>>\n        ]);\n      }\n    } else {\n      observable = new Concast([\n        Observable.of({ data: {} } as FetchResult<T>)\n      ]);\n      context = this.prepareContext(context);\n    }\n\n    const { clientQuery } = this.transform(query);\n    if (clientQuery) {\n      observable = asyncMap(observable, result => {\n        return this.localState.runResolvers({\n          document: clientQuery,\n          remoteResult: result,\n          context,\n          variables,\n        });\n      });\n    }\n\n    return observable;\n  }\n\n  private getResultsFromLink<TData, TVars>(\n    queryInfo: QueryInfo,\n    cacheWriteBehavior: CacheWriteBehavior,\n    options: Pick<WatchQueryOptions<TVars, TData>,\n      | \"variables\"\n      | \"context\"\n      | \"fetchPolicy\"\n      | \"errorPolicy\">,\n  ): Observable<ApolloQueryResult<TData>> {\n    const requestId = queryInfo.lastRequestId = this.generateRequestId();\n\n    return asyncMap(\n      this.getObservableFromLink(\n        queryInfo.document!,\n        options.context,\n        options.variables,\n      ),\n\n      result => {\n        const hasErrors = isNonEmptyArray(result.errors);\n\n        // If we interrupted this request by calling getResultsFromLink again\n        // with the same QueryInfo object, we ignore the old results.\n        if (requestId >= queryInfo.lastRequestId) {\n          if (hasErrors && options.errorPolicy === \"none\") {\n            // Throwing here effectively calls observer.error.\n            throw queryInfo.markError(new ApolloError({\n              graphQLErrors: result.errors,\n            }));\n          }\n          queryInfo.markResult(result, options, cacheWriteBehavior);\n          queryInfo.markReady();\n        }\n\n        const aqr: ApolloQueryResult<TData> = {\n          data: result.data,\n          loading: false,\n          networkStatus: queryInfo.networkStatus || NetworkStatus.ready,\n        };\n\n        if (hasErrors && options.errorPolicy !== \"ignore\") {\n          aqr.errors = result.errors;\n        }\n\n        return aqr;\n      },\n\n      networkError => {\n        const error = isApolloError(networkError)\n          ? networkError\n          : new ApolloError({ networkError });\n\n        // Avoid storing errors from older interrupted queries.\n        if (requestId >= queryInfo.lastRequestId) {\n          queryInfo.markError(error);\n        }\n\n        throw error;\n      },\n    );\n  }\n\n  public fetchQueryObservable<TData, TVars>(\n    queryId: string,\n    options: WatchQueryOptions<TVars, TData>,\n    // The initial networkStatus for this fetch, most often\n    // NetworkStatus.loading, but also possibly fetchMore, poll, refetch,\n    // or setVariables.\n    networkStatus = NetworkStatus.loading,\n  ): Concast<ApolloQueryResult<TData>> {\n    const query = this.transform(options.query).document;\n    const variables = this.getVariables(query, options.variables) as TVars;\n    const queryInfo = this.getQuery(queryId);\n\n    let {\n      fetchPolicy = \"cache-first\" as WatchQueryFetchPolicy,\n      errorPolicy = \"none\" as ErrorPolicy,\n      returnPartialData = false,\n      notifyOnNetworkStatusChange = false,\n      context = {},\n    } = options;\n\n    const normalized = Object.assign({}, options, {\n      query,\n      variables,\n      fetchPolicy,\n      errorPolicy,\n      returnPartialData,\n      notifyOnNetworkStatusChange,\n      context,\n    });\n\n    const fromVariables = (variables: TVars) => {\n      // Since normalized is always a fresh copy of options, it's safe to\n      // modify its properties here, rather than creating yet another new\n      // WatchQueryOptions object.\n      normalized.variables = variables;\n      return this.fetchQueryByPolicy<TData, TVars>(\n        queryInfo,\n        normalized,\n        networkStatus,\n      );\n    };\n\n    // This cancel function needs to be set before the concast is created,\n    // in case concast creation synchronously cancels the request.\n    this.fetchCancelFns.set(queryId, reason => {\n      // This delay ensures the concast variable has been initialized.\n      setTimeout(() => concast.cancel(reason));\n    });\n\n    // A Concast<T> can be created either from an Iterable<Observable<T>>\n    // or from a PromiseLike<Iterable<Observable<T>>>, where T in this\n    // case is ApolloQueryResult<TData>.\n    const concast = new Concast(\n      // If the query has @export(as: ...) directives, then we need to\n      // process those directives asynchronously. When there are no\n      // @export directives (the common case), we deliberately avoid\n      // wrapping the result of this.fetchQueryByPolicy in a Promise,\n      // since the timing of result delivery is (unfortunately) important\n      // for backwards compatibility. TODO This code could be simpler if\n      // we deprecated and removed LocalState.\n      this.transform(normalized.query).hasClientExports\n        ? this.localState.addExportedVariables(\n          normalized.query,\n          normalized.variables,\n          normalized.context,\n        ).then(fromVariables)\n        : fromVariables(normalized.variables!)\n    );\n\n    concast.cleanup(() => {\n      this.fetchCancelFns.delete(queryId);\n      applyNextFetchPolicy(options);\n    });\n\n    return concast;\n  }\n\n  public refetchQueries<TResult>({\n    updateCache,\n    include,\n    optimistic = false,\n    removeOptimistic = optimistic ? makeUniqueId(\"refetchQueries\") : void 0,\n    onQueryUpdated,\n  }: InternalRefetchQueriesOptions<ApolloCache<TStore>, TResult>\n  ): InternalRefetchQueriesMap<TResult> {\n    const includedQueriesById = new Map<string, {\n      oq: ObservableQuery<any>;\n      lastDiff?: Cache.DiffResult<any>;\n      diff?: Cache.DiffResult<any>;\n    }>();\n\n    if (include) {\n      this.getObservableQueries(include).forEach((oq, queryId) => {\n        includedQueriesById.set(queryId, {\n          oq,\n          lastDiff: this.getQuery(queryId).getDiff(),\n        });\n      });\n    }\n\n    const results: InternalRefetchQueriesMap<TResult> = new Map;\n\n    if (updateCache) {\n      this.cache.batch({\n        update: updateCache,\n\n        // Since you can perform any combination of cache reads and/or writes in\n        // the cache.batch update function, its optimistic option can be either\n        // a boolean or a string, representing three distinct modes of\n        // operation:\n        //\n        // * false: read/write only the root layer\n        // * true: read/write the topmost layer\n        // * string: read/write a fresh optimistic layer with that ID string\n        //\n        // When typeof optimistic === \"string\", a new optimistic layer will be\n        // temporarily created within cache.batch with that string as its ID. If\n        // we then pass that same string as the removeOptimistic option, we can\n        // make cache.batch immediately remove the optimistic layer after\n        // running the updateCache function, triggering only one broadcast.\n        //\n        // However, the refetchQueries method accepts only true or false for its\n        // optimistic option (not string). We interpret true to mean a temporary\n        // optimistic layer should be created, to allow efficiently rolling back\n        // the effect of the updateCache function, which involves passing a\n        // string instead of true as the optimistic option to cache.batch, when\n        // refetchQueries receives optimistic: true.\n        //\n        // In other words, we are deliberately not supporting the use case of\n        // writing to an *existing* optimistic layer (using the refetchQueries\n        // updateCache function), since that would potentially interfere with\n        // other optimistic updates in progress. Instead, you can read/write\n        // only the root layer by passing optimistic: false to refetchQueries,\n        // or you can read/write a brand new optimistic layer that will be\n        // automatically removed by passing optimistic: true.\n        optimistic: optimistic && removeOptimistic || false,\n\n        // The removeOptimistic option can also be provided by itself, even if\n        // optimistic === false, to remove some previously-added optimistic\n        // layer safely and efficiently, like we do in markMutationResult.\n        //\n        // If an explicit removeOptimistic string is provided with optimistic:\n        // true, the removeOptimistic string will determine the ID of the\n        // temporary optimistic layer, in case that ever matters.\n        removeOptimistic,\n\n        onWatchUpdated(watch, diff, lastDiff) {\n          const oq =\n            watch.watcher instanceof QueryInfo &&\n            watch.watcher.observableQuery;\n\n          if (oq) {\n            if (onQueryUpdated) {\n              // Since we're about to handle this query now, remove it from\n              // includedQueriesById, in case it was added earlier because of\n              // options.include.\n              includedQueriesById.delete(oq.queryId);\n\n              let result: TResult | boolean | Promise<ApolloQueryResult<any>> =\n                onQueryUpdated(oq, diff, lastDiff);\n\n              if (result === true) {\n                // The onQueryUpdated function requested the default refetching\n                // behavior by returning true.\n                result = oq.refetch();\n              }\n\n              // Record the result in the results Map, as long as onQueryUpdated\n              // did not return false to skip/ignore this result.\n              if (result !== false) {\n                results.set(oq, result as InternalRefetchQueriesResult<TResult>);\n              }\n\n              // Allow the default cache broadcast to happen, except when\n              // onQueryUpdated returns false.\n              return result;\n            }\n\n            if (onQueryUpdated !== null) {\n              // If we don't have an onQueryUpdated function, and onQueryUpdated\n              // was not disabled by passing null, make sure this query is\n              // \"included\" like any other options.include-specified query.\n              includedQueriesById.set(oq.queryId, { oq, lastDiff, diff });\n            }\n          }\n        },\n      });\n    }\n\n    if (includedQueriesById.size) {\n      includedQueriesById.forEach(({ oq, lastDiff, diff }, queryId) => {\n        let result: TResult | boolean | Promise<ApolloQueryResult<any>> | undefined;\n\n        // If onQueryUpdated is provided, we want to use it for all included\n        // queries, even the QueryOptions ones.\n        if (onQueryUpdated) {\n          if (!diff) {\n            const info = oq[\"queryInfo\"];\n            info.reset(); // Force info.getDiff() to read from cache.\n            diff = info.getDiff();\n          }\n          result = onQueryUpdated(oq, diff, lastDiff);\n        }\n\n        // Otherwise, we fall back to refetching.\n        if (!onQueryUpdated || result === true) {\n          result = oq.refetch();\n        }\n\n        if (result !== false) {\n          results.set(oq, result as InternalRefetchQueriesResult<TResult>);\n        }\n\n        if (queryId.indexOf(\"legacyOneTimeQuery\") >= 0) {\n          this.stopQueryNoBroadcast(queryId);\n        }\n      });\n    }\n\n    if (removeOptimistic) {\n      // In case no updateCache callback was provided (so cache.batch was not\n      // called above, and thus did not already remove the optimistic layer),\n      // remove it here. Since this is a no-op when the layer has already been\n      // removed, we do it even if we called cache.batch above, since it's\n      // possible this.cache is an instance of some ApolloCache subclass other\n      // than InMemoryCache, and does not fully support the removeOptimistic\n      // option for cache.batch.\n      this.cache.removeOptimistic(removeOptimistic);\n    }\n\n    return results;\n  }\n\n  private fetchQueryByPolicy<TData, TVars>(\n    queryInfo: QueryInfo,\n    { query,\n      variables,\n      fetchPolicy,\n      refetchWritePolicy,\n      errorPolicy,\n      returnPartialData,\n      context,\n      notifyOnNetworkStatusChange,\n    }: WatchQueryOptions<TVars, TData>,\n    // The initial networkStatus for this fetch, most often\n    // NetworkStatus.loading, but also possibly fetchMore, poll, refetch,\n    // or setVariables.\n    networkStatus: NetworkStatus,\n  ): ConcastSourcesIterable<ApolloQueryResult<TData>> {\n    const oldNetworkStatus = queryInfo.networkStatus;\n\n    queryInfo.init({\n      document: query,\n      variables,\n      networkStatus,\n    });\n\n    const readCache = () => queryInfo.getDiff(variables);\n\n    const resultsFromCache = (\n      diff: Cache.DiffResult<TData>,\n      networkStatus = queryInfo.networkStatus || NetworkStatus.loading,\n    ) => {\n      const data = diff.result;\n\n      if (__DEV__ &&\n          !returnPartialData &&\n          !equal(data, {})) {\n        logMissingFieldErrors(diff.missing);\n      }\n\n      const fromData = (data: TData | undefined) => Observable.of({\n        data,\n        loading: isNetworkRequestInFlight(networkStatus),\n        networkStatus,\n        ...(diff.complete ? null : { partial: true }),\n      } as ApolloQueryResult<TData>);\n\n      if (data && this.transform(query).hasForcedResolvers) {\n        return this.localState.runResolvers({\n          document: query,\n          remoteResult: { data },\n          context,\n          variables,\n          onlyRunForcedResolvers: true,\n        }).then(resolved => fromData(resolved.data || void 0));\n      }\n\n      return fromData(data);\n    };\n\n    const cacheWriteBehavior =\n      fetchPolicy === \"no-cache\" ? CacheWriteBehavior.FORBID :\n      ( // Watched queries must opt into overwriting existing data on refetch,\n        // by passing refetchWritePolicy: \"overwrite\" in their WatchQueryOptions.\n        networkStatus === NetworkStatus.refetch &&\n        refetchWritePolicy !== \"merge\"\n      ) ? CacheWriteBehavior.OVERWRITE\n        : CacheWriteBehavior.MERGE;\n\n    const resultsFromLink = () =>\n      this.getResultsFromLink<TData, TVars>(queryInfo, cacheWriteBehavior, {\n        variables,\n        context,\n        fetchPolicy,\n        errorPolicy,\n      });\n\n    const shouldNotify =\n      notifyOnNetworkStatusChange &&\n      typeof oldNetworkStatus === \"number\" &&\n      oldNetworkStatus !== networkStatus &&\n      isNetworkRequestInFlight(networkStatus);\n\n    switch (fetchPolicy) {\n    default: case \"cache-first\": {\n      const diff = readCache();\n\n      if (diff.complete) {\n        return [\n          resultsFromCache(diff, queryInfo.markReady()),\n        ];\n      }\n\n      if (returnPartialData || shouldNotify) {\n        return [\n          resultsFromCache(diff),\n          resultsFromLink(),\n        ];\n      }\n\n      return [\n        resultsFromLink(),\n      ];\n    }\n\n    case \"cache-and-network\": {\n      const diff = readCache();\n\n      if (diff.complete || returnPartialData || shouldNotify) {\n        return [\n          resultsFromCache(diff),\n          resultsFromLink(),\n        ];\n      }\n\n      return [\n        resultsFromLink(),\n      ];\n    }\n\n    case \"cache-only\":\n      return [\n        resultsFromCache(readCache(), queryInfo.markReady()),\n      ];\n\n    case \"network-only\":\n      if (shouldNotify) {\n        return [\n          resultsFromCache(readCache()),\n          resultsFromLink(),\n        ];\n      }\n\n      return [resultsFromLink()];\n\n    case \"no-cache\":\n      if (shouldNotify) {\n        return [\n          // Note that queryInfo.getDiff() for no-cache queries does not call\n          // cache.diff, but instead returns a { complete: false } stub result\n          // when there is no queryInfo.diff already defined.\n          resultsFromCache(queryInfo.getDiff()),\n          resultsFromLink(),\n        ];\n      }\n\n      return [resultsFromLink()];\n\n    case \"standby\":\n      return [];\n    }\n  }\n\n  private getQuery(queryId: string): QueryInfo {\n    if (queryId && !this.queries.has(queryId)) {\n      this.queries.set(queryId, new QueryInfo(this, queryId));\n    }\n    return this.queries.get(queryId)!;\n  }\n\n  private prepareContext(context = {}) {\n    const newContext = this.localState.prepareContext(context);\n    return {\n      ...newContext,\n      clientAwareness: this.clientAwareness,\n    };\n  }\n}\n", "import { invariant, InvariantError } from '../utilities/globals';\n\nimport { ExecutionResult, DocumentNode } from 'graphql';\n\nimport { ApolloLink, FetchResult, GraphQLRequest, execute } from '../link/core';\nimport { ApolloCache, DataProxy } from '../cache';\nimport { Observable, compact } from '../utilities';\nimport { version } from '../version';\nimport { HttpLink, UriFunction } from '../link/http';\n\nimport { QueryManager } from './QueryManager';\nimport { ObservableQuery } from './ObservableQuery';\n\nimport {\n  ApolloQueryResult,\n  DefaultContext,\n  OperationVariables,\n  Resolvers,\n  RefetchQueriesOptions,\n  RefetchQueriesResult,\n  InternalRefetchQueriesResult,\n  RefetchQueriesInclude,\n} from './types';\n\nimport {\n  QueryOptions,\n  WatchQueryOptions,\n  MutationOptions,\n  SubscriptionOptions,\n  WatchQueryFetchPolicy,\n} from './watchQueryOptions';\n\nimport {\n  LocalState,\n  FragmentMatcher,\n} from './LocalState';\n\nexport interface DefaultOptions {\n  watchQuery?: Partial<WatchQueryOptions<any, any>>;\n  query?: Partial<QueryOptions<any, any>>;\n  mutate?: Partial<MutationOptions<any, any, any>>;\n}\n\nlet hasSuggestedDevtools = false;\n\nexport type ApolloClientOptions<TCacheShape> = {\n  uri?: string | UriFunction;\n  credentials?: string;\n  headers?: Record<string, string>;\n  link?: ApolloLink;\n  cache: ApolloCache<TCacheShape>;\n  ssrForceFetchDelay?: number;\n  ssrMode?: boolean;\n  connectToDevTools?: boolean;\n  queryDeduplication?: boolean;\n  defaultOptions?: DefaultOptions;\n  assumeImmutableResults?: boolean;\n  resolvers?: Resolvers | Resolvers[];\n  typeDefs?: string | string[] | DocumentNode | DocumentNode[];\n  fragmentMatcher?: FragmentMatcher;\n  name?: string;\n  version?: string;\n};\n\ntype OptionsUnion<TData, TVariables, TContext> =\n  | WatchQueryOptions<TVariables, TData>\n  | QueryOptions<TVariables, TData>\n  | MutationOptions<TData, TVariables, TContext>;\n\nexport function mergeOptions<\n  TOptions extends OptionsUnion<any, any, any>\n>(\n  defaults: Partial<TOptions>,\n  options: TOptions,\n): TOptions {\n  return compact(defaults, options, options.variables && {\n    variables: {\n      ...defaults.variables,\n      ...options.variables,\n    },\n  });\n}\n\n/**\n * This is the primary Apollo Client class. It is used to send GraphQL documents (i.e. queries\n * and mutations) to a GraphQL spec-compliant server over a {@link NetworkInterface} instance,\n * receive results from the server and cache the results in a store. It also delivers updates\n * to GraphQL queries through {@link Observable} instances.\n */\nexport class ApolloClient<TCacheShape> implements DataProxy {\n  public link: ApolloLink;\n  public cache: ApolloCache<TCacheShape>;\n  public disableNetworkFetches: boolean;\n  public version: string;\n  public queryDeduplication: boolean;\n  public defaultOptions: DefaultOptions = {};\n  public readonly typeDefs: ApolloClientOptions<TCacheShape>['typeDefs'];\n\n  private queryManager: QueryManager<TCacheShape>;\n  private devToolsHookCb: Function;\n  private resetStoreCallbacks: Array<() => Promise<any>> = [];\n  private clearStoreCallbacks: Array<() => Promise<any>> = [];\n  private localState: LocalState<TCacheShape>;\n\n  /**\n   * Constructs an instance of {@link ApolloClient}.\n   *\n   * @param uri The GraphQL endpoint that Apollo Client will connect to. If\n   *            `link` is configured, this option is ignored.\n   * @param link The {@link ApolloLink} over which GraphQL documents will be resolved into a response.\n   *\n   * @param cache The initial cache to use in the data store.\n   *\n   * @param ssrMode Determines whether this is being run in Server Side Rendering (SSR) mode.\n   *\n   * @param ssrForceFetchDelay Determines the time interval before we force fetch queries for a\n   * server side render.\n   *\n   * @param queryDeduplication If set to false, a query will still be sent to the server even if a query\n   * with identical parameters (query, variables, operationName) is already in flight.\n   *\n   * @param defaultOptions Used to set application wide defaults for the\n   *                       options supplied to `watchQuery`, `query`, or\n   *                       `mutate`.\n   *\n   * @param assumeImmutableResults When this option is true, the client will assume results\n   *                               read from the cache are never mutated by application code,\n   *                               which enables substantial performance optimizations. Passing\n   *                               `{ freezeResults: true }` to the `InMemoryCache` constructor\n   *                               can help enforce this immutability.\n   *\n   * @param name A custom name that can be used to identify this client, when\n   *             using Apollo client awareness features. E.g. \"iOS\".\n   *\n   * @param version A custom version that can be used to identify this client,\n   *                when using Apollo client awareness features. This is the\n   *                version of your client, which you may want to increment on\n   *                new builds. This is NOT the version of Apollo Client that\n   *                you are using.\n   */\n  constructor(options: ApolloClientOptions<TCacheShape>) {\n    const {\n      uri,\n      credentials,\n      headers,\n      cache,\n      ssrMode = false,\n      ssrForceFetchDelay = 0,\n      connectToDevTools =\n        // Expose the client instance as window.__APOLLO_CLIENT__ and call\n        // onBroadcast in queryManager.broadcastQueries to enable browser\n        // devtools, but disable them by default in production.\n        typeof window === 'object' &&\n        !(window as any).__APOLLO_CLIENT__ &&\n        __DEV__,\n      queryDeduplication = true,\n      defaultOptions,\n      assumeImmutableResults = false,\n      resolvers,\n      typeDefs,\n      fragmentMatcher,\n      name: clientAwarenessName,\n      version: clientAwarenessVersion,\n    } = options;\n\n    let { link } = options;\n\n    if (!link) {\n      link = uri\n        ? new HttpLink({ uri, credentials, headers })\n        : ApolloLink.empty();\n    }\n\n    if (!cache) {\n      throw new InvariantError(\n        \"To initialize Apollo Client, you must specify a 'cache' property \" +\n        \"in the options object. \\n\" +\n        \"For more information, please visit: https://go.apollo.dev/c/docs\"\n      );\n    }\n\n    this.link = link;\n    this.cache = cache;\n    this.disableNetworkFetches = ssrMode || ssrForceFetchDelay > 0;\n    this.queryDeduplication = queryDeduplication;\n    this.defaultOptions = defaultOptions || {};\n    this.typeDefs = typeDefs;\n\n    if (ssrForceFetchDelay) {\n      setTimeout(\n        () => (this.disableNetworkFetches = false),\n        ssrForceFetchDelay,\n      );\n    }\n\n    this.watchQuery = this.watchQuery.bind(this);\n    this.query = this.query.bind(this);\n    this.mutate = this.mutate.bind(this);\n    this.resetStore = this.resetStore.bind(this);\n    this.reFetchObservableQueries = this.reFetchObservableQueries.bind(this);\n\n    if (connectToDevTools && typeof window === 'object') {\n      (window as any).__APOLLO_CLIENT__ = this;\n    }\n\n    /**\n     * Suggest installing the devtools for developers who don't have them\n     */\n    if (!hasSuggestedDevtools && __DEV__) {\n      hasSuggestedDevtools = true;\n      if (\n        typeof window !== 'undefined' &&\n        window.document &&\n        window.top === window.self &&\n        !(window as any).__APOLLO_DEVTOOLS_GLOBAL_HOOK__\n      ) {\n        const nav = window.navigator;\n        const ua = nav && nav.userAgent;\n        let url: string | undefined;\n        if (typeof ua === \"string\") {\n          if (ua.indexOf(\"Chrome/\") > -1) {\n            url = \"https://chrome.google.com/webstore/detail/\" +\n              \"apollo-client-developer-t/jdkknkkbebbapilgoeccciglkfbmbnfm\";\n          } else if (ua.indexOf(\"Firefox/\") > -1) {\n            url = \"https://addons.mozilla.org/en-US/firefox/addon/apollo-developer-tools/\";\n          }\n        }\n        if (url) {\n          invariant.log(\n            \"Download the Apollo DevTools for a better development \" +\n              \"experience: \" + url\n          );\n        }\n      }\n    }\n\n    this.version = version;\n\n    this.localState = new LocalState({\n      cache,\n      client: this,\n      resolvers,\n      fragmentMatcher,\n    });\n\n    this.queryManager = new QueryManager({\n      cache: this.cache,\n      link: this.link,\n      queryDeduplication,\n      ssrMode,\n      clientAwareness: {\n        name: clientAwarenessName!,\n        version: clientAwarenessVersion!,\n      },\n      localState: this.localState,\n      assumeImmutableResults,\n      onBroadcast: connectToDevTools ? () => {\n        if (this.devToolsHookCb) {\n          this.devToolsHookCb({\n            action: {},\n            state: {\n              queries: this.queryManager.getQueryStore(),\n              mutations: this.queryManager.mutationStore || {},\n            },\n            dataWithOptimisticResults: this.cache.extract(true),\n          });\n        }\n      } : void 0,\n    });\n  }\n\n  /**\n   * Call this method to terminate any active client processes, making it safe\n   * to dispose of this `ApolloClient` instance.\n   */\n  public stop() {\n    this.queryManager.stop();\n  }\n\n  /**\n   * This watches the cache store of the query according to the options specified and\n   * returns an {@link ObservableQuery}. We can subscribe to this {@link ObservableQuery} and\n   * receive updated results through a GraphQL observer when the cache store changes.\n   * <p /><p />\n   * Note that this method is not an implementation of GraphQL subscriptions. Rather,\n   * it uses Apollo's store in order to reactively deliver updates to your query results.\n   * <p /><p />\n   * For example, suppose you call watchQuery on a GraphQL query that fetches a person's\n   * first and last name and this person has a particular object identifier, provided by\n   * dataIdFromObject. Later, a different query fetches that same person's\n   * first and last name and the first name has now changed. Then, any observers associated\n   * with the results of the first query will be updated with a new result object.\n   * <p /><p />\n   * Note that if the cache does not change, the subscriber will *not* be notified.\n   * <p /><p />\n   * See [here](https://medium.com/apollo-stack/the-concepts-of-graphql-bc68bd819be3#.3mb0cbcmc) for\n   * a description of store reactivity.\n   */\n  public watchQuery<T = any, TVariables = OperationVariables>(\n    options: WatchQueryOptions<TVariables, T>,\n  ): ObservableQuery<T, TVariables> {\n    if (this.defaultOptions.watchQuery) {\n      options = mergeOptions(this.defaultOptions.watchQuery, options);\n    }\n\n    // XXX Overwriting options is probably not the best way to do this long term...\n    if (\n      this.disableNetworkFetches &&\n      (options.fetchPolicy === 'network-only' ||\n        options.fetchPolicy === 'cache-and-network')\n    ) {\n      options = { ...options, fetchPolicy: 'cache-first' };\n    }\n\n    return this.queryManager.watchQuery<T, TVariables>(options);\n  }\n\n  /**\n   * This resolves a single query according to the options specified and\n   * returns a {@link Promise} which is either resolved with the resulting data\n   * or rejected with an error.\n   *\n   * @param options An object of type {@link QueryOptions} that allows us to\n   * describe how this query should be treated e.g. whether it should hit the\n   * server at all or just resolve from the cache, etc.\n   */\n  public query<T = any, TVariables = OperationVariables>(\n    options: QueryOptions<TVariables, T>,\n  ): Promise<ApolloQueryResult<T>> {\n    if (this.defaultOptions.query) {\n      options = mergeOptions(this.defaultOptions.query, options);\n    }\n\n    invariant(\n      (options.fetchPolicy as WatchQueryFetchPolicy) !== 'cache-and-network',\n      'The cache-and-network fetchPolicy does not work with client.query, because ' +\n      'client.query can only return a single result. Please use client.watchQuery ' +\n      'to receive multiple results from the cache and the network, or consider ' +\n      'using a different fetchPolicy, such as cache-first or network-only.'\n    );\n\n    if (this.disableNetworkFetches && options.fetchPolicy === 'network-only') {\n      options = { ...options, fetchPolicy: 'cache-first' };\n    }\n\n    return this.queryManager.query<T, TVariables>(options);\n  }\n\n  /**\n   * This resolves a single mutation according to the options specified and returns a\n   * {@link Promise} which is either resolved with the resulting data or rejected with an\n   * error.\n   *\n   * It takes options as an object with the following keys and values:\n   */\n  public mutate<\n    TData = any,\n    TVariables = OperationVariables,\n    TContext = DefaultContext,\n    TCache extends ApolloCache<any> = ApolloCache<any>\n  >(\n    options: MutationOptions<TData, TVariables, TContext>,\n  ): Promise<FetchResult<TData>> {\n    if (this.defaultOptions.mutate) {\n      options = mergeOptions(this.defaultOptions.mutate, options);\n    }\n    return this.queryManager.mutate<TData, TVariables, TContext, TCache>(options);\n  }\n\n  /**\n   * This subscribes to a graphql subscription according to the options specified and returns an\n   * {@link Observable} which either emits received data or an error.\n   */\n  public subscribe<T = any, TVariables = OperationVariables>(\n    options: SubscriptionOptions<TVariables, T>,\n  ): Observable<FetchResult<T>> {\n    return this.queryManager.startGraphQLSubscription<T>(options);\n  }\n\n  /**\n   * Tries to read some data from the store in the shape of the provided\n   * GraphQL query without making a network request. This method will start at\n   * the root query. To start at a specific id returned by `dataIdFromObject`\n   * use `readFragment`.\n   *\n   * @param optimistic Set to `true` to allow `readQuery` to return\n   * optimistic results. Is `false` by default.\n   */\n  public readQuery<T = any, TVariables = OperationVariables>(\n    options: DataProxy.Query<TVariables, T>,\n    optimistic: boolean = false,\n  ): T | null {\n    return this.cache.readQuery<T, TVariables>(options, optimistic);\n  }\n\n  /**\n   * Tries to read some data from the store in the shape of the provided\n   * GraphQL fragment without making a network request. This method will read a\n   * GraphQL fragment from any arbitrary id that is currently cached, unlike\n   * `readQuery` which will only read from the root query.\n   *\n   * You must pass in a GraphQL document with a single fragment or a document\n   * with multiple fragments that represent what you are reading. If you pass\n   * in a document with multiple fragments then you must also specify a\n   * `fragmentName`.\n   *\n   * @param optimistic Set to `true` to allow `readFragment` to return\n   * optimistic results. Is `false` by default.\n   */\n  public readFragment<T = any, TVariables = OperationVariables>(\n    options: DataProxy.Fragment<TVariables, T>,\n    optimistic: boolean = false,\n  ): T | null {\n    return this.cache.readFragment<T, TVariables>(options, optimistic);\n  }\n\n  /**\n   * Writes some data in the shape of the provided GraphQL query directly to\n   * the store. This method will start at the root query. To start at a\n   * specific id returned by `dataIdFromObject` then use `writeFragment`.\n   */\n  public writeQuery<TData = any, TVariables = OperationVariables>(\n    options: DataProxy.WriteQueryOptions<TData, TVariables>,\n  ): void {\n    this.cache.writeQuery<TData, TVariables>(options);\n    this.queryManager.broadcastQueries();\n  }\n\n  /**\n   * Writes some data in the shape of the provided GraphQL fragment directly to\n   * the store. This method will write to a GraphQL fragment from any arbitrary\n   * id that is currently cached, unlike `writeQuery` which will only write\n   * from the root query.\n   *\n   * You must pass in a GraphQL document with a single fragment or a document\n   * with multiple fragments that represent what you are writing. If you pass\n   * in a document with multiple fragments then you must also specify a\n   * `fragmentName`.\n   */\n  public writeFragment<TData = any, TVariables = OperationVariables>(\n    options: DataProxy.WriteFragmentOptions<TData, TVariables>,\n  ): void {\n    this.cache.writeFragment<TData, TVariables>(options);\n    this.queryManager.broadcastQueries();\n  }\n\n  public __actionHookForDevTools(cb: () => any) {\n    this.devToolsHookCb = cb;\n  }\n\n  public __requestRaw(payload: GraphQLRequest): Observable<ExecutionResult> {\n    return execute(this.link, payload);\n  }\n\n  /**\n   * Resets your entire store by clearing out your cache and then re-executing\n   * all of your active queries. This makes it so that you may guarantee that\n   * there is no data left in your store from a time before you called this\n   * method.\n   *\n   * `resetStore()` is useful when your user just logged out. You\u2019ve removed the\n   * user session, and you now want to make sure that any references to data you\n   * might have fetched while the user session was active is gone.\n   *\n   * It is important to remember that `resetStore()` *will* refetch any active\n   * queries. This means that any components that might be mounted will execute\n   * their queries again using your network interface. If you do not want to\n   * re-execute any queries then you should make sure to stop watching any\n   * active queries.\n   */\n  public resetStore(): Promise<ApolloQueryResult<any>[] | null> {\n    return Promise.resolve()\n      .then(() => this.queryManager.clearStore({\n        discardWatches: false,\n      }))\n      .then(() => Promise.all(this.resetStoreCallbacks.map(fn => fn())))\n      .then(() => this.reFetchObservableQueries());\n  }\n\n  /**\n   * Remove all data from the store. Unlike `resetStore`, `clearStore` will\n   * not refetch any active queries.\n   */\n  public clearStore(): Promise<any[]> {\n    return Promise.resolve()\n      .then(() => this.queryManager.clearStore({\n        discardWatches: true,\n      }))\n      .then(() => Promise.all(this.clearStoreCallbacks.map(fn => fn())));\n  }\n\n  /**\n   * Allows callbacks to be registered that are executed when the store is\n   * reset. `onResetStore` returns an unsubscribe function that can be used\n   * to remove registered callbacks.\n   */\n  public onResetStore(cb: () => Promise<any>): () => void {\n    this.resetStoreCallbacks.push(cb);\n    return () => {\n      this.resetStoreCallbacks = this.resetStoreCallbacks.filter(c => c !== cb);\n    };\n  }\n\n  /**\n   * Allows callbacks to be registered that are executed when the store is\n   * cleared. `onClearStore` returns an unsubscribe function that can be used\n   * to remove registered callbacks.\n   */\n  public onClearStore(cb: () => Promise<any>): () => void {\n    this.clearStoreCallbacks.push(cb);\n    return () => {\n      this.clearStoreCallbacks = this.clearStoreCallbacks.filter(c => c !== cb);\n    };\n  }\n\n  /**\n   * Refetches all of your active queries.\n   *\n   * `reFetchObservableQueries()` is useful if you want to bring the client back to proper state in case of a network outage\n   *\n   * It is important to remember that `reFetchObservableQueries()` *will* refetch any active\n   * queries. This means that any components that might be mounted will execute\n   * their queries again using your network interface. If you do not want to\n   * re-execute any queries then you should make sure to stop watching any\n   * active queries.\n   * Takes optional parameter `includeStandby` which will include queries in standby-mode when refetching.\n   */\n  public reFetchObservableQueries(\n    includeStandby?: boolean,\n  ): Promise<ApolloQueryResult<any>[]> {\n    return this.queryManager.reFetchObservableQueries(includeStandby);\n  }\n\n  /**\n   * Refetches specified active queries. Similar to \"reFetchObservableQueries()\" but with a specific list of queries.\n   *\n   * `refetchQueries()` is useful for use cases to imperatively refresh a selection of queries.\n   *\n   * It is important to remember that `refetchQueries()` *will* refetch specified active\n   * queries. This means that any components that might be mounted will execute\n   * their queries again using your network interface. If you do not want to\n   * re-execute any queries then you should make sure to stop watching any\n   * active queries.\n   */\n  public refetchQueries<\n    TCache extends ApolloCache<any> = ApolloCache<TCacheShape>,\n    TResult = Promise<ApolloQueryResult<any>>,\n  >(\n    options: RefetchQueriesOptions<TCache, TResult>,\n  ): RefetchQueriesResult<TResult> {\n    const map = this.queryManager.refetchQueries(options);\n    const queries: ObservableQuery<any>[] = [];\n    const results: InternalRefetchQueriesResult<TResult>[] = [];\n\n    map.forEach((result, obsQuery) => {\n      queries.push(obsQuery);\n      results.push(result);\n    });\n\n    const result = Promise.all<TResult>(\n      results as TResult[]\n    ) as RefetchQueriesResult<TResult>;\n\n    // In case you need the raw results immediately, without awaiting\n    // Promise.all(results):\n    result.queries = queries;\n    result.results = results;\n\n    // If you decide to ignore the result Promise because you're using\n    // result.queries and result.results instead, you shouldn't have to worry\n    // about preventing uncaught rejections for the Promise.all result.\n    result.catch(error => {\n      invariant.debug(`In client.refetchQueries, Promise.all promise rejected with error ${error}`);\n    });\n\n    return result;\n  }\n\n  /**\n   * Get all currently active `ObservableQuery` objects, in a `Map` keyed by\n   * query ID strings. An \"active\" query is one that has observers and a\n   * `fetchPolicy` other than \"standby\" or \"cache-only\". You can include all\n   * `ObservableQuery` objects (including the inactive ones) by passing \"all\"\n   * instead of \"active\", or you can include just a subset of active queries by\n   * passing an array of query names or DocumentNode objects.\n   */\n  public getObservableQueries(\n    include: RefetchQueriesInclude = \"active\",\n  ): Map<string, ObservableQuery<any>> {\n    return this.queryManager.getObservableQueries(include);\n  }\n\n  /**\n   * Exposes the cache's complete state, in a serializable format for later restoration.\n   */\n  public extract(optimistic?: boolean): TCacheShape {\n    return this.cache.extract(optimistic);\n  }\n\n  /**\n   * Replaces existing state in the cache (if any) with the values expressed by\n   * `serializedState`.\n   *\n   * Called when hydrating a cache (server side rendering, or offline storage),\n   * and also (potentially) during hot reloads.\n   */\n  public restore(serializedState: TCacheShape): ApolloCache<TCacheShape> {\n    return this.cache.restore(serializedState);\n  }\n\n  /**\n   * Add additional local resolvers.\n   */\n  public addResolvers(resolvers: Resolvers | Resolvers[]) {\n    this.localState.addResolvers(resolvers);\n  }\n\n  /**\n   * Set (override existing) local resolvers.\n   */\n  public setResolvers(resolvers: Resolvers | Resolvers[]) {\n    this.localState.setResolvers(resolvers);\n  }\n\n  /**\n   * Get all registered local resolvers.\n   */\n  public getResolvers() {\n    return this.localState.getResolvers();\n  }\n\n  /**\n   * Set a custom local state fragment matcher.\n   */\n  public setLocalStateFragmentMatcher(fragmentMatcher: FragmentMatcher) {\n    this.localState.setFragmentMatcher(fragmentMatcher);\n  }\n\n  /**\n   * Define a new ApolloLink (or link chain) that Apollo Client will use.\n   */\n  public setLink(newLink: ApolloLink) {\n    this.link = this.queryManager.link = newLink;\n  }\n}\n", null, "/* Core */\n\nimport { DEV } from '../utilities/globals';\n\nexport {\n  ApolloClient,\n  ApolloClientOptions,\n  DefaultOptions,\n  mergeOptions,\n} from './ApolloClient';\nexport {\n  ObservableQuery,\n  FetchMoreOptions,\n  UpdateQueryOptions,\n  applyNextFetchPolicy,\n} from './ObservableQuery';\nexport {\n  QueryOptions,\n  WatchQueryOptions,\n  MutationOptions,\n  SubscriptionOptions,\n  FetchPolicy,\n  WatchQueryFetchPolicy,\n  ErrorPolicy,\n  FetchMoreQueryOptions,\n  SubscribeToMoreOptions,\n} from './watchQueryOptions';\nexport { NetworkStatus } from './networkStatus';\nexport * from './types';\nexport {\n  Resolver,\n  FragmentMatcher,\n} from './LocalState';\nexport { isApolloError, ApolloError } from '../errors';\n\n/* Cache */\n\nexport {\n  // All the exports (types and values) from ../cache, minus cacheSlot,\n  // which we want to keep semi-private.\n  Cache,\n  ApolloCache,\n  Transaction,\n  DataProxy,\n  InMemoryCache,\n  InMemoryCacheConfig,\n  MissingFieldError,\n  defaultDataIdFromObject,\n  ReactiveVar,\n  makeVar,\n  TypePolicies,\n  TypePolicy,\n  FieldPolicy,\n  FieldReadFunction,\n  FieldMergeFunction,\n  FieldFunctionOptions,\n  PossibleTypesMap,\n} from '../cache';\n\nexport * from '../cache/inmemory/types';\n\n/* Link */\n\nexport * from '../link/core';\nexport * from '../link/http';\nexport {\n  fromError,\n  toPromise,\n  fromPromise,\n  ServerError,\n  throwServerError,\n} from '../link/utils';\n\n/* Utilities */\n\nexport {\n  Observable,\n  Observer,\n  ObservableSubscription,\n  Reference,\n  isReference,\n  makeReference,\n  StoreObject,\n} from '../utilities';\n\n/* Supporting */\n\n// The verbosity of invariant.{log,warn,error} can be controlled globally\n// (for anyone using the same ts-invariant package) by passing \"log\",\n// \"warn\", \"error\", or \"silent\" to setVerbosity (\"log\" is the default).\n// Note that all invariant.* logging is hidden in production.\nimport { setVerbosity } from \"ts-invariant\";\nexport { setVerbosity as setLogVerbosity }\nsetVerbosity(DEV ? \"log\" : \"silent\");\n\n// Note that importing `gql` by itself, then destructuring\n// additional properties separately before exporting, is intentional.\n// Due to the way the `graphql-tag` library is setup, certain bundlers\n// can't find the properties added to the exported `gql` function without\n// additional guidance (e.g. Rollup - see\n// https://rollupjs.org/guide/en/#error-name-is-not-exported-by-module).\n// Instead of having people that are using bundlers with `@apollo/client` add\n// extra bundler config to help `graphql-tag` exports be found (which would be\n// awkward since they aren't importing `graphql-tag` themselves), this\n// workaround of pulling the extra properties off the `gql` function,\n// then re-exporting them separately, helps keeps bundlers happy without any\n// additional config changes.\nexport {\n  gql,\n  resetCaches,\n  disableFragmentWarnings,\n  enableExperimentalFragmentVariables,\n  disableExperimentalFragmentVariables,\n} from 'graphql-tag';\n", "import { invariant } from '../../utilities/globals';\n\nimport * as React from 'react';\n\nimport { ApolloClient } from '../../core';\nimport { getApolloContext } from './ApolloContext';\n\nexport interface ApolloConsumerProps {\n  children: (client: ApolloClient<object>) => React.ReactChild | null;\n}\n\nexport const ApolloConsumer: React.FC<ApolloConsumerProps> = props => {\n  const ApolloContext = getApolloContext();\n  return (\n    <ApolloContext.Consumer>\n      {(context: any) => {\n        invariant(\n          context && context.client,\n          'Could not find \"client\" in the context of ApolloConsumer. ' +\n            'Wrap the root component in an <ApolloProvider>.'\n        );\n        return props.children(context.client);\n      }}\n    </ApolloContext.Consumer>\n  );\n};\n", "import * as React from 'react';\nimport { ApolloClient } from '../../core';\nimport { canUseSymbol } from '../../utilities';\nimport type { RenderPromises } from '../ssr';\n\nexport interface ApolloContextValue {\n  client?: ApolloClient<object>;\n  renderPromises?: RenderPromises;\n}\n\n// To make sure Apollo Client doesn't create more than one React context\n// (which can lead to problems like having an Apollo Client instance added\n// in one context, then attempting to retrieve it from another different\n// context), a single Apollo context is created and tracked in global state.\nconst contextKey = canUseSymbol\n  ? Symbol.for('__APOLLO_CONTEXT__')\n  : '__APOLLO_CONTEXT__';\n\nexport function getApolloContext(): React.Context<ApolloContextValue> {\n  let context = (React.createContext as any)[contextKey] as React.Context<ApolloContextValue>;\n  if (!context) {\n    Object.defineProperty(React.createContext, contextKey, {\n      value: context = React.createContext<ApolloContextValue>({}),\n      enumerable: false,\n      writable: false,\n      configurable: true,\n    });\n    context.displayName = 'ApolloContext';\n  }\n  return context;\n}\n\nexport { getApolloContext as resetApolloContext }\n", "import { invariant } from '../../utilities/globals';\n\nimport * as React from 'react';\n\nimport { ApolloClient } from '../../core';\nimport { getApolloContext } from './ApolloContext';\n\nexport interface ApolloProviderProps<TCache> {\n  client: ApolloClient<TCache>;\n  children: React.ReactNode | React.ReactNode[] | null;\n}\n\nexport const ApolloProvider: React.FC<ApolloProviderProps<any>> = ({\n  client,\n  children\n}) => {\n  const ApolloContext = getApolloContext();\n  return (\n    <ApolloContext.Consumer>\n      {(context: any = {}) => {\n        if (client && context.client !== client) {\n          context = Object.assign({}, context, { client });\n        }\n\n        invariant(\n          context.client,\n          'ApolloProvider was not passed a client instance. Make ' +\n            'sure you pass in your client via the \"client\" prop.'\n        );\n\n        return (\n          <ApolloContext.Provider value={context}>\n            {children}\n          </ApolloContext.Provider>\n        );\n      }}\n    </ApolloContext.Consumer>\n  );\n};\n", "import { invariant } from '../../utilities/globals';\nimport { useContext } from 'react';\nimport { ApolloClient } from '../../core';\nimport { getApolloContext } from '../context';\n\nexport function useApolloClient(\n  override?: ApolloClient<object>,\n): ApolloClient<object> {\n  const context = useContext(getApolloContext());\n  const client = override || context.client;\n  invariant(\n    !!client,\n    'Could not find \"client\" in the context or passed in as an option. ' +\n    'Wrap the root component in an <ApolloProvider>, or pass an ApolloClient ' +\n    'instance in via options.',\n  );\n\n  return client;\n}\n", "import { DocumentNode } from 'graphql';\nimport { TypedDocumentNode } from '@graphql-typed-document-node/core';\nimport { useCallback, useMemo, useState } from 'react';\n\nimport {\n  LazyQueryHookOptions,\n  QueryLazyOptions,\n  QueryTuple,\n} from '../types/types';\nimport { useQuery } from './useQuery';\nimport { OperationVariables } from '../../core';\n\n// The following methods, when called will execute the query, regardless of\n// whether the useLazyQuery execute function was called before.\nconst EAGER_METHODS = [\n  'refetch',\n  'fetchMore',\n  'updateQuery',\n  'startPolling',\n  'subscribeToMore',\n] as const;\n\nexport function useLazyQuery<TData = any, TVariables = OperationVariables>(\n  query: DocumentNode | TypedDocumentNode<TData, TVariables>,\n  options?: LazyQueryHookOptions<TData, TVariables>\n): QueryTuple<TData, TVariables> {\n  const [execution, setExecution] = useState<{\n    called: boolean,\n    options?: QueryLazyOptions<TVariables>,\n  }>({\n    called: false,\n  });\n\n  let result = useQuery<TData, TVariables>(query, {\n    ...options,\n    ...execution.options,\n    // We don\u2019t set skip to execution.called, because some useQuery SSR code\n    // checks skip for some reason.\n    fetchPolicy: execution.called ? options?.fetchPolicy : 'standby',\n    skip: undefined,\n  });\n\n  if (!execution.called) {\n    result = {\n      ...result,\n      loading: false,\n      data: void 0 as unknown as TData,\n      error: void 0,\n      called: false,\n    };\n  }\n\n  // We use useMemo here to make sure the eager methods have a stable identity.\n  const eagerMethods = useMemo(() => {\n    const eagerMethods: Record<string, any> = {};\n    for (const key of EAGER_METHODS) {\n      const method = result[key];\n      eagerMethods[key] = (...args: any) => {\n        setExecution((execution) => ({ ...execution, called: true }));\n        return (method as any)(...args);\n      };\n    }\n\n    return eagerMethods;\n  }, []);\n\n  result.error = result.error || void 0;\n  Object.assign(result, eagerMethods);\n\n  const execute = useCallback<\n    QueryTuple<TData, TVariables>[0]\n  >((executeOptions?: QueryLazyOptions<TVariables>) => {\n    setExecution({ called: true, options: executeOptions });\n    const promise = result.refetch(executeOptions?.variables).then((result1) => {\n      const result2 = {\n        ...result,\n        data: result1.data,\n        error: result1.error,\n        called: true,\n        loading: false,\n      };\n\n      Object.assign(result2, eagerMethods);\n      return result2;\n    });\n\n    // Because the return value of `useLazyQuery` is usually floated, we need\n    // to catch the promise to prevent unhandled rejections.\n    promise.catch(() => {});\n\n    return promise;\n  }, []);\n\n  return [execute, result];\n}\n", "import { useContext, useEffect, useMemo, useRef, useState } from 'react';\nimport { equal } from '@wry/equality';\nimport { OperationVariables, mergeOptions } from '../../core';\nimport { getApolloContext } from '../context';\nimport { ApolloError } from '../../errors';\nimport {\n  ApolloQueryResult,\n  NetworkStatus,\n  ObservableQuery,\n  DocumentNode,\n  TypedDocumentNode,\n  WatchQueryOptions,\n} from '../../core';\nimport {\n  QueryHookOptions,\n  QueryResult,\n} from '../types/types';\n\nimport { DocumentType, verifyDocumentType } from '../parser';\nimport { useApolloClient } from './useApolloClient';\n\nexport function useQuery<\n  TData = any,\n  TVariables = OperationVariables,\n>(\n  query: DocumentNode | TypedDocumentNode<TData, TVariables>,\n  options?: QueryHookOptions<TData, TVariables>,\n): QueryResult<TData, TVariables> {\n  const context = useContext(getApolloContext());\n  const client = useApolloClient(options?.client);\n  const defaultWatchQueryOptions = client.defaultOptions.watchQuery;\n  verifyDocumentType(query, DocumentType.Query);\n  const [obsQuery, setObsQuery] = useState(() => {\n    const watchQueryOptions = createWatchQueryOptions(query, options, defaultWatchQueryOptions);\n    // See if there is an existing observable that was used to fetch the same\n    // data and if so, use it instead since it will contain the proper queryId\n    // to fetch the result set. This is used during SSR.\n    let obsQuery: ObservableQuery<TData, TVariables> | null = null;\n    if (context.renderPromises) {\n      obsQuery = context.renderPromises.getSSRObservable(watchQueryOptions);\n    }\n\n    if (!obsQuery) {\n      // Is it safe (StrictMode/memory-wise) to call client.watchQuery here?\n      obsQuery = client.watchQuery(watchQueryOptions);\n      if (context.renderPromises) {\n        context.renderPromises.registerSSRObservable(\n          obsQuery,\n          watchQueryOptions,\n        );\n      }\n    }\n\n    if (\n      context.renderPromises &&\n      options?.ssr !== false &&\n      !options?.skip &&\n      obsQuery.getCurrentResult().loading\n    ) {\n      // TODO: This is a legacy API which could probably be cleaned up\n      context.renderPromises.addQueryPromise(\n        {\n          // The only options which seem to actually be used by the\n          // RenderPromises class are query and variables.\n          getOptions: () => createWatchQueryOptions(query, options, defaultWatchQueryOptions),\n          fetchData: () => new Promise<void>((resolve) => {\n            const sub = obsQuery!.subscribe({\n              next(result) {\n                if (!result.loading) {\n                  resolve()\n                  sub.unsubscribe();\n                }\n              },\n              error() {\n                resolve();\n                sub.unsubscribe();\n              },\n              complete() {\n                resolve();\n              },\n            });\n          }),\n        },\n        // This callback never seemed to do anything\n        () => null,\n      );\n    }\n\n    return obsQuery;\n  });\n\n  let [result, setResult] = useState(() => {\n    const result = obsQuery.getCurrentResult();\n    if (!result.loading && options) {\n      if (result.error) {\n        options.onError?.(result.error);\n      } else if (result.data) {\n        options.onCompleted?.(result.data);\n      }\n    }\n\n    return result;\n  });\n\n  const ref = useRef({\n    client,\n    query,\n    options,\n    result,\n    previousData: void 0 as TData | undefined,\n    watchQueryOptions: createWatchQueryOptions(query, options, defaultWatchQueryOptions),\n  });\n\n  // An effect to recreate the obsQuery whenever the client or query changes.\n  // This effect is also responsible for checking and updating the obsQuery\n  // options whenever they change.\n  useEffect(() => {\n    const watchQueryOptions = createWatchQueryOptions(query, options, defaultWatchQueryOptions);\n    let nextResult: ApolloQueryResult<TData> | undefined;\n    if (ref.current.client !== client || !equal(ref.current.query, query)) {\n      const obsQuery = client.watchQuery(watchQueryOptions);\n      setObsQuery(obsQuery);\n      nextResult = obsQuery.getCurrentResult();\n    } else if (!equal(ref.current.watchQueryOptions, watchQueryOptions)) {\n      obsQuery.setOptions(watchQueryOptions).catch(() => {});\n      nextResult = obsQuery.getCurrentResult();\n      ref.current.watchQueryOptions = watchQueryOptions;\n    }\n\n    if (nextResult) {\n      const previousResult = ref.current.result;\n      if (previousResult.data) {\n        ref.current.previousData = previousResult.data;\n      }\n\n      setResult(ref.current.result = nextResult);\n      if (!nextResult.loading && options) {\n        if (nextResult.error) {\n          options.onError?.(nextResult.error);\n        } else if (nextResult.data) {\n          options.onCompleted?.(nextResult.data);\n        }\n      }\n    }\n\n    Object.assign(ref.current, { client, query });\n  }, [obsQuery, client, query, options]);\n\n  // An effect to subscribe to the current observable query\n  useEffect(() => {\n    if (context.renderPromises) {\n      return;\n    }\n\n    let subscription = obsQuery.subscribe(onNext, onError);\n    // We use `getCurrentResult()` instead of the callback argument because\n    // the values differ slightly. Specifically, loading results will have\n    // an empty object for data instead of `undefined` for some reason.\n    function onNext() {\n      const previousResult = ref.current.result;\n      const result = obsQuery.getCurrentResult();\n      // Make sure we're not attempting to re-render similar results\n      if (\n        previousResult &&\n        previousResult.loading === result.loading &&\n        previousResult.networkStatus === result.networkStatus &&\n        equal(previousResult.data, result.data)\n      ) {\n        return;\n      }\n\n      if (previousResult.data) {\n        ref.current.previousData = previousResult.data;\n      }\n\n      setResult(ref.current.result = result);\n      if (!result.loading) {\n        ref.current.options?.onCompleted?.(result.data);\n      }\n    }\n\n    function onError(error: Error) {\n      const last = obsQuery[\"last\"];\n      subscription.unsubscribe();\n      // Unfortunately, if `lastError` is set in the current\n      // `observableQuery` when the subscription is re-created,\n      // the subscription will immediately receive the error, which will\n      // cause it to terminate again. To avoid this, we first clear\n      // the last error/result from the `observableQuery` before re-starting\n      // the subscription, and restore it afterwards (so the subscription\n      // has a chance to stay open).\n      try {\n        obsQuery.resetLastResults();\n        subscription = obsQuery.subscribe(onNext, onError);\n      } finally {\n        obsQuery[\"last\"] = last;\n      }\n\n      if (!error.hasOwnProperty('graphQLErrors')) {\n        // The error is not a GraphQL error\n        throw error;\n      }\n\n      const previousResult = ref.current.result;\n      if (\n        (previousResult && previousResult.loading) ||\n        !equal(error, previousResult.error)\n      ) {\n        setResult(ref.current.result = {\n          data: previousResult.data,\n          error: error as ApolloError,\n          loading: false,\n          networkStatus: NetworkStatus.error,\n        });\n        ref.current.options?.onError?.(error as ApolloError);\n      }\n    }\n\n    return () => subscription.unsubscribe();\n  }, [obsQuery, context.renderPromises, client.disableNetworkFetches]);\n\n  let partial: boolean | undefined;\n  ({ partial, ...result } = result);\n\n  {\n    // BAD BOY CODE BLOCK WHERE WE PUT SIDE-EFFECTS IN THE RENDER FUNCTION\n    //\n    // TODO: This code should be removed when the partialRefetch option is\n    // removed. I was unable to get this hook to behave reasonably in certain\n    // edge cases when this block was put in an effect.\n    if (\n      partial &&\n      options?.partialRefetch &&\n      !result.loading &&\n      (!result.data || Object.keys(result.data).length === 0) &&\n      obsQuery.options.fetchPolicy !== 'cache-only'\n    ) {\n      result = {\n        ...result,\n        loading: true,\n        networkStatus: NetworkStatus.refetch,\n      };\n\n      obsQuery.refetch();\n    }\n\n    // TODO: This is a hack to make sure useLazyQuery executions update the\n    // obsevable query options for ssr.\n    if (\n      context.renderPromises &&\n      options?.ssr !== false &&\n      !options?.skip &&\n      result.loading\n    ) {\n      obsQuery.setOptions(createWatchQueryOptions(query, options, defaultWatchQueryOptions)).catch(() => {});\n    }\n\n    // We assign options during rendering as a guard to make sure that\n    // callbacks like onCompleted and onError are not stale.\n    Object.assign(ref.current, { options });\n  }\n\n  if (\n    (context.renderPromises || client.disableNetworkFetches) &&\n    options?.ssr === false\n  ) {\n    // If SSR has been explicitly disabled, and this function has been called\n    // on the server side, return the default loading state.\n    result = ref.current.result = {\n      loading: true,\n      data: void 0 as unknown as TData,\n      error: void 0,\n      networkStatus: NetworkStatus.loading,\n    };\n  } else if (options?.skip || options?.fetchPolicy === 'standby') {\n    // When skipping a query (ie. we're not querying for data but still want to\n    // render children), make sure the `data` is cleared out and `loading` is\n    // set to `false` (since we aren't loading anything).\n    //\n    // NOTE: We no longer think this is the correct behavior. Skipping should\n    // not automatically set `data` to `undefined`, but instead leave the\n    // previous data in place. In other words, skipping should not mandate that\n    // previously received data is all of a sudden removed. Unfortunately,\n    // changing this is breaking, so we'll have to wait until Apollo Client 4.0\n    // to address this.\n    result = {\n      loading: false,\n      data: void 0 as unknown as TData,\n      error: void 0,\n      networkStatus: NetworkStatus.ready,\n    };\n  }\n\n  if (result.errors && result.errors.length) {\n    // Until a set naming convention for networkError and graphQLErrors is\n    // decided upon, we map errors (graphQLErrors) to the error options.\n    // TODO: Is it possible for both result.error and result.errors to be\n    // defined here?\n    result = {\n      ...result,\n      error: result.error || new ApolloError({ graphQLErrors: result.errors }),\n    };\n  }\n\n  const obsQueryFields = useMemo(() => ({\n    refetch: obsQuery.refetch.bind(obsQuery),\n    fetchMore: obsQuery.fetchMore.bind(obsQuery),\n    updateQuery: obsQuery.updateQuery.bind(obsQuery),\n    startPolling: obsQuery.startPolling.bind(obsQuery),\n    stopPolling: obsQuery.stopPolling.bind(obsQuery),\n    subscribeToMore: obsQuery.subscribeToMore.bind(obsQuery),\n  }), [obsQuery]);\n\n  return {\n    ...obsQueryFields,\n    variables: createWatchQueryOptions(query, options, defaultWatchQueryOptions).variables,\n    client,\n    called: true,\n    previousData: ref.current.previousData,\n    ...result,\n  };\n}\n\n/**\n * A function to massage options before passing them the ObservableQuery.\n */\nfunction createWatchQueryOptions<TData, TVariables>(\n  query: DocumentNode | TypedDocumentNode<TData, TVariables>,\n  options: QueryHookOptions<TData, TVariables> = {},\n  defaultOptions?: Partial<WatchQueryOptions<any, any>>\n): WatchQueryOptions<TVariables, TData> {\n  // TODO: For some reason, we pass context, which is the React Apollo Context,\n  // into observable queries, and test for that.\n  // removing hook specific options\n  const {\n    skip,\n    ssr,\n    onCompleted,\n    onError,\n    displayName,\n    ...otherOptions\n  } = options;\n\n  let watchQueryOptions = { query, ...otherOptions };\n  if (defaultOptions) {\n    watchQueryOptions = mergeOptions(defaultOptions, watchQueryOptions);\n  }\n\n  if (skip) {\n    watchQueryOptions.fetchPolicy = 'standby';\n  } else if (\n    watchQueryOptions.context?.renderPromises &&\n    (\n      watchQueryOptions.fetchPolicy === 'network-only' ||\n      watchQueryOptions.fetchPolicy === 'cache-and-network'\n    )\n  ) {\n    // this behavior was added to react-apollo without explanation in this PR\n    // https://github.com/apollographql/react-apollo/pull/1579\n    watchQueryOptions.fetchPolicy = 'cache-first';\n  } else if (!watchQueryOptions.fetchPolicy) {\n    // cache-first is the default policy, but we explicitly assign it here so\n    // the cache policies computed based on options can be cleared\n    watchQueryOptions.fetchPolicy = 'cache-first';\n  }\n\n  if (!watchQueryOptions.variables) {\n    watchQueryOptions.variables = {} as TVariables;\n  }\n\n  return watchQueryOptions;\n}\n", "import { invariant } from '../../utilities/globals';\n\nimport {\n  DocumentNode,\n  DefinitionNode,\n  VariableDefinitionNode,\n  OperationDefinitionNode\n} from 'graphql';\n\nexport enum DocumentType {\n  Query,\n  Mutation,\n  Subscription\n}\n\nexport interface IDocumentDefinition {\n  type: DocumentType;\n  name: string;\n  variables: ReadonlyArray<VariableDefinitionNode>;\n}\n\nconst cache = new Map();\n\nexport function operationName(type: DocumentType) {\n  let name;\n  switch (type) {\n    case DocumentType.Query:\n      name = 'Query';\n      break;\n    case DocumentType.Mutation:\n      name = 'Mutation';\n      break;\n    case DocumentType.Subscription:\n      name = 'Subscription';\n      break;\n  }\n  return name;\n}\n\n// This parser is mostly used to safety check incoming documents.\nexport function parser(document: DocumentNode): IDocumentDefinition {\n  const cached = cache.get(document);\n  if (cached) return cached;\n\n  let variables, type, name;\n\n  invariant(\n    !!document && !!document.kind,\n    `Argument of ${document} passed to parser was not a valid GraphQL ` +\n      `DocumentNode. You may need to use 'graphql-tag' or another method ` +\n      `to convert your operation into a document`\n  );\n\n  const fragments = document.definitions.filter(\n    (x: DefinitionNode) => x.kind === 'FragmentDefinition'\n  );\n\n  const queries = document.definitions.filter(\n    (x: DefinitionNode) =>\n      x.kind === 'OperationDefinition' && x.operation === 'query'\n  );\n\n  const mutations = document.definitions.filter(\n    (x: DefinitionNode) =>\n      x.kind === 'OperationDefinition' && x.operation === 'mutation'\n  );\n\n  const subscriptions = document.definitions.filter(\n    (x: DefinitionNode) =>\n      x.kind === 'OperationDefinition' && x.operation === 'subscription'\n  );\n\n  invariant(\n    !fragments.length ||\n      (queries.length || mutations.length || subscriptions.length),\n    `Passing only a fragment to 'graphql' is not yet supported. ` +\n      `You must include a query, subscription or mutation as well`\n  );\n\n  invariant(\n    queries.length + mutations.length + subscriptions.length <= 1,\n    `react-apollo only supports a query, subscription, or a mutation per HOC. ` +\n      `${document} had ${queries.length} queries, ${subscriptions.length} ` +\n      `subscriptions and ${mutations.length} mutations. ` +\n      `You can use 'compose' to join multiple operation types to a component`\n  );\n\n  type = queries.length ? DocumentType.Query : DocumentType.Mutation;\n  if (!queries.length && !mutations.length) type = DocumentType.Subscription;\n\n  const definitions = queries.length\n    ? queries\n    : mutations.length\n    ? mutations\n    : subscriptions;\n\n  invariant(\n    definitions.length === 1,\n    `react-apollo only supports one definition per HOC. ${document} had ` +\n      `${definitions.length} definitions. ` +\n      `You can use 'compose' to join multiple operation types to a component`\n  );\n\n  const definition = definitions[0] as OperationDefinitionNode;\n  variables = definition.variableDefinitions || [];\n\n  if (definition.name && definition.name.kind === 'Name') {\n    name = definition.name.value;\n  } else {\n    name = 'data'; // fallback to using data if no name\n  }\n\n  const payload = { name, type, variables };\n  cache.set(document, payload);\n  return payload;\n}\n\nexport function verifyDocumentType(document: DocumentNode, type: DocumentType) {\n  const operation = parser(document);\n  const requiredOperationName = operationName(type);\n  const usedOperationName = operationName(operation.type);\n  invariant(\n    operation.type === type,\n    `Running a ${requiredOperationName} requires a graphql ` +\n      `${requiredOperationName}, but a ${usedOperationName} was used instead.`\n  );\n}\n\n", "import { useCallback, useEffect, useRef, useState } from 'react';\nimport { DocumentNode } from 'graphql';\nimport { TypedDocumentNode } from '@graphql-typed-document-node/core';\nimport {\n  MutationFunctionOptions,\n  MutationHookOptions,\n  MutationResult,\n  MutationTuple,\n} from '../types/types';\n\nimport {\n  ApolloCache,\n  DefaultContext,\n  mergeOptions,\n  OperationVariables,\n} from '../../core';\nimport { equal } from '@wry/equality';\nimport { DocumentType, verifyDocumentType } from '../parser';\nimport { ApolloError } from '../../errors';\nimport { useApolloClient } from './useApolloClient';\n\nexport function useMutation<\n  TData = any,\n  TVariables = OperationVariables,\n  TContext = DefaultContext,\n  TCache extends ApolloCache<any> = ApolloCache<any>,\n>(\n  mutation: DocumentNode | TypedDocumentNode<TData, TVariables>,\n  options?: MutationHookOptions<TData, TVariables, TContext>,\n): MutationTuple<TData, TVariables, TContext, TCache> {\n  const client = useApolloClient(options?.client);\n  verifyDocumentType(mutation, DocumentType.Mutation);\n  const [result, setResult] = useState<Omit<MutationResult, 'reset'>>({\n    called: false,\n    loading: false,\n    client,\n  });\n\n  const ref = useRef({\n    result,\n    mutationId: 0,\n    isMounted: true,\n    client,\n    mutation,\n    options,\n  });\n\n  // TODO: Trying to assign these in a useEffect or useLayoutEffect breaks\n  // higher-order components.\n  {\n    Object.assign(ref.current, { client, options, mutation });\n  }\n\n  const execute = useCallback((\n    executeOptions: MutationFunctionOptions<\n      TData,\n      TVariables,\n      TContext,\n      TCache\n    > = {}\n  ) => {\n    const {client, options, mutation} = ref.current;\n    const baseOptions = { ...options, mutation };\n    if (!ref.current.result.loading && !baseOptions.ignoreResults) {\n      setResult(ref.current.result = {\n        loading: true,\n        error: void 0,\n        data: void 0,\n        called: true,\n        client,\n      });\n    }\n\n    const mutationId = ++ref.current.mutationId;\n    const clientOptions = mergeOptions(\n      baseOptions,\n      executeOptions as any,\n    );\n\n    return client.mutate(clientOptions).then((response) => {\n      const { data, errors } = response;\n      const error =\n        errors && errors.length > 0\n          ? new ApolloError({ graphQLErrors: errors })\n          : void 0;\n\n      if (\n        mutationId === ref.current.mutationId &&\n        !clientOptions.ignoreResults\n      ) {\n        const result = {\n          called: true,\n          loading: false,\n          data,\n          error,\n          client,\n        };\n\n        if (ref.current.isMounted && !equal(ref.current.result, result)) {\n          setResult(ref.current.result = result);\n        }\n      }\n\n      baseOptions.onCompleted?.(response.data!);\n      executeOptions.onCompleted?.(response.data!);\n      return response;\n    }).catch((error) => {\n      if (\n        mutationId === ref.current.mutationId &&\n        ref.current.isMounted\n      ) {\n        const result = {\n          loading: false,\n          error,\n          data: void 0,\n          called: true,\n          client,\n        };\n\n        if (!equal(ref.current.result, result)) {\n          setResult(ref.current.result = result);\n        }\n      }\n\n      if (baseOptions.onError || clientOptions.onError) {\n        baseOptions.onError?.(error);\n        executeOptions.onError?.(error);\n        // TODO(brian): why are we returning this here???\n        return { data: void 0, errors: error };\n      }\n\n      throw error;\n    });\n  }, []);\n\n  const reset = useCallback(() => {\n    setResult({ called: false, loading: false, client });\n  }, []);\n\n  useEffect(() => () => {\n    ref.current.isMounted = false;\n  }, []);\n\n  return [execute, { reset, ...result }];\n}\n", "import '../../utilities/globals';\nimport { useState, useRef, useEffect } from 'react';\nimport { DocumentNode } from 'graphql';\nimport { TypedDocumentNode } from '@graphql-typed-document-node/core';\nimport { equal } from '@wry/equality';\n\nimport { DocumentType, verifyDocumentType } from '../parser';\nimport {\n  SubscriptionHookOptions,\n  SubscriptionResult\n} from '../types/types';\nimport { OperationVariables } from '../../core';\nimport { useApolloClient } from './useApolloClient';\n\nexport function useSubscription<TData = any, TVariables = OperationVariables>(\n  subscription: DocumentNode | TypedDocumentNode<TData, TVariables>,\n  options?: SubscriptionHookOptions<TData, TVariables>,\n) {\n  const client = useApolloClient(options?.client);\n  verifyDocumentType(subscription, DocumentType.Subscription);\n  const [result, setResult] = useState<SubscriptionResult<TData>>({\n    loading: !options?.skip,\n    error: void 0,\n    data: void 0,\n    variables: options?.variables,\n  });\n\n  const [observable, setObservable] = useState(() => {\n    if (options?.skip) {\n      return null;\n    }\n\n    return client.subscribe({\n      query: subscription,\n      variables: options?.variables,\n      fetchPolicy: options?.fetchPolicy,\n      context: options?.context,\n    });\n  });\n\n  const ref = useRef({ client, subscription, options });\n  useEffect(() => {\n    let shouldResubscribe = options?.shouldResubscribe;\n    if (typeof shouldResubscribe === 'function') {\n      shouldResubscribe = !!shouldResubscribe(options!);\n    }\n\n    if (options?.skip) {\n      if (!options?.skip !== !ref.current.options?.skip) {\n        setResult({\n          loading: false,\n          data: void 0,\n          error: void 0,\n          variables: options?.variables,\n        });\n        setObservable(null);\n      }\n    } else if (\n      shouldResubscribe !== false && (\n        client !== ref.current.client ||\n        subscription !== ref.current.subscription ||\n        options?.fetchPolicy !== ref.current.options?.fetchPolicy ||\n        !options?.skip !== !ref.current.options?.skip ||\n        !equal(options?.variables, ref.current.options?.variables)\n      )\n    ) {\n      setResult({\n        loading: true,\n        data: void 0,\n        error: void 0,\n        variables: options?.variables,\n      });\n      setObservable(client.subscribe({\n        query: subscription,\n        variables: options?.variables,\n        fetchPolicy: options?.fetchPolicy,\n        context: options?.context,\n      }));\n    }\n\n    Object.assign(ref.current, { client, subscription, options });\n  }, [client, subscription, options]);\n\n  useEffect(() => {\n    if (!observable) {\n      return;\n    }\n\n    const subscription = observable.subscribe({\n      next(fetchResult) {\n        const result = {\n          loading: false,\n          // TODO: fetchResult.data can be null but SubscriptionResult.data\n          // expects TData | undefined only\n          data: fetchResult.data!,\n          error: void 0,\n          variables: options?.variables,\n        };\n        setResult(result);\n\n        ref.current.options?.onSubscriptionData?.({\n          client,\n          subscriptionData: result\n        });\n      },\n      error(error) {\n        setResult({\n          loading: false,\n          data: void 0,\n          error,\n          variables: options?.variables,\n        });\n      },\n      complete() {\n        ref.current.options?.onSubscriptionComplete?.();\n      },\n    });\n\n    return () => {\n      subscription.unsubscribe();\n    };\n  }, [observable]);\n\n  return result;\n}\n", "import { useEffect, useState } from 'react';\nimport { ReactiveVar } from '../../core';\n\nexport function useReactiveVar<T>(rv: ReactiveVar<T>): T {\n  const value = rv();\n\n  // We don't actually care what useState thinks the value of the variable\n  // is, so we take only the update function from the returned array.\n  const setValue = useState(value)[1];\n\n  // We subscribe to variable updates on initial mount and when the value has\n  // changed. This avoids a subtle bug in React.StrictMode where multiple\n  // listeners are added, leading to inconsistent updates.\n  useEffect(() => {\n    const probablySameValue = rv();\n    if (value !== probablySameValue) {\n      // If the value of rv has already changed, we don't need to listen for the\n      // next change, because we can report this change immediately.\n      setValue(probablySameValue);\n    } else {\n      return rv.onNextChange(setValue);\n    }\n  }, [value]);\n\n  return value;\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAO,IAAM,UAAU;;;ACGf,IAAA,iBAAmB,OAAO,UAAS;AAQrC,mCACJ,YAAmC;AAEnC,SAAO,SAAC,UAAkB;AAAK,WAAA,SAC5B,OACA,KAAK,SAAA,UAAQ;AACZ,UAAI;AACF,eAAO,KAAK,MAAM;eACX,KAAP;AACA,YAAM,aAAa;AACnB,mBAAW,OAAO;AAClB,mBAAW,WAAW;AACtB,mBAAW,aAAa,SAAS;AACjC,mBAAW,WAAW;AACtB,cAAM;;OAGT,KAAK,SAAC,QAAW;AAChB,UAAI,SAAS,UAAU,KAAK;AAE1B,yBACE,UACA,QACA,iDAAA,OAAiD,SAAS;;AAI9D,UACE,CAAC,MAAM,QAAQ,WACf,CAAC,eAAe,KAAK,QAAQ,WAC7B,CAAC,eAAe,KAAK,QAAQ,WAC7B;AAEA,yBACE,UACA,QACA,0CAAA,OACE,MAAM,QAAQ,cACV,WAAW,IAAI,SAAA,IAAE;AAAI,iBAAA,GAAG;aACxB,WAAW,eAAa;;AAIlC,aAAO;;;;;;AChDN,IAAM,0BAA0B,SAAC,GAAQ,OAAa;AAC3D,MAAI;AACJ,MAAI;AACF,iBAAa,KAAK,UAAU;WACrB,GAAP;AACA,QAAM,aAAa,UAAI,IAAA,eACrB,2BAA2B,OAAK,OAAA,0BAA2B,OAAS,EAChD,YAAA,IAAA,eAAA;AACtB,eAAW,aAAa;AACxB,UAAM;;AAER,SAAO;;;;ACyET,IAAM,qBAAuC;EAC3C,cAAc;EACd,mBAAmB;;AAGrB,IAAM,iBAAiB;EAErB,QAAQ;EACR,gBAAgB;;AAGlB,IAAM,iBAAiB;EACrB,QAAQ;;AAGH,IAAM,qBAAqB;EAChC,MAAM;EACN,SAAS;EACT,SAAS;;AAGJ,IAAM,iBAA0B,SAAC,KAAK,SAAO;AAAK,SAAA,QAAQ;;AAE3D,kCACJ,WACA,gBAA0B;AAC1B,MAAA,UAAA;WAAA,KAAA,GAAA,KAAA,UAAA,QAAA,MAA6B;AAA7B,YAAA,KAAA,KAAA,UAAA;;AAEA,UAAQ,QAAQ;AAChB,SAAO,iCAAgC,MAAA,QAAA,cAAA;IACrC;IACA;KACG,SAAO;;AAIR,0CACJ,WACA,SAAgB;AAChB,MAAA,UAAA;WAAA,KAAA,GAAA,KAAA,UAAA,QAAA,MAAwB;AAAxB,YAAA,KAAA,KAAA,UAAA;;AAEA,MAAI,UAAU;AACd,MAAI,OAAO;AAEX,UAAQ,QAAQ,SAAA,QAAM;AACpB,cAAO,SAAA,SAAA,SAAA,IACF,UACA,OAAO,UAAO,EACjB,SAAO,SAAA,SAAA,IACF,QAAQ,UACR,mBAAmB,OAAO;AAIjC,QAAI,OAAO,aAAa;AACtB,cAAQ,cAAc,OAAO;;AAG/B,WAAI,SAAA,SAAA,IACC,OACA,OAAO;;AAKN,MAAA,iBAAgD,UAAS,eAA1C,aAAiC,UAAS,YAA9B,YAAqB,UAAS,WAAnB,QAAU,UAAS;AACjE,MAAM,OAAa,EAAE,eAAa,gBAAE;AAEpC,MAAI,KAAK;AAAoB,SAAa,aAAa;AAGvD,MAAI,KAAK;AAAe,SAAa,QAAQ,QAAQ,OAAO;AAE5D,SAAO;IACL;IACA;;;AAIJ,4BACE,SAA2C;AAE3C,MAAI,SAAS;AACX,QAAM,eAAa,uBAAO,OAAO;AACjC,WAAO,KAAK,OAAO,UAAU,QAAQ,SAAA,MAAI;AACvC,mBAAW,KAAK,iBAAiB,QAAQ;;AAE3C,WAAO;;AAET,SAAO;;;;ACjLF,IAAM,eAAe,SAAC,SAAuD;AAClF,MAAI,CAAC,WAAW,OAAO,UAAU,aAAa;AAC5C,UAAM,UAAI,IAAA,eAAe;;;;;;;;SAWtB,IAAA,eAAA;;;;;ACfA,IAAM,0BAA0B,WAAA;AACrC,MAAI,OAAO,oBAAoB;AAC7B,WAAO,EAAE,YAAY,OAAO,QAAQ;AAEtC,MAAM,aAAa,IAAI;AACvB,MAAM,SAAS,WAAW;AAC1B,SAAO,EAAE,YAAY;;;;ACJhB,IAAM,YAAY,SACvB,WACA,aAAyD;AAEzD,MAAM,UAAU,UAAU;AAC1B,MAAM,aAAa,QAAQ;AAE3B,MAAI,YAAY;AACd,WAAO;aACE,OAAO,gBAAgB,YAAY;AAC5C,WAAO,YAAY;SACd;AACL,WAAQ,eAA0B;;;;;ACThC,0BAA2B,WAAmB,MAAU;AAG5D,MAAM,cAAwB;AAC9B,MAAM,gBAAgB,SAAC,KAAa,OAAa;AAC/C,gBAAY,KAAK,GAAA,OAAG,KAAG,KAAA,OAAI,mBAAmB;;AAGhD,MAAI,WAAW,MAAM;AACnB,kBAAc,SAAS,KAAK;;AAE9B,MAAI,KAAK,eAAe;AACtB,kBAAc,iBAAiB,KAAK;;AAEtC,MAAI,KAAK,WAAW;AAClB,QAAI,sBAAmB;AACvB,QAAI;AACF,4BAAsB,wBACpB,KAAK,WACL;aAEK,YAAP;AACA,aAAO,EAAE;;AAEX,kBAAc,aAAa;;AAE7B,MAAI,KAAK,YAAY;AACnB,QAAI,uBAAoB;AACxB,QAAI;AACF,6BAAuB,wBACrB,KAAK,YACL;aAEK,YAAP;AACA,aAAO,EAAE;;AAEX,kBAAc,cAAc;;AAS9B,MAAI,WAAW,IACb,cAAc;AAChB,MAAM,gBAAgB,UAAU,QAAQ;AACxC,MAAI,kBAAkB,IAAI;AACxB,eAAW,UAAU,OAAO;AAC5B,kBAAc,UAAU,OAAO,GAAG;;AAEpC,MAAM,oBAAoB,YAAY,QAAQ,SAAS,KAAK,MAAM;AAClE,MAAM,SACJ,cAAc,oBAAoB,YAAY,KAAK,OAAO;AAC5D,SAAO,EAAE;;;;ACvCX,IAAM,cAAc,MAAM,WAAA;AAAM,SAAA;;AAEzB,IAAM,iBAAiB,SAAC,aAA6B;AAA7B,MAAA,gBAAA,QAAA;AAAA,kBAAA;;AAE3B,MAAA,MAQE,YAAW,KARb,MAAG,QAAA,SAAG,aAAU,KAET,iBAML,YAAW,OALb,KAKE,YAAW,OALb,SAAK,OAAA,SAAG,iBAAc,IACtB,oBAIE,YAAW,mBAHb,mBAGE,YAAW,kBAFb,KAEE,YAAW,wBAFb,yBAAsB,OAAA,SAAG,QAAK,IAC3B,iBAAc,OACf,aATA,CAAA,OAAA,SAAA,SAAA,qBAAA,oBAAA;AAWJ,MAAI,SAAS;AAGX,iBAAa,kBAAkB;;AAGjC,MAAM,aAAa;IACjB,MAAM,EAAE;IACR,SAAS,eAAe;IACxB,aAAa,eAAe;IAC5B,SAAS,eAAe;;AAG1B,SAAO,IAAI,WAAW,SAAA,WAAS;AAC7B,QAAI,YAAY,UAAU,WAAW;AAErC,QAAM,UAAU,UAAU;AAQ1B,QAAM,yBAGF;AAEJ,QAAI,QAAQ,iBAAiB;AACrB,UAAA,MAAoB,QAAQ,iBAA1B,SAAI,IAAA,MAAE,WAAO,IAAA;AACrB,UAAI,QAAM;AACR,+BAAuB,+BAA+B;;AAExD,UAAI,UAAS;AACX,+BAAuB,kCAAkC;;;AAI7D,QAAM,iBAAc,SAAA,SAAA,IAAQ,yBAA2B,QAAQ;AAE/D,QAAM,gBAAgB;MACpB,MAAM,QAAQ;MACd,SAAS,QAAQ;MACjB,aAAa,QAAQ;MACrB,SAAS;;AAIL,QAAA,MAAoB,iCACxB,WACA,QACA,oBACA,YACA,gBALM,UAAO,IAAA,SAAE,OAAI,IAAA;AAQrB,QAAI,KAAK,aAAa,CAAC,wBAAwB;AAC7C,UAAM,gBAAc,IAAI,IAAI,OAAO,KAAK,KAAK;AAC7C,YAAM,UAAU,OAAO;QACrB,UAAA,SAAS,MAAM,MAAM,QAAM;AAKzB,cAAI,UAAW,OAAkC,SAAS,sBAAsB;AAC9E,0BAAY,OAAO,KAAK,KAAK;;;;AAInC,UAAI,cAAY,MAAM;AAGpB,aAAK,YAAS,SAAA,IAAQ,KAAK;AAC3B,sBAAY,QAAQ,SAAA,MAAI;AACtB,iBAAO,KAAK,UAAW;;;;AAK7B,QAAI;AACJ,QAAI,CAAE,QAAgB,QAAQ;AACtB,UAAA,MAAsC,2BAAxB,cAAW,IAAA,YAAE,SAAM,IAAA;AACvC,mBAAa;AACb,UAAI;AAAa,gBAAgB,SAAS;;AAI5C,QAAM,uBAAuB,SAAC,GAAiB;AAC7C,aAAO,EAAE,SAAS,yBAAyB,EAAE,cAAc;;AAE7D,QACE,oBACA,CAAC,UAAU,MAAM,YAAY,KAAK,uBAClC;AACA,cAAQ,SAAS;;AAGnB,QAAI,QAAQ,WAAW,OAAO;AACtB,UAAA,KAAyB,iBAAiB,WAAW,OAAnD,SAAM,GAAA,QAAE,aAAU,GAAA;AAC1B,UAAI,YAAY;AACd,eAAO,UAAU;;AAEnB,kBAAY;WACP;AACL,UAAI;AACD,gBAAgB,OAAO,wBAAwB,MAAM;eAC/C,aAAP;AACA,eAAO,UAAU;;;AAIrB,WAAO,IAAI,WAAW,SAAA,UAAQ;AAM5B,UAAM,eAAe,kBAAkB,MAAM,WAAA;AAAM,eAAA;YAAU;AAE7D,mBAAc,WAAW,SACtB,KAAK,SAAA,UAAQ;AACZ,kBAAU,WAAW,EAAE;AACvB,eAAO;SAER,KAAK,0BAA0B,YAC/B,KAAK,SAAA,QAAM;AAEV,iBAAS,KAAK;AACd,iBAAS;AACT,eAAO;SAER,MAAM,SAAA,KAAG;AAER,YAAI,IAAI,SAAS;AAAc;AAO/B,YAAI,IAAI,UAAU,IAAI,OAAO,UAAU,IAAI,OAAO,MAAM;AA2BtD,mBAAS,KAAK,IAAI;;AAEpB,iBAAS,MAAM;;AAGnB,aAAO,WAAA;AAGL,YAAI;AAAY,qBAAW;;;;;;;AC/MnC,IAAA,WAAA,SAAA,QAAA;AAA8B,YAAA,WAAA;AAE5B,qBAAmB,SAAyB;AAAzB,QAAA,YAAA,QAAA;AAAA,gBAAA;;AAAnB,QAAA,QACE,OAAA,KAAA,MAAM,eAAe,SAAS,YAAQ;AADrB,UAAA,UAAA;;;AAGrB,SAAA;EAL8B;;;ACJxB,IAAA,KAA+B,OAAO;AAAtC,IAAE,WAAQ,GAAA;AAAV,IAAY,kBAAc,GAAA;AAChC,IAAM,UAAU,SAAS,UAAU;AACnC,IAAM,sBAAsB,oBAAI;eAKV,GAAQ,GAAM;AAClC,MAAI;AACF,WAAO,MAAM,GAAG;;AAEhB,wBAAoB;;;AAOxB,eAAe,GAAQ,GAAM;AAE3B,MAAI,MAAM,GAAG;AACX,WAAO;;AAKT,MAAM,OAAO,SAAS,KAAK;AAC3B,MAAM,OAAO,SAAS,KAAK;AAK3B,MAAI,SAAS,MAAM;AACjB,WAAO;;AAGT,UAAQ;SACD;AAGH,UAAI,EAAE,WAAW,EAAE;AAAQ,eAAO;SAE/B,mBAAmB;AACtB,UAAI,mBAAmB,GAAG;AAAI,eAAO;AAErC,UAAM,QAAQ,YAAY;AAC1B,UAAM,QAAQ,YAAY;AAI1B,UAAM,WAAW,MAAM;AACvB,UAAI,aAAa,MAAM;AAAQ,eAAO;AAGtC,eAAS,IAAI,GAAG,IAAI,UAAU,EAAE,GAAG;AACjC,YAAI,CAAC,gBAAe,KAAK,GAAG,MAAM,KAAK;AACrC,iBAAO;;;AAKX,eAAS,IAAI,GAAG,IAAI,UAAU,EAAE,GAAG;AACjC,YAAM,MAAM,MAAM;AAClB,YAAI,CAAC,MAAM,EAAE,MAAM,EAAE,OAAO;AAC1B,iBAAO;;;AAIX,aAAO;;SAGJ;AACH,aAAO,EAAE,SAAS,EAAE,QAAQ,EAAE,YAAY,EAAE;SAEzC;AAEH,UAAI,MAAM;AAAG,eAAO,MAAM;SAEvB;SACA;AACH,aAAO,CAAC,MAAM,CAAC;SAEZ;SACA;AACH,aAAO,KAAK,KAAG;SAEZ;SACA,gBAAgB;AACnB,UAAI,EAAE,SAAS,EAAE;AAAM,eAAO;AAC9B,UAAI,mBAAmB,GAAG;AAAI,eAAO;AAErC,UAAM,YAAY,EAAE;AACpB,UAAM,QAAQ,SAAS;AAEvB,aAAO,MAAM;AACX,YAAM,OAAO,UAAU;AACvB,YAAI,KAAK;AAAM;AAGT,YAAA,MAAiB,KAAK,OAArB,OAAI,IAAA,IAAE,SAAM,IAAA;AAGnB,YAAI,CAAC,EAAE,IAAI,OAAO;AAChB,iBAAO;;AAKT,YAAI,SAAS,CAAC,MAAM,QAAQ,EAAE,IAAI,QAAQ;AACxC,iBAAO;;;AAIX,aAAO;;SAGJ;SACA;SACA;SACA;SACA;SACA;SACA;AAGH,UAAI,IAAI,WAAW;AACnB,UAAI,IAAI,WAAW;SAEhB,qBAAqB;AACxB,UAAI,MAAM,EAAE;AACZ,UAAI,QAAQ,EAAE,YAAY;AACxB,eAAO,SAAS,EAAE,SAAS,EAAE,MAAM;;;AAIrC,aAAO,QAAQ;;SAGZ;SACA;SACA;SACA,qBAAqB;AACxB,UAAM,QAAQ,QAAQ,KAAK;AAC3B,UAAI,UAAU,QAAQ,KAAK,IAAI;AAC7B,eAAO;;AA0BT,aAAO,CAAC,SAAS,OAAO;;;AAK5B,SAAO;;AAGT,qBAA6C,KAAY;AAGvD,SAAO,OAAO,KAAK,KAAK,OAAO,cAAc;;AAE/C,sBAEE,KAAkB;AAElB,SAAO,KAAK,SAAS;;AAGvB,IAAM,mBAAmB;AAEzB,kBAAkB,MAAc,QAAc;AAC5C,MAAM,YAAY,KAAK,SAAS,OAAO;AACvC,SAAO,aAAa,KAClB,KAAK,QAAQ,QAAQ,eAAe;;AAGxC,4BAA4B,GAAW,GAAS;AAS9C,MAAI,OAAO,oBAAoB,IAAI;AACnC,MAAI,MAAM;AAGR,QAAI,KAAK,IAAI;AAAI,aAAO;SACnB;AACL,wBAAoB,IAAI,GAAG,OAAO,oBAAI;;AAExC,OAAK,IAAI;AACT,SAAO;;;;AClNT,IAAM,kBAAkB,WAAA;AAAM,SAAA,uBAAO,OAAO;;AAGtC,IAAA,MAAqB,MAAM;AAA3B,IAAE,UAAO,IAAA;AAAT,IAAW,QAAK,IAAA;;AAUpB,iBACU,UACA,UAAkD;AADlD,QAAA,aAAA,QAAA;AAAA,iBAAA;;AACA,QAAA,aAAA,QAAA;AAAA,iBAAA;;AADA,SAAA,WAAA;AACA,SAAA,WAAA;;AAGH,QAAA,UAAA,SAAP,WAAA;AAA+B,QAAA,QAAA;aAAA,KAAA,GAAA,KAAA,UAAA,QAAA,MAAW;AAAX,YAAA,MAAA,UAAA;;AAC7B,WAAO,KAAK,YAAY;;AAGnB,QAAA,UAAA,cAAP,SAAiD,OAAQ;AACvD,QAAI,OAAmB;AACvB,YAAQ,KAAK,OAAO,SAAA,KAAG;AAAI,aAAA,OAAO,KAAK,aAAa;;AACpD,WAAO,KAAK,QAAS,MAAK,OAAO,KAAK,SAAS,MAAM,KAAK;;AAGpD,QAAA,UAAA,eAAR,SAAqB,KAAQ;AAC3B,QAAM,MAAM,KAAK,YAAY,SAAS,OAClC,KAAK,QAAS,MAAK,OAAO,oBAAI,aAC9B,KAAK,UAAW,MAAK,SAAS,oBAAI;AACtC,QAAI,QAAQ,IAAI,IAAI;AACpB,QAAI,CAAC;AAAO,UAAI,IAAI,KAAK,QAAQ,IAAI,MAAW,KAAK,UAAU,KAAK;AACpE,WAAO;;AAEX,SAAA;;AAEA,kBAAkB,OAAU;AAC1B,UAAQ,OAAO;SACV;AACH,UAAI,UAAU;AAAM;SAEjB;AACH,aAAO;;AAET,SAAO;;;;AC5CT,IAAI,iBAAiC;AAIrC,IAAM,gBAAqB;AAE3B,IAAI,YAAY;AAKhB,IAAM,gBAAgB,WAAA;AAAM,SAAA,WAAA;AAAA,qBAAA;AAIV,WAAA,KAAK;QACnB;QACA;QACA,KAAK;QACL,KAAK,SAAS,SAAS,IAAI,MAAM;QACjC,KAAK;;AAEA,UAAA,UAAA,WAAP,WAAA;AACE,eAAS,YAAU,gBAAgB,WAAS,YAAU,UAAQ,QAAQ;AAGpE,YAAI,KAAK,MAAM,UAAQ,OAAO;AAC5B,cAAM,QAAQ,UAAQ,MAAM,KAAK;AACjC,cAAI,UAAU;AAAe;AAC7B,cAAI,cAAY,gBAAgB;AAI9B,2BAAgB,MAAM,KAAK,MAAM;;AAEnC,iBAAO;;;AAGX,UAAI,gBAAgB;AAIlB,uBAAe,MAAM,KAAK,MAAM;;AAElC,aAAO;;AAGF,UAAA,UAAA,WAAP,WAAA;AACE,UAAI,KAAK,YAAY;AACnB,eAAO,eAAgB,MAAM,KAAK;;;AAI/B,UAAA,UAAA,YAAP,SACE,OACA,UAGA,MACA,SAAe;;AAEf,UAAM,QAAK,OAAA;QACT,WAAW;SACX,IAAC,KAAK,MAAK;AAEb,UAAM,SAAS;AACf,uBAAiB,EAAE,QAAQ;AAC3B,UAAI;AAGF,eAAO,SAAS,MAAM,SAAU;;AAEhC,yBAAiB;;;AAMd,UAAA,OAAP,SACE,UAAkD;AAElD,UAAM,UAAU;AAChB,aAAO,WAAA;AACL,YAAM,QAAQ;AACd,YAAI;AACF,2BAAiB;AACjB,iBAAO,SAAS,MAAM,MAAM;;AAE5B,2BAAiB;;;;AAMhB,UAAA,YAAP,SACE,UAGA,MACA,SAAe;AAEf,UAAI,gBAAgB;AAClB,YAAM,QAAQ;AACd,YAAI;AACF,2BAAiB;AAGjB,iBAAO,SAAS,MAAM,SAAU;;AAEhC,2BAAiB;;aAEd;AACL,eAAO,SAAS,MAAM,SAAU;;;AAGtC,WAAA;;;AAUA,IAAM,YAAY;AAClB,IAAM,OAAO;IAEA,OAAyC,KAAK,cAAc,WAAA;AACvE,MAAM,QAAO;AACb,MAAI;AACF,WAAO,eAAe,MAAM,WAAW;MACrC,OAAO,KAAK,aAAa;MACzB,YAAY;MACZ,UAAU;MACV,cAAc;;;AAGhB,WAAO;;;IChJI,OAAoB,KAAI;IAAlB,YAAc,KAAI;;;ACKvC,0BAAuB;;AAEvB,IAAA,QAAA,WAAA;AAKE,kBACU,KACD,SAAoD;AADnD,QAAA,QAAA,QAAA;AAAA,YAAA;;AACD,QAAA,YAAA,QAAA;AAAA,gBAAA;;AADC,SAAA,MAAA;AACD,SAAA,UAAA;AAND,SAAA,MAAM,oBAAI;AACV,SAAA,SAA4B;AAC5B,SAAA,SAA4B;;AAO7B,SAAA,UAAA,MAAP,SAAW,KAAM;AACf,WAAO,KAAK,IAAI,IAAI;;AAGf,SAAA,UAAA,MAAP,SAAW,KAAM;AACf,QAAM,OAAO,KAAK,QAAQ;AAC1B,WAAO,QAAQ,KAAK;;AAGd,SAAA,UAAA,UAAR,SAAgB,KAAM;AACpB,QAAM,OAAO,KAAK,IAAI,IAAI;AAE1B,QAAI,QAAQ,SAAS,KAAK,QAAQ;AACxB,UAAA,QAAiB,KAAI,OAAd,QAAU,KAAI;AAE7B,UAAI,OAAO;AACT,cAAM,QAAQ;;AAGhB,UAAI,OAAO;AACT,cAAM,QAAQ;;AAGhB,WAAK,QAAQ,KAAK;AAClB,WAAK,MAAO,QAAQ;AAEpB,WAAK,QAAQ;AACb,WAAK,SAAS;AAEd,UAAI,SAAS,KAAK,QAAQ;AACxB,aAAK,SAAS;;;AAIlB,WAAO;;AAGF,SAAA,UAAA,MAAP,SAAW,KAAQ,OAAQ;AACzB,QAAI,OAAO,KAAK,QAAQ;AACxB,QAAI,MAAM;AACR,aAAO,KAAK,QAAQ;;AAGtB,WAAO;MACL;MACA;MACA,OAAO;MACP,OAAO,KAAK;;AAGd,QAAI,KAAK,QAAQ;AACf,WAAK,OAAO,QAAQ;;AAGtB,SAAK,SAAS;AACd,SAAK,SAAS,KAAK,UAAU;AAE7B,SAAK,IAAI,IAAI,KAAK;AAElB,WAAO,KAAK;;AAGP,SAAA,UAAA,QAAP,WAAA;AACE,WAAO,KAAK,UAAU,KAAK,IAAI,OAAO,KAAK,KAAK;AAC9C,WAAK,OAAO,KAAK,OAAO;;;AAIrB,SAAA,UAAA,SAAP,SAAc,KAAM;AAClB,QAAM,OAAO,KAAK,IAAI,IAAI;AAC1B,QAAI,MAAM;AACR,UAAI,SAAS,KAAK,QAAQ;AACxB,aAAK,SAAS,KAAK;;AAGrB,UAAI,SAAS,KAAK,QAAQ;AACxB,aAAK,SAAS,KAAK;;AAGrB,UAAI,KAAK,OAAO;AACd,aAAK,MAAM,QAAQ,KAAK;;AAG1B,UAAI,KAAK,OAAO;AACd,aAAK,MAAM,QAAQ,KAAK;;AAG1B,WAAK,IAAI,OAAO;AAChB,WAAK,QAAQ,KAAK,OAAO;AAEzB,aAAO;;AAGT,WAAO;;AAEX,SAAA;;AC/GO,IAAM,kBAAkB,IAAI;;ACFjC,IAAA,kBACE,OAAO,UAAS;AAQlB,IAAM,UAAN,OAKE,MAAK,MADN,QAAA,SAJe,SAAC,YAAoB;AACnC,MAAM,QAAe;AACrB,aAAW,QAAQ,SAAA,MAAI;AAAI,WAAA,MAAM,KAAK;;AACtC,SAAO;IACR;0BAO8B,YAA0B;AACjD,MAAA,cAAgB,WAAU;AAClC,MAAI,OAAO,gBAAgB,YAAY;AACrC,eAAW,cAAc;AACzB;;;ACpBJ,IAAM,eAA2B;AACjC,IAAM,mBAAmB;AAIzB,gBAAgB,WAAgB,iBAAwB;AACtD,MAAI,CAAE,WAAW;AACf,UAAM,IAAI,MAAM,mBAAmB;;;AAWvC,iBAAiB,GAAe,GAAa;AAC3C,MAAM,MAAM,EAAE;AACd,SAEE,MAAM,KAEN,QAAQ,EAAE,UAEV,EAAE,MAAM,OAAO,EAAE,MAAM;;AAI3B,kBAAqB,OAAe;AAClC,UAAQ,MAAM;SACP;AAAG,YAAM,IAAI,MAAM;SACnB;AAAG,aAAO,MAAM;SAChB;AAAG,YAAM,MAAM;;;AAIxB,mBAAsB,OAAe;AACnC,SAAO,MAAM,MAAM;;AAKrB,IAAA,QAAA,WAAA;AAkBE,kBACkB,IAA8B;AAA9B,SAAA,KAAA;AAbF,SAAA,UAAU,oBAAI;AACd,SAAA,cAAc,oBAAI;AAK3B,SAAA,gBAAsC;AAEtC,SAAA,QAAQ;AACR,SAAA,cAAc;AACL,SAAA,QAAuB;AAwE/B,SAAA,OAA6B;AAnEnC,MAAE,OAAM;;AAGH,SAAA,UAAA,OAAP,WAAA;AACE,QAAI,KAAK,MAAM,WAAW,KAAK,CAAC,aAAa,OAAO;AAClD,qBAAe;AACf,aAAO,KAAK,MAAM;;;AAUf,SAAA,UAAA,YAAP,SAAiB,MAAW;AAC1B,WAAO,CAAE,KAAK,aAAa;AAC3B,mBAAe;AACf,WAAO,aAAa,QAChB,gBAAgB,MAAM,QACtB,SAAS,KAAK;;AAGb,SAAA,UAAA,WAAP,WAAA;AACE,QAAI,KAAK;AAAO;AAChB,SAAK,QAAQ;AACb,SAAK,MAAM,SAAS;AACpB,gBAAY;AAIZ,qBAAiB;;AAGZ,SAAA,UAAA,UAAP,WAAA;AAAA,QAAA,QAAA;AACE,SAAK;AAKL,mBAAe;AAaf,eAAW,MAAM,SAAC,QAAQ,OAAK;AAC7B,aAAO;AACP,kBAAY,QAAQ;;;AAIjB,SAAA,UAAA,SAAP,WAAA;AAIE,SAAK;;AAKA,SAAA,UAAA,WAAP,SAAgB,MAAa;AAC3B,SAAI,IAAI;AACR,QAAI,CAAE,KAAK,MAAM;AACf,WAAK,OAAO,aAAa,SAAS,oBAAI;;AAExC,SAAK,KAAK,IAAI;;AAGT,SAAA,UAAA,aAAP,WAAA;AAAA,QAAA,QAAA;AACE,QAAI,KAAK,MAAM;AACb,cAAQ,KAAK,MAAM,QAAQ,SAAA,MAAG;AAAI,eAAA,KAAI,OAAO;;AAC7C,WAAK,KAAK;AACV,mBAAa,KAAK,KAAK;AACvB,WAAK,OAAO;;;AAtGF,SAAA,QAAQ;AAyGxB,SAAA;;AAEA,wBAAwB,OAAe;AACrC,MAAM,SAAS,gBAAgB;AAC/B,MAAI,QAAQ;AACV,UAAM,QAAQ,IAAI;AAElB,QAAI,CAAE,OAAO,YAAY,IAAI,QAAQ;AACnC,aAAO,YAAY,IAAI,OAAO;;AAGhC,QAAI,aAAa,QAAQ;AACvB,uBAAiB,QAAQ;WACpB;AACL,uBAAiB,QAAQ;;AAG3B,WAAO;;;AAIX,yBAAyB,OAAiB,MAAW;AACnD,iBAAe;AAGf,kBAAgB,UAAU,OAAO,mBAAmB,CAAC,OAAO;AAE5D,MAAI,eAAe,OAAO,OAAO;AAG/B,aAAS;;AAGX,SAAO,SAAS,MAAM;;AAGxB,2BAA2B,OAAiB,MAAW;AACrD,QAAM,cAAc;AAEpB,QAAM,MAAM,SAAS;AACrB,MAAI;AAEF,UAAM,MAAM,KAAK,MAAM,GAAG,MAAM,MAAM;WAC/B,GAAP;AAEA,UAAM,MAAM,KAAK;;AAGnB,QAAM,cAAc;;AAGtB,sBAAsB,OAAe;AACnC,SAAO,MAAM,SAAS,CAAC,CAAE,OAAM,iBAAiB,MAAM,cAAc;;AAGtE,kBAAkB,OAAe;AAC/B,QAAM,QAAQ;AAEd,MAAI,aAAa,QAAQ;AAGvB;;AAGF,cAAY;;AAGd,qBAAqB,OAAe;AAClC,aAAW,OAAO;;AAGpB,qBAAqB,OAAe;AAClC,aAAW,OAAO;;AAGpB,oBACE,OACA,UAAoD;AAEpD,MAAM,cAAc,MAAM,QAAQ;AAClC,MAAI,aAAa;AACf,QAAM,UAAU,QAAQ,MAAM;AAC9B,aAAS,IAAI,GAAG,IAAI,aAAa,EAAE,GAAG;AACpC,eAAS,QAAQ,IAAI;;;;AAM3B,0BAA0B,QAAkB,OAAe;AAGzD,SAAO,OAAO,YAAY,IAAI;AAC9B,SAAO,aAAa;AACpB,MAAM,iBAAiB,CAAC,aAAa;AAErC,MAAI,CAAE,OAAO,eAAe;AAC1B,WAAO,gBAAgB,aAAa,SAAS,oBAAI;aAExC,OAAO,cAAc,IAAI,QAAQ;AAI1C;;AAGF,SAAO,cAAc,IAAI;AAIzB,MAAI,gBAAgB;AAClB,gBAAY;;;AAKhB,0BAA0B,QAAkB,OAAe;AAGzD,SAAO,OAAO,YAAY,IAAI;AAC9B,SAAO,CAAE,aAAa;AAEtB,MAAM,aAAa,OAAO,YAAY,IAAI;AAC1C,MAAI,WAAW,WAAW,GAAG;AAC3B,WAAO,YAAY,IAAI,OAAO,UAAU,MAAM;aACrC,CAAE,QAAQ,YAAY,MAAM,QAAQ;AAC7C,WAAO;;AAGT,mBAAiB,QAAQ;AAEzB,MAAI,aAAa,SAAS;AACxB;;AAGF,cAAY;;AAGd,0BAA0B,QAAkB,OAAe;AACzD,MAAM,KAAK,OAAO;AAClB,MAAI,IAAI;AACN,OAAG,OAAO;AACV,QAAI,GAAG,SAAS,GAAG;AACjB,UAAI,aAAa,SAAS,kBAAkB;AAC1C,qBAAa,KAAK;;AAEpB,aAAO,gBAAgB;;;;AAO7B,wBAAwB,QAAgB;AACtC,MAAI,OAAO,YAAY,OAAO,GAAG;AAC/B,WAAO,YAAY,QAAQ,SAAC,QAAQ,OAAK;AACvC,kBAAY,QAAQ;;;AAMxB,SAAO;AAIP,SAAO,OAAO,kBAAkB;;AAGlC,qBAAqB,QAAkB,OAAe;AACpD,QAAM,QAAQ,OAAO;AACrB,SAAO,YAAY,OAAO;AAC1B,mBAAiB,QAAQ;;AAG3B,wBAAwB,OAAiB,MAAW;AAClD,MAAI,OAAO,MAAM,cAAc,YAAY;AACzC,QAAI;AACF,uBAAiB;AACjB,YAAM,cAAc,MAAM,UAAU,MAAM,MAAM;aACzC,GAAP;AAKA,YAAM;AACN,aAAO;;;AAMX,SAAO;;ACrVT,IAAM,eAAe;EACnB,UAAU;EACV,SAAS;EACT,QAAQ;;aAYgB,SAEzB;AACC,MAAM,YAAY,oBAAI;AACtB,MAAM,YAAY,WAAW,QAAQ;AAErC,kBAAgB,KAAS;AACvB,QAAM,SAAS,gBAAgB;AAC/B,QAAI,QAAQ;AACV,UAAI,QAAM,UAAU,IAAI;AACxB,UAAI,CAAC,OAAK;AACR,kBAAU,IAAI,KAAK,QAAM,oBAAI;;AAE/B,aAAO,SAAS;AAChB,UAAI,OAAO,cAAc,YAAY;AACnC,yBAAiB;AACjB,cAAI,cAAc,UAAU;;;;AAKlC,SAAO,QAAQ,eACb,KACA,iBAAiC;AAEjC,QAAM,OAAM,UAAU,IAAI;AAC1B,QAAI,MAAK;AACP,UAAM,MACJ,mBACA,gBAAe,KAAK,cAAc,mBAChC,kBAAkB;AAItB,cAAQ,MAAK,QAAQ,SAAA,OAAK;AAAI,eAAA,MAAM;;AACpC,gBAAU,OAAO;AACjB,uBAAiB;;;AAIrB,SAAO;;ACpCT,2CAAwC;AAItC,MAAM,UAAU,IAAI,KAAgB,OAAO,YAAY;AACvD,SAAO,WAAA;AACL,WAAO,QAAQ,YAAY;;;IAWlB,sBAAsB;AAoEnC,IAAM,SAAS,oBAAI;cAQjB,kBACA,SAAqE;AAArE,MAAA,YAAA,QAAA;AAAA,cAAkD,uBAAO,OAAO;;AAEhE,MAAM,SAAQ,IAAI,MAChB,QAAQ,OAAO,KAAK,IAAI,GAAG,KAC3B,SAAA,OAAK;AAAI,WAAA,MAAM;;AAGjB,MAAM,UAAU,QAAQ;AACxB,MAAM,eAAe,QAAQ,gBAC3B;AAEF,MAAM,aAAa,WAAA;AACjB,QAAM,MAAM,aAAa,MACvB,MACA,UAAU,QAAQ,MAAM,MAAM,aAAoB;AAGpD,QAAI,QAAQ,QAAQ;AAClB,aAAO,iBAAiB,MAAM,MAAM;;AAGtC,QAAI,QAAQ,OAAM,IAAI;AACtB,QAAI,CAAC,OAAO;AACV,aAAM,IAAI,KAAK,QAAQ,IAAI,MAAM;AACjC,YAAM,YAAY,QAAQ;AAG1B,YAAM,SAAS,WAAA;AAAM,eAAA,OAAM,OAAO;;;AAGpC,QAAM,QAAQ,MAAM,UAClB,MAAM,UAAU,MAAM,KAAK;AAK7B,WAAM,IAAI,KAAK;AAEf,WAAO,IAAI;AAKX,QAAI,CAAE,gBAAgB,YAAY;AAChC,aAAO,QAAQ,SAAA,QAAK;AAAI,eAAA,OAAM;;AAC9B,aAAO;;AAGT,WAAO;;AAGT,SAAO,eAAe,YAAY,QAAQ;IACxC,KAAG,WAAA;AACD,aAAO,OAAM,OAAO;;IAEtB,cAAc;IACd,YAAY;;AAGd,oBAAkB,KAAc;AAC9B,QAAM,QAAQ,OAAM,IAAI;AACxB,QAAI,OAAO;AACT,YAAM;;;AAGV,aAAW,WAAW;AACtB,aAAW,QAAQ,iBAAc;AAC/B,aAAS,aAAa,MAAM,MAAM;;AAGpC,mBAAiB,KAAc;AAC7B,QAAM,QAAQ,OAAM,IAAI;AACxB,QAAI,OAAO;AACT,aAAO,MAAM;;;AAGjB,aAAW,UAAU;AACrB,aAAW,OAAO,gBAAa;AAC7B,WAAO,QAAQ,aAAa,MAAM,MAAM;;AAG1C,qBAAmB,KAAc;AAC/B,WAAO,OAAM,OAAO;;AAEtB,aAAW,YAAY;AACvB,aAAW,SAAS,kBAAe;AACjC,WAAO,UAAU,aAAa,MAAM,MAAM;;AAG5C,aAAW,eAAe;AAC1B,aAAW,SAAS,UAAU,kBAAe;AAC3C,WAAO,aAAa,MAAM,MAAM,QAAQ,MAAM,MAAM;MAClD;AAEJ,SAAO,OAAO,OAAO;;;;ACxMvB,IAAA,cAAA,WAAA;AAAA,0BAAA;AA+HU,SAAA,iBAAiB,KAAK;;AA1EvB,eAAA,UAAA,QAAP,SAAgB,SAAoC;AAApD,QAAA,QAAA;AACE,QAAM,eACJ,OAAO,QAAQ,eAAe,WAAW,QAAQ,aACjD,QAAQ,eAAe,QAAQ,OAAO;AACxC,QAAI;AACJ,SAAK,mBACH,WAAA;AAAM,aAAA,eAAe,QAAQ,OAAO;OACpC;AAEF,WAAO;;AAeF,eAAA,UAAA,8BAAP,SACE,aACA,cAAoB;AAEpB,SAAK,mBAAmB,aAAa;;AAKhC,eAAA,UAAA,oBAAP,SAAyB,UAAsB;AAC7C,WAAO;;AAGF,eAAA,UAAA,WAAP,SAAgB,QAA+B;AAC7C;;AAGK,eAAA,UAAA,KAAP,WAAA;AACE,WAAO;;AAGF,eAAA,UAAA,SAAP,SAAc,SAA4B;AACxC,WAAO;;AAKF,eAAA,UAAA,mBAAP,SAAwB,UAAsB;AAC5C,WAAO;;AASF,eAAA,UAAA,YAAP,SACE,SACA,YAAiC;AAAjC,QAAA,eAAA,QAAA;AAAA,mBAAA,CAAc,CAAC,QAAQ;;AAEvB,WAAO,KAAK,KAAI,SAAA,SAAA,IACX,UAAO,EACV,QAAQ,QAAQ,MAAM,cACtB;;AAQG,eAAA,UAAA,eAAP,SACE,SACA,YAAiC;AAAjC,QAAA,eAAA,QAAA;AAAA,mBAAA,CAAc,CAAC,QAAQ;;AAEvB,WAAO,KAAK,KAAI,SAAA,SAAA,IACX,UAAO,EACV,OAAO,KAAK,eAAe,QAAQ,UAAU,QAAQ,eACrD,QAAQ,QAAQ,IAChB;;AAIG,eAAA,UAAA,aAAP,SAAiD,KAIJ;AAH3C,QAAA,KAAE,IAAA,IACF,OAAI,IAAA,MACD,UAAO,OAAA,KAHqC,CAAA,MAAA;AAK/C,WAAO,KAAK,MAAM,OAAO,OAAO,SAAS;MACvC,QAAQ,MAAM;MACd,QAAQ;;;AAIL,eAAA,UAAA,gBAAP,SAAoD,KAMJ;AAL9C,QAAA,KAAE,IAAA,IACF,OAAI,IAAA,MACJ,WAAQ,IAAA,UACR,eAAY,IAAA,cACT,UAAO,OAAA,KALwC,CAAA,MAAA,QAAA,YAAA;AAOlD,WAAO,KAAK,MAAM,OAAO,OAAO,SAAS;MACvC,OAAO,KAAK,eAAe,UAAU;MACrC,QAAQ;MACR,QAAQ;;;AAIL,eAAA,UAAA,cAAP,SACE,SACA,QAAmD;AAEnD,WAAO,KAAK,MAAM;MAChB,QAAA,SAAO,QAAK;AACV,YAAM,QAAQ,OAAM,UAA6B;AACjD,YAAM,OAAO,OAAO;AACpB,YAAI,SAAS,UAAU,SAAS;AAAM,iBAAO;AAC7C,eAAM,WAAU,SAAA,SAAA,IAAyB,UAAO,EAAE;AAClD,eAAO;;;;AAKN,eAAA,UAAA,iBAAP,SACE,SACA,QAAmD;AAEnD,WAAO,KAAK,MAAM;MAChB,QAAA,SAAO,QAAK;AACV,YAAM,QAAQ,OAAM,aAAgC;AACpD,YAAM,OAAO,OAAO;AACpB,YAAI,SAAS,UAAU,SAAS;AAAM,iBAAO;AAC7C,eAAM,cAAa,SAAA,SAAA,IAAyB,UAAO,EAAE;AACrD,eAAO;;;;AAIf,SAAA;;;;AC5MM,IAAW;AAAjB,AAAA,UAAiB,QAAK;GAAL,UAAA,UAAK;;;ACoBtB,IAAA,oBAAA,WAAA;AACE,8BACkB,SACA,MACA,OACA,WAA+B;AAH/B,SAAA,UAAA;AACA,SAAA,OAAA;AACA,SAAA,QAAA;AACA,SAAA,YAAA;;AAEpB,SAAA;;;;ACRE,IAAgB,SACd,OAAO,UAAS;AAEd,iCACJ,KACA,SAA0B;MADxB,aAAU,IAAA,YAAE,KAAE,IAAA,IAAE,MAAG,IAAA;AAGrB,MAAI,OAAO,eAAe,UAAU;AAClC,QAAI,SAAS;AACX,cAAQ,YACL,OAAO,SAAS,EAAG,OACpB,QAAQ,SAAS,EAAE,QACnB;;AAGJ,QAAI,OAAO;AAAQ,WAAK;AACxB,QAAI,OAAO,QAAQ;AACjB,aAAO,GAAA,OAAG,YAAU,KAAA,OAClB,OAAO,OAAO,YACd,OAAO,OAAO,WACZ,KAAK,KAAK,UAAU;;;;AAK9B,IAAM,gBAAgB;EACpB,kBAAkB;EAClB,aAAa;EACb,eAAe;EAGf,iBAAiB;;AAGb,yBAA0B,QAA2B;AACzD,SAAO,QAAQ,eAAe;;AAG1B,+BACJ,QAAoD;AAEpD,MAAM,QAAQ,OAAO;AACrB,SAAO,UAAU,SAAS,cAAc,kBAAkB;;AAGtD,oCACJ,OACA,mBAA0C;AAE1C,SAAO,YAAY,qBACf,MAAM,IAAI,kBAAkB,OAAO,gBACnC,qBAAqB,kBAAkB;;AAGtC,IAAM,wBAAwB;AAE/B,gCAAiC,gBAAsB;AAC3D,MAAM,QAAQ,eAAe,MAAM;AACnC,SAAO,QAAQ,MAAM,KAAK;;AAGtB,mCACJ,cACA,QACA,WAA+B;AAE/B,MAAI,gBAAgB,SAAS;AAC3B,WAAO,QAAQ,UACX,OAAO,MAAM,SAAA,MAAI;AAAI,aAAA,0BAA0B,cAAc,MAAM;SACnE,aAAa,WAAW,MAAM,SAAA,OAAK;AACnC,UAAI,QAAQ,UAAU,cAAc,OAAO,YAAY;AACrD,YAAM,MAAM,uBAAuB;AACnC,eAAO,OAAO,KAAK,QAAQ,QACxB,EAAC,MAAM,gBACP,0BAA0B,MAAM,cAAc,OAAO,MAAM;;AAOhE,aAAO;;;AAGb,SAAO;;AAGH,iCACJ,OAAiB;AAEjB,SAAO,gBAAgB,UACrB,CAAC,YAAY,UACb,CAAC,QAAQ;;AAGP,qCAAmC;AACvC,SAAO,IAAI;;AAGN,IAAM,UAAU,SAAC,GAAM;AAAkC,SAAA,MAAM,QAAQ;;;;AC7F9E,IAAM,SAAc,uBAAO,OAAO;AAClC,IAAM,cAA6B,WAAA;AAAM,SAAA;;AACzC,IAAM,aAAkB,uBAAO,OAAO;AAEtC,IAAA,cAAA,WAAA;AAGE,wBACkB,UACA,OAAiB;AAFnC,QAAA,QAAA;AACkB,SAAA,WAAA;AACA,SAAA,QAAA;AAJR,SAAA,OAA8B,uBAAO,OAAO;AAqU9C,SAAA,UAEJ,uBAAO,OAAO;AA0DV,SAAA,OAEJ,uBAAO,OAAO;AA6CX,SAAA,gBAAgB,SACrB,mBACA,gBAAsB;AACnB,aAAA,gBACH,YAAY,qBACR,MAAK,IAAI,kBAAkB,OAAO,kBAClC,qBAAqB,kBAAkB;;AAMtC,SAAA,UAA2B,SAAA,UAAQ;AACxC,aAAO,YAAY,YACf,MAAK,IAAI,SAAS,SAClB,OAAO,aAAa;;AAOnB,SAAA,cAAmC,SACxC,cACA,gBAAc;AAEd,UAAI,OAAO,iBAAiB,UAAU;AACpC,eAAO,cAAc;;AAGvB,UAAI,YAAY,eAAe;AAC7B,eAAO;;AAGF,UAAA,KAAM,MAAK,SAAS,SAAS,cAAa;AAEjD,UAAI,IAAI;AACN,YAAM,MAAM,cAAc;AAC1B,YAAI,gBAAgB;AAClB,gBAAK,MAAM,IAAI;;AAEjB,eAAO;;;;AAvcJ,eAAA,UAAA,WAAP,WAAA;AACE,WAAA,SAAA,IAAY,KAAK;;AAGZ,eAAA,UAAA,MAAP,SAAW,QAAc;AACvB,WAAO,KAAK,OAAO,QAAQ,UAAU;;AAGhC,eAAA,UAAA,MAAP,SAAW,QAAgB,WAAiB;AAC1C,SAAK,MAAM,OAAO,QAAQ;AAC1B,QAAI,OAAO,KAAK,KAAK,MAAM,SAAS;AAClC,UAAM,cAAc,KAAK,KAAK;AAC9B,UAAI,eAAe,OAAO,KAAK,aAAa,YAAY;AACtD,eAAO,YAAY;;;AAGvB,QAAI,cAAc,gBACd,OAAO,KAAK,KAAK,SAAS,mBAAmB,SAAS;AACxD,aAAO,KAAK,SAAS,kBAAkB;;AAEzC,QAAI,gBAAgB,OAAO;AACzB,aAAO,KAAK,OAAO,IAAI,QAAQ;;;AAIzB,eAAA,UAAA,SAAV,SAAiB,QAAgB,mBAA2B;AAM1D,QAAI;AAAmB,WAAK,MAAM,OAAO,QAAQ;AAEjD,QAAI,OAAO,KAAK,KAAK,MAAM,SAAS;AAClC,aAAO,KAAK,KAAK;;AAGnB,QAAI,gBAAgB,OAAO;AACzB,aAAO,KAAK,OAAO,OAAO,QAAQ;;AAGpC,QAAI,KAAK,SAAS,kBAAkB,SAAS;AAC3C,aAAO,uBAAO,OAAO;;;AAIlB,eAAA,UAAA,QAAP,SACE,OACA,OAA2B;AAF7B,QAAA,QAAA;AAIE,QAAI;AAGJ,QAAI,YAAY;AAAQ,cAAQ,MAAM;AACtC,QAAI,YAAY;AAAQ,cAAQ,MAAM;AAEtC,QAAM,WACJ,OAAO,UAAU,WACb,KAAK,OAAO,SAAS,SACrB;AAEN,QAAM,WACJ,OAAO,UAAU,WACb,KAAK,OAAO,SAAS,SACrB;AAIN,QAAI,CAAC;AAAU;AAEf,cACE,UAAO,OAAM,WACb,UAAA,qCACA,UAAA,OAAA,WAAA,UAAA;AAEF,QAAM,SACJ,IAAI,WAAW,uBAAuB,MAAM,UAAU;AAIxD,SAAK,KAAK,UAAU;AAEpB,QAAI,WAAW,UAAU;AACvB,aAAO,KAAK,KAAK;AACjB,UAAI,KAAK,MAAM,SAAS;AACtB,YAAM,kBAAmC,uBAAO,OAAO;AAKvD,YAAI,CAAC;AAAU,0BAAc,WAAW;AAIxC,eAAO,KAAK,UAAU,QAAQ,SAAA,gBAAc;AAC1C,cAAI,CAAC,YAAY,SAAS,oBAAoB,OAAO,iBAAiB;AAGpE,4BAAc,kBAAkB;AAShC,gBAAM,YAAY,uBAAuB;AACzC,gBAAI,cAAc,kBACd,CAAC,MAAK,SAAS,WAAW,OAAO,YAAY,YAAY;AAC3D,8BAAc,aAAa;;AAM7B,gBAAI,OAAO,oBAAoB,UAAU,CAAE,kBAAgB,QAAQ;AACjE,qBAAO,OAAO;;;;AAKpB,YAAI,gBAAc,cACd,CAAE,aAAY,SAAS,eAKvB,KAAK,SAAS,kBAAkB,YAAY,OAAO,YAAY;AACjE,iBAAO,gBAAc;;AAGvB,eAAO,KAAK,iBAAe,QACzB,SAAA,WAAS;AAAI,iBAAA,MAAK,MAAM,MAAM,QAAkB;;;;;AAKjD,eAAA,UAAA,SAAP,SACE,QACA,QAAiC;AAFnC,QAAA,QAAA;AAIE,QAAM,cAAc,KAAK,OAAO;AAEhC,QAAI,aAAa;AACf,UAAM,kBAAqC,uBAAO,OAAO;AACzD,UAAI,gBAAc;AAClB,UAAI,eAAa;AAEjB,UAAM,kBAAgB;QACpB;QACA;QACA;QACA,aAAa,KAAK;QAClB,SAAS,KAAK;QACd,WAAW,SACT,oBACA,OAA8B;AAC3B,iBAAA,MAAK,SAAS,UACjB,OAAO,uBAAuB,WAAW;YACvC,WAAW;YACX,MAAM,SAAQ,cAAc;cAC1B,oBACJ,EAAE,OAAO;;;AAIb,aAAO,KAAK,aAAa,QAAQ,SAAA,gBAAc;AAC7C,YAAM,YAAY,uBAAuB;AACzC,YAAI,aAAa,YAAY;AAC7B,YAAI,eAAe;AAAQ;AAC3B,YAAM,SAA+B,OAAO,WAAW,aACnD,SACA,OAAO,mBAAmB,OAAO;AACrC,YAAI,QAAQ;AACV,cAAI,WAAW,WAAW,cAAc,SACtC,OAAO,gBAAgB,aAAW,SAAA,SAAA,IAC7B,kBAAa,EAChB,WACA,gBACA,SAAS,MAAK,WAAW,QAAQ;AAErC,cAAI,aAAa,YAAY;AAC3B,kBAAK,MAAM,MAAM,QAAQ;iBACpB;AACL,gBAAI,aAAa;AAAQ,yBAAW;AACpC,gBAAI,aAAa,YAAY;AAC3B,8BAAc,kBAAkB;AAChC,8BAAc;AACd,2BAAa;;;;AAInB,YAAI,eAAe,QAAQ;AACzB,yBAAa;;;AAIjB,UAAI,eAAa;AACf,aAAK,MAAM,QAAQ;AAEnB,YAAI,cAAY;AACd,cAAI,gBAAgB,OAAO;AACzB,iBAAK,KAAK,UAAU;iBACf;AACL,mBAAO,KAAK,KAAK;;AAEnB,eAAK,MAAM,MAAM,QAAQ;;AAG3B,eAAO;;;AAIX,WAAO;;AASF,eAAA,UAAA,SAAP,SACE,QACA,WACA,MAA0B;;AAE1B,QAAM,cAAc,KAAK,OAAO;AAChC,QAAI,aAAa;AACf,UAAM,WAAW,KAAK,cAAsB,aAAa;AACzD,UAAM,iBAAiB,aAAa,OAChC,KAAK,SAAS,kBAAkB,EAAE,UAAU,WAAW,UACvD;AACJ,aAAO,KAAK,OAAO,QAAQ,iBAAgB,OAAA,IACzC,IAAC,kBAAiB,oBAChB;;AAEN,WAAO;;AAGF,eAAA,UAAA,QAAP,SACE,SACA,OAAkB;AAElB,QAAI,UAAU;AACd,QAAI,QAAQ,IAAI;AACd,UAAI,OAAO,KAAK,KAAK,MAAM,QAAQ,KAAK;AACtC,kBAAU,KAAK,OAAO,QAAQ,IAAI,QAAQ,WAAW,QAAQ;;AAE/D,UAAI,gBAAgB,SAAS,SAAS,OAAO;AAC3C,kBAAU,KAAK,OAAO,MAAM,SAAS,UAAU;;AAMjD,UAAI,QAAQ,aAAa,SAAS;AAChC,aAAK,MAAM,MAAM,QAAQ,IAAI,QAAQ,aAAa;;;AAGtD,WAAO;;AAGF,eAAA,UAAA,QAAP,WAAA;AACE,SAAK,QAAQ;;AAGR,eAAA,UAAA,UAAP,WAAA;AAAA,QAAA,QAAA;AACE,QAAM,MAAM,KAAK;AACjB,QAAM,eAAyB;AAC/B,SAAK,eAAe,QAAQ,SAAA,IAAE;AAC5B,UAAI,CAAC,OAAO,KAAK,MAAK,SAAS,mBAAmB,KAAK;AACrD,qBAAa,KAAK;;;AAGtB,QAAI,aAAa,QAAQ;AACvB,UAAI,SAAS,EAAE,cAAc,aAAa;;AAE5C,WAAO;;AAGF,eAAA,UAAA,UAAP,SAAe,SAAqC;AAApD,QAAA,QAAA;AACE,WAAO,KAAK,KAAK,MAAM,QAAQ,SAAA,QAAM;AACnC,UAAI,CAAE,YAAW,OAAO,KAAK,SAAS,UAAU;AAC9C,cAAK,OAAO;;;AAGhB,QAAI,SAAS;AACH,UAAA,SAAoB,QAAO,QAAhB,SAAI,OAAK,SAAtB,CAAA;AACN,aAAO,KAAK,QAAM,QAAQ,SAAA,QAAM;AAC9B,cAAK,MAAM,QAAQ,OAAK;;AAE1B,UAAI,QAAQ;AACV,eAAO,aAAa,QAAQ,KAAK,QAAQ;;;;AAiBxC,eAAA,UAAA,SAAP,SAAc,QAAc;AAC1B,WAAO,KAAK,QAAQ,UAAW,MAAK,QAAQ,WAAW,KAAK;;AAGvD,eAAA,UAAA,UAAP,SAAe,QAAc;AAC3B,QAAI,KAAK,QAAQ,UAAU,GAAG;AAC5B,UAAM,QAAQ,EAAE,KAAK,QAAQ;AAC7B,UAAI,CAAC;AAAO,eAAO,KAAK,QAAQ;AAChC,aAAO;;AAET,WAAO;;AAKF,eAAA,UAAA,eAAP,SAAoB,KAAuB;AAAvB,QAAA,QAAA,QAAA;AAAA,YAAA,oBAAU;;AAC5B,WAAO,KAAK,KAAK,SAAS,QAAQ,IAAI,KAAK;AAC3C,QAAI,gBAAgB,OAAO;AACzB,WAAK,OAAO,aAAa;WACpB;AAIL,aAAO,KAAK,KAAK,SAAS,mBAAmB,QAAQ,IAAI,KAAK;;AAEhE,WAAO;;AAOF,eAAA,UAAA,KAAP,WAAA;AAAA,QAAA,QAAA;AACE,QAAM,MAAM,KAAK;AACjB,QAAM,WAAW,KAAK;AACtB,QAAI,QAAQ,SAAA,IAAE;AACZ,UAAI,OAAO,KAAK,UAAU,KAAK;AAI7B,eAAO,KAAK,MAAK,gBAAgB,KAAK,QAAQ,IAAI,KAAK;AAGvD,eAAO,SAAS;;;AAGpB,QAAM,cAAc,OAAO,KAAK;AAChC,QAAI,YAAY,QAAQ;AACtB,UAAI,SAAoB;AACxB,aAAO,kBAAgB;AAAO,iBAAO,OAAK;AAC1C,kBAAY,QAAQ,SAAA,IAAE;AAAI,eAAA,OAAK,OAAO;;;AAExC,WAAO;;AAQF,eAAA,UAAA,kBAAP,SAAuB,QAAc;AACnC,QAAI,CAAC,OAAO,KAAK,KAAK,MAAM,SAAS;AACnC,UAAM,UAAQ,KAAK,KAAK,UAAU,uBAAO,OAAO;AAChD,UAAM,OAAO,KAAK,KAAK;AACvB,UAAI,CAAC;AAAM,eAAO;AAElB,UAAM,YAAU,oBAAI,IAAkC,CAAC;AAGvD,gBAAQ,QAAQ,SAAA,KAAG;AACjB,YAAI,YAAY,MAAM;AACpB,kBAAM,IAAI,SAAS;;AASrB,YAAI,gBAAgB,MAAM;AACxB,iBAAO,KAAK,KAAK,QAAQ,SAAA,KAAG;AAC1B,gBAAM,QAAQ,IAAI;AAGlB,gBAAI,gBAAgB,QAAQ;AAC1B,wBAAQ,IAAI;;;;;;AAMtB,WAAO,KAAK,KAAK;;AAKZ,eAAA,UAAA,eAAP,WAAA;AACE,WAAO,KAAK,MAAM,SAAS,YAAY;;AAiD3C,SAAA;;AAiBA,IAAA,aAAA,WAAA;AAOE,uBACkB,SACR,QAAgC;AAAhC,QAAA,WAAA,QAAA;AAAA,eAAA;;AADQ,SAAA,UAAA;AACR,SAAA,SAAA;AARF,SAAA,IAAiD;AAUvD,SAAK;;AAGA,cAAA,UAAA,eAAP,WAAA;AACE,SAAK,IAAI,KAAK,UAAU,QAAgB;AACxC,SAAK,WAAW,IAAI,KAAK;;AAGpB,cAAA,UAAA,SAAP,SAAc,QAAgB,gBAAsB;AAClD,QAAI,KAAK,GAAG;AACV,WAAK,EAAE,WAAW,QAAQ;AAC1B,UAAM,YAAY,uBAAuB;AACzC,UAAI,cAAc,gBAAgB;AAMhC,aAAK,EAAE,WAAW,QAAQ;;AAE5B,UAAI,KAAK,QAAQ;AACf,aAAK,OAAO,OAAO,QAAQ;;;;AAK1B,cAAA,UAAA,QAAP,SAAa,QAAgB,gBAAsB;AACjD,QAAI,KAAK,GAAG;AACV,WAAK,EAAE,MACL,WAAW,QAAQ,iBAQnB,mBAAmB,aAAa,WAAW;;;AAInD,SAAA;;AAEA,oBAAoB,QAAgB,gBAAsB;AAIxD,SAAO,iBAAiB,MAAM;;AAG1B,wCACJ,OACA,UAAgB;AAEhB,MAAI,sBAAsB,QAAQ;AAShC,UAAM,MAAM,OAAO,UAAU;;;AAIjC,AAAA,UAAiB,cAAW;AAE1B,MAAA,OAAA,SAAA,QAAA;AAA0B,cAAA,OAAA;AACxB,mBAAY,KAQX;UAPC,WAAQ,IAAA,UACR,KAAA,IAAA,eAAA,gBAAa,OAAA,SAAG,OAAI,IACpB,OAAI,IAAA;AAHN,UAAA,QASE,OAAA,KAAA,MAAM,UAAU,IAAI,WAAW,mBAAe;AAIhC,YAAA,QAAQ,IAAI,MAAM;AAiBlB,YAAA,cAAc,IAAI,KAAkB;AApBlD,UAAI;AAAM,cAAK,QAAQ;;;AAKlB,UAAA,UAAA,WAAP,SACE,SACA,QAAmC;AAKnC,aAAO,KAAK,MAAM,SAAS,SAAS;;AAG/B,UAAA,UAAA,cAAP,WAAA;AAEE,aAAO;;AAIF,UAAA,UAAA,aAAP,WAAA;AACE,aAAO,KAAK,YAAY,YAAY;;AAExC,WAAA;IAnC0B;AAAb,eAAA,OAAI;GAFF,eAAA,eAAW;AA0C5B,IAAA,QAAA,SAAA,QAAA;AAAoB,YAAA,QAAA;AAClB,kBACkB,IACA,QACA,QACA,OAAiB;AAJnC,QAAA,QAME,OAAA,KAAA,MAAM,OAAO,UAAU,UAAM;AALb,UAAA,KAAA;AACA,UAAA,SAAA;AACA,UAAA,SAAA;AACA,UAAA,QAAA;AAGhB,WAAO;;;AAGF,SAAA,UAAA,WAAP,SACE,SACA,QAAmC;AAEnC,WAAO,IAAI,OAAM,SAAS,MAAM,QAAQ,KAAK;;AAGxC,SAAA,UAAA,cAAP,SAAmB,SAAe;AAAlC,QAAA,QAAA;AAEE,QAAM,SAAS,KAAK,OAAO,YAAY;AAEvC,QAAI,YAAY,KAAK,IAAI;AACvB,UAAI,KAAK,MAAM,SAAS;AAKtB,eAAO,KAAK,KAAK,MAAM,QAAQ,SAAA,QAAM;AACnC,cAAM,iBAAiB,MAAK,KAAK;AACjC,cAAM,oBAAoB,OAAO,UAAU;AAC3C,cAAI,CAAC,mBAAmB;AAMtB,kBAAK,OAAO;qBACH,CAAC,gBAAgB;AAK1B,kBAAK,MAAM,MAAM,QAAQ;AACzB,mBAAO,KAAK,mBAAmB,QAAQ,SAAA,gBAAc;AACnD,oBAAK,MAAM,MAAM,QAAQ;;qBAElB,mBAAmB,mBAAmB;AAI/C,mBAAO,KAAK,gBAAgB,QAAQ,SAAA,gBAAc;AAChD,kBAAI,CAAC,MAAM,eAAe,iBACf,kBAAkB,kBAAkB;AAC7C,sBAAK,MAAM,MAAM,QAAQ;;;;;;AAOnC,aAAO;;AAIT,QAAI,WAAW,KAAK;AAAQ,aAAO;AAGnC,WAAO,OAAO,SAAS,KAAK,IAAI,KAAK;;AAGhC,SAAA,UAAA,WAAP,WAAA;AACE,WAAA,SAAA,SAAA,IACK,KAAK,OAAO,aACZ,KAAK;;AAIL,SAAA,UAAA,kBAAP,SAAuB,QAAc;AACnC,QAAM,aAAa,KAAK,OAAO,gBAAgB;AAC/C,WAAO,OAAO,KAAK,KAAK,MAAM,UAAS,SAAA,SAAA,IAClC,aACA,OAAA,UAAM,gBAAe,KAAA,MAAC,WACvB;;AAGC,SAAA,UAAA,aAAP,WAAA;AACE,QAAI,IAAiB,KAAK;AAC1B,WAAQ,EAAY;AAAQ,UAAK,EAAY;AAC7C,WAAO,EAAE,WAAW,MAAM,GAAG;;AAEjC,SAAA;EA3FoB;AAiGpB,IAAA,QAAA,SAAA,QAAA;AAAoB,YAAA,QAAA;AAClB,kBAAY,MAAsB;WAChC,OAAA,KAAA,MACE,qBACA,MACA,WAAA;OACA,IAAI,WAAW,KAAK,MAAM,SAAS,KAAK,WACzC;;AAGI,SAAA,UAAA,cAAP,WAAA;AAEE,WAAO;;AAGF,SAAA,UAAA,QAAP,WAAA;AAME,WAAO,KAAK,OAAO,MAAM,MAAM,KAAK,QAAQ;;AAEhD,SAAA;EAvBoB;AAyBpB,+BACE,gBACA,gBACA,UAAgB;AAEhB,MAAM,gBAAgB,eAAe;AACrC,MAAM,gBAAgB,eAAe;AAMrC,SAAO,MAAM,eAAe,iBAAiB,gBAAgB;;AAGzD,+BAAgC,OAAU;AAE9C,SAAO,CAAC,CAAE,kBAAiB,eAAe,MAAM,MAAM;;;;ACxwBxD,qBAAwB,OAAQ;AAC9B,MAAI,gBAAgB,QAAQ;AAC1B,WAAO,QAAQ,SACX,MAAM,MAAM,KACb,SAAA,EAAG,WAAW,OAAO,eAAe,UAAW;;AAEpD,SAAO;;AA0DT,IAAA,cAAA,WAAA;AAAA,0BAAA;AAGU,SAAA,QAAQ,IAAK,iBAAgB,UAAU;AAGvC,SAAA,OAAO,IAAI,KAIhB;AAQK,SAAA,SAAS,oBAAI;AAiGb,SAAA,aAAa,oBAAI;AAGT,SAAA,QAAQ,KAAK,MAAM;;AA1G5B,eAAA,UAAA,UAAP,SAAe,OAAU;AACvB,WAAO,gBAAgB,UAAU,KAAK,MAAM,IAAI;;AAO3C,eAAA,UAAA,OAAP,SAAY,OAAU;AACpB,QAAI,gBAAgB,QAAQ;AAC1B,UAAM,OAAO,YAAY;AACzB,WAAK,OAAO,IAAI,MAAM;AACtB,aAAO;;AAET,WAAO;;AAKF,eAAA,UAAA,QAAP,SAAa,OAAU;AAAvB,QAAA,QAAA;AACE,QAAI,gBAAgB,QAAQ;AAC1B,UAAM,WAAW,KAAK,OAAO,IAAI;AACjC,UAAI;AAAU,eAAO;AAErB,UAAM,QAAQ,OAAO,eAAe;AACpC,cAAQ;aACD,MAAM,WAAW;AACpB,cAAI,KAAK,MAAM,IAAI;AAAQ,mBAAO;AAClC,cAAM,QAAgB,MAAgB,IAAI,KAAK,OAAO;AAItD,cAAM,OAAO,KAAK,KAAK,YAAY;AACnC,cAAI,CAAC,KAAK,OAAO;AACf,iBAAK,MAAM,IAAI,KAAK,QAAQ;AAI5B,gBAAI,SAAS;AACX,qBAAO,OAAO;;;AAGlB,iBAAO,KAAK;;aAGT;aACA,OAAO,WAAW;AACrB,cAAI,KAAK,MAAM,IAAI;AAAQ,mBAAO;AAClC,cAAM,UAAQ,OAAO,eAAe;AACpC,cAAM,UAAQ,CAAC;AACf,cAAM,OAAO,KAAK,WAAW;AAC7B,kBAAM,KAAK,KAAK;AAChB,cAAM,oBAAkB,QAAM;AAC9B,eAAK,OAAO,QAAQ,SAAA,KAAG;AACrB,oBAAM,KAAK,MAAK,MAAO,MAAc;;AAUvC,cAAM,OAAO,KAAK,KAAK,YAAY;AACnC,cAAI,CAAC,KAAK,QAAQ;AAChB,gBAAM,QAAM,KAAK,SAAS,OAAO,OAAO;AACxC,iBAAK,MAAM,IAAI;AACf,iBAAK,OAAO,QAAQ,SAAC,KAAK,GAAC;AACzB,oBAAI,OAAO,QAAM,oBAAkB;;AAKrC,gBAAI,SAAS;AACX,qBAAO,OAAO;;;AAGlB,iBAAO,KAAK;;;;AAIlB,WAAO;;AAOD,eAAA,UAAA,aAAR,SAAmB,KAAW;AAC5B,QAAM,OAAO,OAAO,KAAK;AACzB,QAAM,OAAO,KAAK,KAAK,YAAY;AACnC,QAAI,CAAC,KAAK,MAAM;AACd,WAAK;AACL,UAAM,OAAO,KAAK,UAAU;AAC5B,UAAI,CAAE,MAAK,OAAO,KAAK,WAAW,IAAI,QAAQ;AAC5C,aAAK,WAAW,IAAI,MAAM,KAAK,OAAO,EAAE,QAAQ,MAAM;;;AAG1D,WAAO,KAAK;;AAQhB,SAAA;;AAUO,IAAM,qBAAqB,OAAO,OAAO,SAAU,OAAU;AAClE,MAAI,gBAAgB,QAAQ;AAC1B,QAAI,mBAAmB,QAAQ;AAC7B;;AAEF,QAAM,YAAY,eAAe,MAAM;AACvC,QAAI,OAAO,eAAe,IAAI;AAC9B,QAAI,SAAS,QAAQ;AACnB,qBAAe,IACb,WACA,OAAO,KAAK,UAAU;;AAG1B,WAAO;;AAET,SAAO,KAAK,UAAU;GACrB;EACD,OAAO;;AAIT,IAAI;AACJ,IAAI;AAEJ,mCAAgC;AAC9B,mBAAiB,IAAI;AACrB,mBAAiB,IAAK,iBAAgB,UAAU;;;;AC3IlD,iCACE,SAAgC;AAEhC,SAAO;IACL,QAAQ;IACR,QAAQ;IACR,QAAQ;IAGR,QAAQ,QAAQ;;;AAIpB,IAAA,cAAA,WAAA;AA8BE,wBAAY,QAAyB;AAArC,QAAA,QAAA;AATQ,SAAA,eAAe,IACrB,iBAAgB,UAAU;AAS1B,SAAK,SAAS,QAAQ,QAAQ;MAC5B,aAAa,OAAO,gBAAgB;MACpC,iBAAiB,sBAAsB;;AAGzC,SAAK,QAAQ,OAAO,SAAS,IAAI;AAEjC,SAAK,sBAAsB,KAAK,SAAA,SAAO;;AAC7B,UAAA,kBAAoB,QAAQ,QAAO;AAE3C,UAAM,WAAW,wBAAwB;AAIzC,eAAS,KAAK,CAAC;AAEf,UAAM,QAAQ,OAAA,MAAK,qBAAoB,KAAI,MAAA,KAAI;AAE/C,UAAI,OAAO;AACT,YAAI,iBAAiB;AACnB,iBAAA,SAAA,SAAA,IACK,QAAK,EAGR,QAAQ,MAAK,MAAM,MAAM,MAAM;;AAKnC,eAAO;;AAGT,qCACE,QAAQ,QAAQ,OAChB,QAAQ,aAAa;AAKvB,aAAO,MAAK,qBAAqB;OAEhC;MACD,KAAK,KAAK,OAAO;MACjB,SAAS;MAGT,cAAY,SAAC,cAAc,QAAQ,SAAS,iBAAe;AACzD,YAAI,sBAAsB,QAAQ,QAAQ;AACxC,iBAAO,QAAQ,MAAM,aACnB,cACA,YAAY,UAAU,OAAO,QAAQ,QACrC,QAAQ,WACR;;;;AAMR,SAAK,0BAA0B,KAAK,SAAC,SAAoC;AACvE,qCACE,QAAQ,QAAQ,OAChB,QAAQ,aAAa;AAEvB,aAAO,MAAK,yBAAyB;OACpC;MACD,KAAK,KAAK,OAAO;MACjB,cAAY,SAAC,KAAyB;YAAvB,QAAK,IAAA,OAAE,QAAK,IAAA,OAAE,UAAO,IAAA;AAClC,YAAI,sBAAsB,QAAQ,QAAQ;AACxC,iBAAO,QAAQ,MAAM,aACnB,OACA,OACA,QAAQ;;;;;AA5EX,eAAA,UAAA,aAAP,WAAA;AACE,SAAK,QAAQ,IAAI;;AAyFZ,eAAA,UAAA,wBAAP,SAAgC,KAOD;QAN7B,QAAK,IAAA,OACL,QAAK,IAAA,OACL,KAAA,IAAA,QAAA,SAAM,OAAA,SAAG,eAAY,IACrB,YAAS,IAAA,WACT,KAAA,IAAA,mBAAA,oBAAiB,OAAA,SAAG,OAAI,IACxB,KAAA,IAAA,iBAAA,kBAAe,OAAA,SAAG,KAAK,OAAO,kBAAe;AAE7C,QAAM,WAAW,KAAK,OAAO,MAAM;AAEnC,gBAAS,SAAA,SAAA,IACJ,iBAAiB,mBAAmB,UACpC;AAGL,QAAM,UAAU,cAAc;AAC9B,QAAM,SAAS,IAAI;AACnB,QAAM,aAAa,KAAK,oBAAoB;MAC1C,cAAc,kBAAkB,OAAO;MACvC,mBAAmB;MACnB,cAAc;MACd,SAAS;QACP;QACA;QACA;QACA;QACA,WAAW,mBAAmB;QAC9B;QACA,aAAa,kBAAkB,uBAAuB;QACtD,OAAK,SAAC,GAAG,GAAC;AAOR,iBAAO,OAAO,MAAM,GAAG;;;;AAK7B,QAAI;AACJ,QAAI,WAAW,SAAS;AAKtB,gBAAU,CAAC,IAAI,kBACb,aAAa,WAAW,UACxB,WAAW,SACX,OACA;AAEF,UAAI,CAAC,mBAAmB;AACtB,cAAM,QAAQ;;;AAIlB,WAAO;MACL,QAAQ,WAAW;MACnB,UAAU,CAAC;MACX;;;AAIG,eAAA,UAAA,UAAP,SACE,QACA,QACA,cACA,SAA+B;AAE/B,QAAI,sBAAsB,QAAQ,UAC9B,KAAK,aAAa,IAAI,YAAY,cAAc;AAClD,UAAM,SAAS,KAAK,oBAAoB,KACtC,cACA,QACA,SAIA,KAAK,MAAM,QAAQ;AAErB,UAAI,UAAU,WAAW,OAAO,QAAQ;AACtC,eAAO;;;AAGX,WAAO;;AAID,eAAA,UAAA,uBAAR,SAA6B,KAKH;AAL1B,QAAA,QAAA;QACE,eAAY,IAAA,cACZ,oBAAiB,IAAA,mBACjB,eAAY,IAAA,cACZ,UAAO,IAAA;AAEP,QAAI,YAAY,sBACZ,CAAC,QAAQ,SAAS,kBAAkB,kBAAkB,UACtD,CAAC,QAAQ,MAAM,IAAI,kBAAkB,QAAQ;AAC/C,aAAO;QACL,QAAQ,KAAK,MAAM;QACnB,SAAS,iCAAA,OAAiC,kBAAkB,OAAK;;;AAI7D,QAAA,YAA+B,QAAO,WAA3B,WAAoB,QAAO,UAAjB,QAAU,QAAO;AAC9C,QAAM,WAAW,MAAM,cAAsB,mBAAmB;AAEhE,QAAI,SAAc;AAClB,QAAI;AAEJ,QAAI,KAAK,OAAO,eACZ,OAAO,aAAa,YACpB,CAAC,SAAS,kBAAkB,WAAW;AAIzC,eAAS,EAAE,YAAY;;AAGzB,2BAA0B,SAAuB,YAAkB;;AACjE,UAAI,QAAO,SAAS;AAClB,kBAAU,QAAQ,MAAM,SAAO,OAAA,IAAI,IAAC,cAAa,QAAO,SAAO;;AAEjE,aAAO,QAAO;;AAGhB,QAAM,UAAU,IAAI,IAAI,aAAa;AAErC,YAAQ,QAAQ,SAAA,WAAS;;AAGvB,UAAI,CAAC,cAAc,WAAW;AAAY;AAE1C,UAAI,QAAQ,YAAY;AACtB,YAAI,aAAa,SAAS,UAAU;UAClC,WAAW,UAAU,KAAK;UAC1B,OAAO;UACP,WAAW,QAAQ;UACnB,MAAM;WACL;AAEH,YAAM,aAAa,uBAAuB;AAE1C,YAAI,eAAe,QAAQ;AACzB,cAAI,CAAC,sBAAsB,MAAM,YAAY;AAC3C,sBAAU,QAAQ,MAAM,SAAO,OAAA,IAC7B,IAAC,cAAa,qBAAA,OACZ,UAAU,KAAK,OAAK,SAAA,OAEpB,YAAY,qBACR,kBAAkB,QAAQ,YAC1B,YAAY,KAAK,UAAU,mBAAmB,MAAM;;mBAKrD,QAAQ,aAAa;AAC9B,uBAAa,cAAc,MAAK,wBAAwB;YACtD,OAAO;YACP,OAAO;YACP;YACA;cACE;mBAEK,CAAC,UAAU,cAAc;AAKlC,cAAI,QAAQ,iBAAiB;AAC3B,yBAAa,MAAK,MAAM,KAAK;;mBAGtB,cAAc,MAAM;AAI7B,uBAAa,cAAc,MAAK,oBAAoB;YAClD,cAAc,UAAU;YACxB,mBAAmB;YACnB,cAAc,YAAY,cAAc,aAAa;YACrD;cACE;;AAGN,YAAI,eAAe,QAAQ;AACzB,mBAAS,QAAQ,MAAM,QAAM,MAAA,IAAI,GAAC,cAAa,YAAU;;aAGtD;AACL,YAAM,WAAW,yBACf,WACA,QAAQ;AAGV,YAAI,YAAY,SAAS,gBAAgB,UAAU,WAAW;AAC5D,mBAAS,aAAa,WAAW,QAAQ,QAAQ,KAAK;;;;AAK5D,QAAM,cAA0B,EAAE,QAAQ;AAC1C,QAAM,SAAS,QAAQ,kBACnB,KAAK,MAAM,MAAM,eAGjB,gBAAgB;AAIpB,QAAI,OAAO,QAAQ;AACjB,WAAK,aAAa,IAAI,OAAO,QAAQ;;AAGvC,WAAO;;AAID,eAAA,UAAA,2BAAR,SAAiC,KAKH;AAL9B,QAAA,QAAA;QACE,QAAK,IAAA,OACL,QAAK,IAAA,OACL,eAAY,IAAA,cACZ,UAAO,IAAA;AAEP,QAAI;AAEJ,2BAA0B,aAA4B,GAAS;;AAC7D,UAAI,YAAY,SAAS;AACvB,kBAAU,QAAQ,MAAM,SAAO,OAAA,IAAI,IAAC,KAAI,YAAY,SAAO;;AAE7D,aAAO,YAAY;;AAGrB,QAAI,MAAM,cAAc;AACtB,cAAQ,MAAM,OAAO,QAAQ,MAAM;;AAGrC,YAAQ,MAAM,IAAI,SAAC,MAAM,GAAC;AAExB,UAAI,SAAS,MAAM;AACjB,eAAO;;AAIT,UAAI,QAAQ,OAAO;AACjB,eAAO,cAAc,MAAK,wBAAwB;UAChD;UACA,OAAO;UACP;UACA;YACE;;AAIN,UAAI,MAAM,cAAc;AACtB,eAAO,cAAc,MAAK,oBAAoB;UAC5C,cAAc,MAAM;UACpB,mBAAmB;UACnB,cAAc,YAAY,QAAQ,OAAO;UACzC;YACE;;AAGN,UAAI,SAAS;AACX,qCAA6B,QAAQ,OAAO,OAAO;;AAGrD,aAAO;;AAGT,WAAO;MACL,QAAQ,QAAQ,kBAAkB,KAAK,MAAM,MAAM,SAAS;MAC5D;;;AAGN,SAAA;;AAEA,sBAAsB,MAAiB;AACrC,MAAI;AACF,SAAK,UAAU,MAAM,SAAC,GAAG,OAAK;AAC5B,UAAI,OAAO,UAAU;AAAU,cAAM;AACrC,aAAO;;WAEF,QAAP;AACA,WAAO;;;AAIX,sCACE,OACA,OACA,YAAe;AAEf,MAAI,CAAC,MAAM,cAAc;AACvB,QAAM,YAAU,oBAAI,IAAI,CAAC;AACzB,cAAQ,QAAQ,SAAA,OAAK;AACnB,UAAI,gBAAgB,QAAQ;AAC1B,kBACE,UAAC,CAAA,YACD,QAAA,4CACE,OAAA,2BAAkC,OAAM,QAAA,8BACb,OAAU,MAAM,KAC7C,UAAA,UAAA,CAAA,YAAA,QAAA;AACF,eAAO,OAAO,OAAO,QAAQ,UAAQ,KAAK;;;;;;;AC3f3C,IAAM,YAAY,IAAI;AAE7B,IAAM,eAAe,oBAAI;AAKzB,sBAAsB,QAAuB;AAC3C,MAAI,OAAO,aAAa,IAAI;AAC5B,MAAI,CAAC,MAAM;AACT,iBAAa,IAAI,QAAO,OAAO;MAC7B,MAAM,oBAAI;MACV,KAAK;;;AAGT,SAAO;;AAGH,qBAAsB,QAAuB;AACjD,eAAa,QAAO,KAAK,QAAQ,SAAA,IAAE;AAAI,WAAA,GAAG,YAAY;;;AAWlD,qBAAsB,QAAuB;AACjD,eAAa,QAAO,KAAK,QAAQ,SAAA,IAAE;AAAI,WAAA,GAAG,YAAY;;;AAGlD,iBAAqB,OAAQ;AACjC,MAAM,UAAS,oBAAI;AACnB,MAAM,YAAY,oBAAI;AAEtB,MAAM,KAAqB,SAAU,UAAQ;AAC3C,QAAI,UAAU,SAAS,GAAG;AACxB,UAAI,UAAU,UAAU;AACtB,gBAAQ;AACR,gBAAO,QAAQ,SAAA,QAAK;AAIlB,uBAAa,QAAO,IAAI,MAAM;AAG9B,oBAAU;;AAGZ,YAAM,eAAe,MAAM,KAAK;AAChC,kBAAU;AACV,qBAAa,QAAQ,SAAA,UAAQ;AAAI,iBAAA,SAAS;;;WAEvC;AAIL,UAAM,SAAQ,UAAU;AACxB,UAAI,QAAO;AACT,eAAO;AACP,qBAAa,QAAO,IAAI;;;AAI5B,WAAO;;AAGT,KAAG,eAAe,SAAA,UAAQ;AACxB,cAAU,IAAI;AACd,WAAO,WAAA;AACL,gBAAU,OAAO;;;AAIrB,MAAM,SAAS,GAAG,cAAc,SAAA,QAAK;AACnC,YAAO,IAAI;AACX,iBAAa,QAAO,KAAK,IAAI;AAC7B,WAAO;;AAGT,KAAG,cAAc,SAAA,QAAK;AAAI,WAAA,QAAO,OAAO;;AAExC,SAAO;;AAST,mBAAmB,QAAoB;AACrC,MAAI,OAAM,kBAAkB;AAC1B,WAAM;;;;;AC/FV,IAAM,qBAID,uBAAO,OAAO;AAEnB,6BAA6B,MAAkB;AAI7C,MAAM,WAAW,KAAK,UAAU;AAChC,SAAO,mBAAmB,aACvB,oBAAmB,YAAY,uBAAO,OAAO;;AAG5C,kCACJ,WAAuB;AAEvB,MAAM,OAAO,oBAAoB;AAEjC,SAAO,KAAK,eAAgB,MAAK,cAAc,SAC7C,QACA,SAAO;AAEP,QAAM,UACJ,SAAC,OAAM,KAAG;AAAK,aAAA,QAAQ,UAAU,KAAK;;AAExC,QAAM,YAAY,QAAQ,YAAY,sBACpC,WACA,SAAA,eAAa;AACX,UAAI,YAAY,eACd,QAAQ,aACR,eAIA;AAGF,UACE,cAAc,UACd,WAAW,QAAQ,eACnB,OAAO,KAAK,QAAQ,cAAc,KAClC;AAUA,oBAAY,eAAe,QAAQ,eAAe;;AAGpD,gBACE,UAAS,cACT,QAAA,kBAAkB,OAAA,cAAuB,KAAA,MAAA,sCACvC,OAAK,KAAU,UAEjB,YAAA,UAAA,cAAA,QAAA;AAEF,aAAO;;AAIX,WAAO,GAAA,OAAG,QAAQ,UAAQ,KAAA,OAAI,KAAK,UAAU;;;AAW3C,gCAAiC,WAAuB;AAC5D,MAAM,OAAO,oBAAoB;AAEjC,SAAO,KAAK,aAAc,MAAK,YAAY,SAAC,MAAM,KAIjD;QAHC,QAAK,IAAA,OACL,YAAS,IAAA,WACT,YAAS,IAAA;AAET,QAAM,YAAY,sBAAsB,WAAW,SAAA,SAAO;AACxD,UAAM,WAAW,QAAQ;AACzB,UAAM,YAAY,SAAS,OAAO;AAElC,UAAI,cAAc,KAAK;AACrB,YAAI,SAAS,gBAAgB,MAAM,aAAa;AAC9C,cAAM,kBAAgB,SAAS,MAAM;AAIrC,cAAM,IAAI,MAAM,WAAW,KAAK,SAAA,IAAC;AAAI,mBAAA,GAAE,KAAK,UAAU;;AAEtD,cAAM,gBAAgB,KAAK,yBAAyB,GAAG;AAQvD,iBAAO,iBAAiB,eACtB,eAIA,QAAQ,MAAM;;AAMlB;;AAGF,UAAI,cAAc,KAAK;AACrB,YAAM,eAAe,SAAS,MAAM;AACpC,YAAI,aAAa,OAAO,KAAK,WAAW,eAAe;AACrD,cAAM,aAAa,QAAQ,MAAM;AACjC,qBAAW,KAAK;AAChB,iBAAO,eAAe,WAAW;;AAKnC;;AAGF,UAAI,MAAM;AACR,eAAO,eAAe,MAAM;;;AAIhC,QAAM,SAAS,KAAK,UAAU;AAO9B,QAAI,QAAQ,WAAW,MAAM;AAC3B,mBAAa,MAAM;;AAGrB,WAAO;;;AAIL,+BACJ,WACA,WAAkC;AAIlC,MAAM,SAAS,IAAI;AACnB,SAAO,kBAAkB,WAAW,OAAO,SAAC,WAAW,MAAI;;AACzD,QAAI,UAAU,UAAU;AACxB,QAAI,YAAY,QAAQ;AAGtB,eAAS,IAAI,KAAK,SAAS,GAAG,KAAK,GAAG,EAAE,GAAG;AACzC,kBAAO,OAAA,IAAK,IAAC,KAAK,MAAK,SAAO;;AAEhC,kBAAY,OAAO,MAAM,WAAW;;AAEtC,WAAO;KACN,uBAAO,OAAO;;AAGb,2BAA4B,MAAkB;AAClD,MAAM,OAAO,oBAAoB;AAEjC,MAAI,CAAC,KAAK,OAAO;AACf,QAAM,UAAoB,KAAK,QAAQ;AACvC,QAAM,gBAAwB;AAE9B,SAAK,QAAQ,SAAC,GAAG,GAAC;AAChB,UAAI,QAAQ,IAAI;AACd,0BAAkB,GAAG,QAAQ,SAAA,GAAC;AAAI,iBAAA,QAAM,KAAK,cAAY,OAAO;;AAChE,sBAAY,SAAS;aAChB;AACL,sBAAY,KAAK;AACjB,YAAI,CAAC,QAAQ,KAAK,IAAI,KAAK;AACzB,kBAAM,KAAK,cAAY,MAAM;AAC7B,wBAAY,SAAS;;;;;AAM7B,SAAO,KAAK;;AAGd,oBAGE,QAAc,KAAS;AACvB,SAAO,OAAO;;AAGV,wBACJ,QACA,MACA,SAA2B;AAa3B,YAAU,WAAW;AACrB,SAAO,UAAU,KAAK,OAAO,iBAAiB,KAAK,KAAG;AACpD,WAAO,QAAQ,OACX,IAAI,IAAI,SAAA,OAAK;AAAI,aAAA,QAAQ,OAAO;SAChC,OAAO,QAAS,KAAK;KACxB;;AAGL,mBAAsB,OAAQ;AAI5B,MAAI,gBAAgB,QAAQ;AAC1B,QAAI,QAAQ,QAAQ;AAClB,aAAO,MAAM,IAAI;;AAEnB,WAAO,sBACL,OAAO,KAAK,OAAO,QACnB,SAAA,MAAI;AAAI,aAAA,eAAe,OAAO;;;AAGlC,SAAO;;;;AC7MT,gBAAgB,aAAa;AAoH7B,gCAAgC,MAAoB;AAClD,SAAO,KAAK,SAAS,SAAS,KAAK,OACjC,KAAK,QAAQ,yBAAyB,KAAK,OAAO,KAAK,aAAa;;AA8FxE,IAAM,kBAAqC,WAAA;AAAM,SAAA;;AACjD,IAAM,kBAAmC,SAAC,OAAO,SAAO;AAAK,SAAA,QAAQ;;AAIrE,IAAM,cACJ,SAAC,UAAU,UAAU,KAAgB;MAAd,eAAY,IAAA;AAAO,SAAA,aAAa,UAAU;;AACnE,IAAM,eAAwC,SAAC,GAAG,UAAQ;AAAK,SAAA;;AAM/D,IAAA,WAAA,WAAA;AAsCE,qBAAoB,QAKnB;AALmB,SAAA,SAAA;AArCZ,SAAA,eAYJ,uBAAO,OAAO;AAEV,SAAA,YAEJ,uBAAO,OAAO;AAMV,SAAA,eAAe,oBAAI;AAMnB,SAAA,gBAAgB,oBAAI;AAIZ,SAAA,oBAA4C,uBAAO,OAAO;AAC1D,SAAA,oBAA4C,uBAAO,OAAO;AAE1D,SAAA,qBAAqB;AAQnC,SAAK,SAAM,SAAA,EACT,kBAAkB,2BACf;AAGL,SAAK,QAAQ,KAAK,OAAO;AAEzB,SAAK,gBAAgB;AACrB,SAAK,gBAAgB;AACrB,SAAK,gBAAgB;AAErB,QAAI,OAAO,eAAe;AACxB,WAAK,iBAAiB,OAAO;;AAG/B,QAAI,OAAO,cAAc;AACvB,WAAK,gBAAgB,OAAO;;;AAIzB,YAAA,UAAA,WAAP,SACE,QACA,gBAA0C;;AAE1C,QAAM,WAAW;AAEjB,QAAM,WAAW,kBACf,gBAAe,YACf,QAAA,eAAe,iBAAW,QAAA,QAAA,SAAA,SAAA,IAAE,gBACzB,OAAO;AAOZ,QAAI,aAAa,KAAK,kBAAkB,YAAY;AAClD,aAAO,CAAC;;AAIV,QAAM,cAAc,kBAAkB,eAAe,eAAe;AAEpE,QAAM,UAAO,SAAA,SAAA,IACR,iBAAc,EACjB,UACA,aACA,WAAW,kBAAkB,eAAe,aAAa,WAAA;AACvD,UAAM,UAAU,0BAA0B,WAAW;AACrD,aAAO,SAAS,UAAU,SAAS;QACjC,OAAO,SAAS,MAAM;QACtB,WAAW,QAAQ;;;AAKzB,QAAI;AAEJ,QAAM,SAAS,YAAY,KAAK,cAAc;AAC9C,QAAI,QAAQ,UAAU,OAAO,SAAS,KAAK,OAAO;AAClD,WAAO,OAAO;AACZ,UAAM,gBAAgB,MAAM,QAAQ;AACpC,UAAI,QAAQ,gBAAgB;AAC1B,gBAAQ,yBAAyB;aAC5B;AACL,aAAK;AACL;;;AAIJ,SAAK,KAAK,OAAO,MAAM;AACvB,WAAO,QAAQ,YAAY,CAAC,IAAI,QAAQ,aAAa,CAAC;;AAGjD,YAAA,UAAA,kBAAP,SAAuB,cAA0B;AAAjD,QAAA,QAAA;AACE,WAAO,KAAK,cAAc,QAAQ,SAAA,UAAQ;AACxC,UAAM,MAKF,aAAa,WAJf,YAAS,IAAA,WACT,eAAY,IAAA,cACZ,mBAAgB,IAAA,kBACb,WAAQ,OAAA,KAJP,CAAA,aAAA,gBAAA;AAqBN,UAAI;AAAW,cAAK,gBAAgB,SAAS;AAC7C,UAAI;AAAc,cAAK,gBAAgB,YAAY;AACnD,UAAI;AAAkB,cAAK,gBAAgB,gBAAgB;AAE3D,UAAI,OAAO,KAAK,MAAK,WAAW,WAAW;AACzC,cAAK,UAAU,UAAU,KAAK;aACzB;AACL,cAAK,UAAU,YAAY,CAAC;;;;AAK1B,YAAA,UAAA,mBAAR,SAAyB,UAAkB,UAAoB;AAA/D,QAAA,QAAA;AACE,QAAM,WAAW,KAAK,cAAc;AAC5B,QAAA,YAAsB,SAAQ,WAAnB,SAAW,SAAQ;AAEtC,sBACE,WACA,OAAoC;AAEpC,gBAAS,QACP,OAAO,UAAU,aAAa,QAG9B,UAAU,OAAO,cAGjB,UAAU,QAAQ,eAClB,UAAS;;AAKb,aAAS,UAAU,SAAS;AAE5B,aAAS,QAEP,cAAc,QAAQ,kBAGtB,QAAQ,aAAa,yBAAyB,aAE9C,OAAO,cAAc,aAAa,YAElC,SAAS;AAEX,QAAI,QAAQ;AACV,aAAO,KAAK,QAAQ,QAAQ,SAAA,WAAS;AACnC,YAAM,YAAW,MAAK,eAAe,UAAU,WAAW;AAC1D,YAAM,YAAW,OAAO;AAExB,YAAI,OAAO,cAAa,YAAY;AAClC,oBAAS,OAAO;eACX;AACG,cAAA,UAAyB,UAAQ,SAAxB,OAAgB,UAAQ,MAAlB,QAAU,UAAQ;AAEzC,oBAAS,QAGP,YAAY,QAAQ,kBAGpB,QAAQ,WAAW,uBAAuB,WAE1C,OAAO,YAAY,aAAa,UAEhC,UAAS;AAEX,cAAI,OAAO,SAAS,YAAY;AAC9B,sBAAS,OAAO;;AAGlB,mBAAS,WAAU;;AAGrB,YAAI,UAAS,QAAQ,UAAS,OAAO;AAMnC,oBAAS,QAAQ,UAAS,SAAS;;;;;AAMnC,YAAA,UAAA,kBAAR,SACE,OACA,UAAwB;AAAxB,QAAA,aAAA,QAAA;AAAA,iBAAA;;AAEA,QAAM,SAAS,UAAU,MAAM;AAC/B,QAAM,MAAM,KAAK,kBAAkB;AACnC,QAAI,aAAa,KAAK;AACpB,gBAAU,UAAQ,CAAG,OAAK,QAAO,OAAA,sBAAsB,OAAK,OAAA,iCAA8B,UAAA,CAAA,OAAA,QAAA,OAAA;AAG1F,UAAI;AAAK,eAAO,KAAK,kBAAkB;AAEvC,WAAK,kBAAkB,YAAY;AAEnC,WAAK,kBAAkB,UAAU;;;AAI9B,YAAA,UAAA,mBAAP,SAAwB,eAA+B;AAAvD,QAAA,QAAA;AACG,SAAK,qBAAiC;AACvC,WAAO,KAAK,eAAe,QAAQ,SAAA,WAAS;AAI1C,YAAK,gBAAgB,WAAW;AAEhC,oBAAc,WAAW,QAAQ,SAAA,SAAO;AACtC,cAAK,gBAAgB,SAAS,MAAO,IAAI;AACzC,YAAM,QAAQ,QAAQ,MAAM;AAC5B,YAAI,CAAC,SAAS,MAAM,OAAO,SAAS;AAElC,gBAAK,cAAc,IAAI,SAAS,IAAI,OAAO;;;;;AAM3C,YAAA,UAAA,gBAAR,SAAsB,UAAgB;AAAtC,QAAA,QAAA;AACE,QAAI,CAAC,OAAO,KAAK,KAAK,cAAc,WAAW;AAC7C,UAAM,WACJ,KAAK,aAAa,YAAY,uBAAO,OAAO;AAC9C,eAAO,SAAS,uBAAO,OAAO;AAuB9B,UAAM,aAAa,KAAK,aAAa,IAAI;AACzC,UAAI,cAAc,WAAW,MAAM;AACjC,mBAAW,QAAQ,SAAA,WAAS;AAC1B,cAAM,MAAsB,MAAK,cAAc,YAAvC,SAAM,IAAA,QAAK,OAAI,OAAA,KAAjB,CAAA;AACN,iBAAO,OAAO,UAAQ;AACtB,iBAAO,OAAO,SAAO,QAAQ;;;;AAKnC,QAAM,QAAQ,KAAK,UAAU;AAC7B,QAAI,SAAS,MAAM,QAAQ;AAGzB,YAAM,OAAO,GAAG,QAAQ,SAAA,QAAM;AAC5B,cAAK,iBAAiB,UAAU;;;AAIpC,WAAO,KAAK,aAAa;;AAGnB,YAAA,UAAA,iBAAR,SACE,UACA,WACA,iBAAwB;AAMxB,QAAI,UAAU;AACZ,UAAM,gBAAgB,KAAK,cAAc,UAAU;AACnD,aAAO,cAAc,cACnB,mBAAoB,eAAc,aAAa,uBAAO,OAAO;;;AAI3D,YAAA,UAAA,kBAAR,SACE,SACA,iBAAwB;AAExB,QAAI,eAAe,KAAK,aAAa,IAAI;AACzC,QAAI,CAAC,gBAAgB,iBAAiB;AACpC,WAAK,aAAa,IAAI,SAAS,eAAe,oBAAI;;AAEpD,WAAO;;AAGF,YAAA,UAAA,kBAAP,SACE,UACA,UACA,QACA,WAA+B;AAJjC,QAAA,QAAA;AAME,QAAI,CAAC,SAAS;AAAe,aAAO;AAIpC,QAAI,CAAC;AAAU,aAAO;AAEtB,QAAM,YAAY,SAAS,cAAc,KAAK;AAE9C,QAAI,aAAa;AAAW,aAAO;AAEnC,QAAI,KAAK,sBACL,KAAK,aAAa,IAAI,YAAY;AACpC,UAAM,uBAAuB,KAAK,gBAAgB,UAAU;AAC5D,UAAM,cAAY,CAAC;AACnB,UAAM,iBAAe,SAAC,SAAe;AACnC,YAAM,gBAAe,MAAK,gBAAgB,SAAS;AACnD,YAAI,iBACA,cAAa,QACb,YAAU,QAAQ,iBAAgB,GAAG;AACvC,sBAAU,KAAK;;;AAUnB,UAAI,2BAA2B,CAAC,CAAE,WAAU,KAAK,cAAc;AAC/D,UAAI,wBAAwB;AAI5B,eAAS,IAAI,GAAG,IAAI,YAAU,QAAQ,EAAE,GAAG;AACzC,YAAM,eAAe,YAAU;AAE/B,YAAI,aAAa,IAAI,YAAY;AAC/B,cAAI,CAAC,qBAAqB,IAAI,YAAY;AACxC,gBAAI,uBAAuB;AACzB,yBAAU,UAAK,KAAA,qBAAqB,OAAQ,UAAA,kBAAiB,OAAY;;AAM3E,iCAAqB,IAAI;;AAE3B,iBAAO;;AAGT,qBAAa,QAAQ;AAErB,YAAI,4BAGA,MAAM,YAAU,SAAS,KAKzB,0BAA0B,SAAS,cAAc,QAAS,YAAY;AAIxE,qCAA2B;AAC3B,kCAAwB;AAMxB,eAAK,cAAc,QAAQ,SAAC,QAAQ,aAAW;AAC7C,gBAAM,QAAQ,SAAS,MAAM;AAC7B,gBAAI,SAAS,MAAM,OAAO,UAAU;AAClC,6BAAa;;;;;;AAOvB,WAAO;;AAGF,YAAA,UAAA,aAAP,SAAkB,UAA8B,WAAiB;AAC/D,QAAM,SAAS,KAAK,eAAe,UAAU,WAAW;AACxD,WAAO,CAAC,CAAE,WAAU,OAAO;;AAGtB,YAAA,UAAA,oBAAP,SAAyB,WAAyB;AACxC,QAAA,WAAwB,UAAS,UAAvB,YAAc,UAAS;AACzC,QAAM,SAAS,KAAK,eAAe,UAAU,WAAW;AACxD,QAAI;AAEJ,QAAI,QAAQ,UAAU,OAAO;AAC7B,QAAI,SAAS,UAAU;AACrB,UAAM,UAA0C;QAC9C;QACA;QACA,OAAO,UAAU,SAAS;QAC1B,WAAW,UAAU;;AAEvB,UAAM,OAAO,uBAAuB;AACpC,aAAO,OAAO;AACZ,YAAM,oBAAoB,MAAM,MAAM;AACtC,YAAI,QAAQ,oBAAoB;AAC9B,kBAAQ,uBAAuB;eAC1B;AAGL,2BAAiB,qBAAqB;AACtC;;;;AAKN,QAAI,mBAAmB,QAAQ;AAC7B,uBAAiB,UAAU,QACvB,sBAAsB,UAAU,OAAO,UAAU,aACjD,gBAAgB,WAAW,uBAAuB;;AAKxD,QAAI,mBAAmB,OAAO;AAC5B,aAAO;;AAMT,WAAO,cAAc,uBAAuB,kBACxC,iBACA,YAAY,MAAM;;AAGjB,YAAA,UAAA,YAAP,SACE,SACA,SAA+B;AAE/B,QAAM,oBAAoB,QAAQ;AAClC,QAAI,CAAC;AAAmB;AAExB,QAAM,cAAc,QAAQ,SAAS,QAAQ;AAC7C,QAAI,CAAC;AAAa;AAElB,QAAI,QAAQ,aAAa,QAAQ;AAC/B,UAAM,WAAW,QAAQ,MAAM,cAAsB,mBAAmB;AACxE,UAAI;AAAU,gBAAQ,WAAW;;AAGnC,QAAM,iBAAiB,KAAK,kBAAkB;AAC9C,QAAM,YAAY,uBAAuB;AACzC,QAAM,WAAW,QAAQ,MAAM,cAAiB,mBAAmB;AACnE,QAAM,SAAS,KAAK,eAAe,QAAQ,UAAU,WAAW;AAChE,QAAM,OAAO,UAAU,OAAO;AAE9B,QAAI,MAAM;AACR,UAAM,cAAc,yBAClB,MACA,mBACA,SACA,SACA,QAAQ,MAAM,WACZ,YAAY,qBACR,kBAAkB,QAClB,mBACJ;AAKJ,aAAO,UAAU,UACf,KAAK,OACL,MACA,CAAC,UAAU;;AAIf,WAAO;;AAGF,YAAA,UAAA,kBAAP,SACE,UACA,WAAiB;AAEjB,QAAM,SAAS,KAAK,eAAe,UAAU,WAAW;AACxD,WAAO,UAAU,OAAO;;AAGnB,YAAA,UAAA,mBAAP,SACE,gBACA,WACA,eAAiC;AAEjC,QAAI,SAIF,KAAK,eAAe,gBAAgB,WAAW;AACjD,QAAI,QAAQ,UAAU,OAAO;AAC7B,QAAI,CAAC,SAAS,eAAe;AAC3B,eAAS,KAAK,cAAc;AAC5B,cAAQ,UAAU,OAAO;;AAE3B,WAAO;;AAGF,YAAA,UAAA,mBAAP,SACE,UACA,UACA,KACA,SACA,SAAqB;QAFnB,QAAK,IAAA,OAAE,WAAQ,IAAA,UAAE,QAAK,IAAA;AAIxB,QAAI,UAAU,aAAa;AAIzB,aAAO,yBACL,QAAQ,OACR,UACA;;AAGJ,QAAI,UAAU,cAAc;AAE1B,aAAO;;AAOT,QAAI,QAAQ,WAAW;AACrB,iBAAW;;AAGb,WAAO,MAAM,UAAU,UAAU,yBAC/B,MAYA,QACA,EAAE,UACA,WAAW,MAAM,KAAK,OACtB,OACA,WAAW,QAAQ,aACrB,SACA,WAAW,uBAAO,OAAO;;AAG/B,SAAA;;AAEA,kCACE,UACA,mBACA,WACA,SACA,SAAoB;AAEpB,MAAM,iBAAiB,SAAS,kBAAkB;AAClD,MAAM,YAAY,uBAAuB;AACzC,MAAM,YAAY,UAAU,aAAa,QAAQ;AAC3C,MAAA,MAA2B,QAAQ,OAAjC,cAAW,IAAA,aAAE,UAAO,IAAA;AAE5B,SAAO;IACL,MAAM,uBAAuB;IAC7B,OAAO,UAAU,SAAS;IAC1B;IACA;IACA;IACA;IACA;IACA;IACA,OAAO,SAAS;IAChB;IACA,WAAA,WAAA;AACE,aAAO,SAAS,UACd,0BAA0B,WAAW,mBAAmB,UACxD;;IAGJ,cAAc,yBAAyB,QAAQ;;;AAI7C,mCACJ,eACA,mBACA,WAA+C;AAG7C,MAAG,qBAGD,cAAa,IAFZ,QAED,cAAa,IADP,OACN,cAAa;AAEjB,MAAI;AAEJ,MAAI,OAAO,uBAAuB,UAAU;AAC1C,cAAU;MACR,WAAW;MAIX,MAAM,OAAO,IAAI,QAAO;;SAErB;AACL,cAAO,SAAA,IAAQ;AAGf,QAAI,CAAC,OAAO,KAAK,SAAS,SAAS;AACjC,cAAQ,OAAO;;;AAInB,MAAI,WAAW,QAAQ,SAAS,QAAQ;AACtC,eAAU,UAAK,KAAA,uDACb,OAAA,oBAA+B,MAAA,KAAA;;AAInC,MAAI,AAAW,QAAQ,cAAnB,QAA8B;AAChC,YAAQ,YAAY;;AAGtB,SAAO;;AAGT,kCACE,OAAsB;AAEtB,SAAO,sBAAsB,UAAU,UAAQ;AAC7C,QAAI,QAAQ,aAAa,QAAQ,WAAW;AAC1C,YAAM,UAAI,IAAA,eAAe,uCAAqC,IAAA,eAAA;;AAOhE,QAAI,gBAAgB,aAChB,gBAAgB,WAAW;AAC7B,UAAM,QAAQ,MAAM,cAAc,UAAU;AAC5C,UAAM,QAAQ,MAAM,cAAc,UAAU;AAC5C,UAAM,cAAc,SAAS,SAAS,UAAU;AAEhD,UAAI,aAAa;AACf,eAAO;;AAGT,UAAI,YAAY,aACZ,wBAAwB,WAAW;AAIrC,cAAM,MAAM,SAAS,OAAO;AAC5B,eAAO;;AAGT,UAAI,wBAAwB,aACxB,YAAY,WAAW;AAKzB,cAAM,MAAM,UAAU,SAAS;AAC/B,eAAO;;AAGT,UAAI,wBAAwB,aACxB,wBAAwB,WAAW;AACrC,eAAA,SAAA,SAAA,IAAY,WAAa;;;AAI7B,WAAO;;;;;AC16BX,0BACE,SACA,YACA,UAA8B;AAE9B,MAAM,MAAM,GAAA,OAAG,YAAU,OAAG;AAC5B,MAAI,WAAW,QAAQ,QAAQ,IAAI;AACnC,MAAI,CAAC,UAAU;AACb,YAAQ,QAAQ,IAAI,KAAK,WACvB,QAAQ,eAAe,cACvB,QAAQ,aAAa,WACnB,UAAS,SAAA,SAAA,IACR,UAAO,EACV,YACA;;AAGJ,SAAO;;AAWT,IAAA,cAAA,WAAA;AACE,wBACkB,QACR,QAAoB;AADZ,SAAA,QAAA;AACR,SAAA,SAAA;;AAGH,eAAA,UAAA,eAAP,SAAoB,OAAwB,KAMvB;AANrB,QAAA,QAAA;QACE,QAAK,IAAA,OACL,SAAM,IAAA,QACN,SAAM,IAAA,QACN,YAAS,IAAA,WACT,YAAS,IAAA;AAET,QAAM,sBAAsB,uBAAuB;AACnD,QAAM,SAAS;AAEf,gBAAS,SAAA,SAAA,IACJ,iBAAiB,uBACjB;AAGL,QAAM,UAAwB;MAC5B;MACA,SAAS,uBAAO,OAAO;MACvB,OAAA,SAAS,UAAa,UAAW;AAC/B,eAAO,OAAO,MAAM,UAAU;;MAEhC;MACA,WAAW,mBAAmB;MAC9B,aAAa,kBAAkB,uBAAuB;MACtD,WAAW,CAAC,CAAC;MACb,cAAc,oBAAI;MAClB,YAAY;MACZ,UAAU;MACV,SAAS,oBAAI;;AAGf,QAAM,MAAM,KAAK,oBAAoB;MACnC,QAAQ,UAAU,uBAAO,OAAO;MAChC;MACA,cAAc,oBAAoB;MAClC,WAAW,EAAE,KAAK,oBAAI;MACtB;;AAGF,QAAI,CAAC,YAAY,MAAM;AACrB,YAAM,UAAI,IAAA,eAAe,6BAA6B,OAAK,KAAU,UAAW,YAAA,IAAA,eAAA;;AAKlF,YAAQ,aAAa,QAAQ,SAAC,KAA0C,SAAM;UAA9C,cAAW,IAAA,aAAE,YAAS,IAAA,WAAE,eAAY,IAAA;AAClE,UAAM,YAAY,cAAc;AAEhC,UAAI,aAAa,UAAU,IAAI,MAAM;AACnC,YAAM,UAAU,MAAK,YAAY,WAAW,WAAW,aAAa;AACpE,YAAI,YAAY,UAAU;AAIxB;;AAIF,sBAAc;;AAGhB,UAAI,WAAW,CAAC,QAAQ,WAAW;AACjC,YAAM,4BAAgD,uBAAO,OAAO;AACpE,qBAAa,QAAQ,SAAA,OAAK;AACxB,cAAI,MAAM,cAAc;AACtB,sCAAwB,MAAM,KAAK,SAAS;;;AAIhD,YAAM,oBAAkB,SAAC,gBAAsB;AAC7C,iBAAA,0BACE,uBAAuB,qBACnB;;AAER,YAAM,qBAAmB,SAAC,gBAAsB;AAC9C,cAAM,YAAY,aAAa,UAAU,IAAI,IAAI;AACjD,iBAAO,QAAQ,aAAa,UAAU,QAAQ,UAAU,KAAK;;AAG/D,eAAO,KAAK,aAAa,QAAQ,SAAA,gBAAc;AAK7C,cAAI,kBAAgB,mBAChB,CAAC,mBAAiB,iBAAiB;AACrC,8BACE,WACA,aACA,gBACA,QAAQ;;;;AAMhB,YAAM,MAAM,SAAQ;;AAQtB,UAAM,OAAO,IAAI;AAEjB,WAAO;;AAGD,eAAA,UAAA,sBAAR,SAA4B,KAQC;AAR7B,QAAA,QAAA;QACE,SAAM,IAAA,QACN,SAAM,IAAA,QACN,eAAY,IAAA,cACZ,UAAO,IAAA,SAGP,YAAS,IAAA;AAED,QAAA,WAAa,KAAK,MAAK;AAI/B,QAAI,WAAwB,uBAAO,OAAO;AAK1C,QAAM,WACH,UAAU,SAAS,kBAAkB,WACtC,sBAAsB,QAAQ,cAAc,QAAQ,gBACnD,UAAU,QAAQ,MAAM,IAAI,QAAQ;AAEvC,QAAI,AAAa,OAAO,aAApB,UAA8B;AAChC,eAAS,aAAa;;AAWxB,QAAM,YAA+B,WAAA;AACnC,UAAM,UAAU,0BACd,WACA,UACA,QAAQ;AAGV,UAAI,YAAY,QAAQ,OAAO;AAC7B,YAAM,OAAO,QAAQ,aAAa,IAAI,QAAQ,KAAK;AACnD,YAAI,MAAM;AACR,cAAM,WAAS,SAAS,UAAS,SAAA,SAAA,IAC5B,UAAO,EACV,MAAM,KAAK,gBACV;AAEH,cAAI,aAAW,QAAQ;AACrB,mBAAO;;;;AAKb,aAAO,SAAS,UAAU,SAAS;;AAGrC,QAAM,eAAe,oBAAI;AAEzB,SAAK,cACH,cACA,QAIA,SACA,UACA,QAAQ,SAAC,UAAS,OAAK;;AACvB,UAAM,iBAAiB,uBAAuB;AAC9C,UAAM,QAAQ,OAAO;AAErB,mBAAa,IAAI;AAEjB,UAAI,UAAU,QAAQ;AACpB,YAAM,iBAAiB,SAAS,kBAAkB;UAChD;UACA,WAAW,MAAM,KAAK;UACtB;UACA,WAAW,SAAQ;;AAGrB,YAAM,YAAY,kBAAkB,WAAW;AAE/C,YAAI,gBAAgB,MAAK,kBACvB,OACA,OAGA,MAAM,eACF,iBAAiB,UAAS,OAAO,SACjC,UACJ;AAMF,YAAI,gBAAa;AAIjB,YAAI,MAAM,gBACL,aAAY,kBACZ,wBAAwB,iBAAiB;AAC5C,0BAAgB,UAAkB,cAAc;;AAGlD,YAAM,QAAQ,SAAS,iBACrB,UACA,MAAM,KAAK,OACX;AAGF,YAAI,OAAO;AACT,oBAAU,OAAO;YAEf;YACA;YACA;;eAEG;AACL,qCAA2B,WAAW;;AAGxC,mBAAW,SAAQ,MAAM,UAAQ,OAAA,IAC/B,IAAC,kBAAiB;iBAIpB,WACA,CAAC,SAAQ,cACT,CAAC,SAAQ,YACT,CAAC,sBAAsB,MAAM,UAI7B,CAAC,SAAS,gBAAgB,UAAU,MAAM,KAAK,QAC/C;AACA,mBAAU,UAAM,MAAA,kBACd,OAAA,uBAA6B,QAAA,2BAEzB,OAAC,KAAU,UAAQ,QACtB,MAAA,IAAW,UAAS,GAAA;;;AAM3B,QAAI;AACI,UAAA,KAAkB,SAAS,SAAS,QAAQ;QAChD;QACA;QACA,aAAa,QAAQ;QACrB,aAAa;QACb;UALK,KAAE,GAAA,IAAE,YAAS,GAAA;AAUpB,eAAS,UAAU;AAInB,UAAI,WAAW;AAEb,mBAAW,QAAQ,MAAM,UAAU;;aAE9B,GAAP;AAEA,UAAI,CAAC;AAAQ,cAAM;;AAGrB,QAAI,AAAa,OAAO,WAApB,UAA4B;AAC9B,UAAM,UAAU,cAAc;AAO9B,UAAM,OAAO,QAAQ,QAAQ,WAAY,SAAQ,QAAQ,UAAU;AACnE,UAAI,KAAK,QAAQ,iBAAiB;AAAG,eAAO;AAC5C,WAAK,KAAK;AAOV,UAAI,KAAK,UAAU,KAAK,OAAO,QAC7B,QACA,SACA,cACA,UACC;AACD,eAAO;;AAGT,UAAM,aAAW,QAAQ,aAAa,IAAI;AAC1C,UAAI,YAAU;AACZ,mBAAS,cAAc,QAAQ,MAAM,WAAS,aAAa;AAC3D,mBAAS,YAAY,gBAAgB,WAAS,WAAW;AACzD,qBAAa,QAAQ,SAAA,OAAK;AAAI,iBAAA,WAAS,aAAa,IAAI;;aACnD;AACL,gBAAQ,aAAa,IAAI,QAAQ;UAC/B,aAAa;UAIb,WAAW,iBAAiB,aAAa,SAAS;UAClD;;;AAIJ,aAAO;;AAGT,WAAO;;AAGD,eAAA,UAAA,oBAAR,SACE,OACA,OACA,SACA,WAAoB;AAJtB,QAAA,QAAA;AAME,QAAI,CAAC,MAAM,gBAAgB,UAAU,MAAM;AAIzC,aAAO,UAAU,UAAU,SAAS;;AAGtC,QAAI,QAAQ,QAAQ;AAClB,aAAO,MAAM,IAAI,SAAC,MAAM,GAAC;AACvB,YAAM,SAAQ,MAAK,kBACjB,MAAM,OAAO,SAAS,kBAAkB,WAAW;AACrD,mCAA2B,WAAW;AACtC,eAAO;;;AAIX,WAAO,KAAK,oBAAoB;MAC9B,QAAQ;MACR,cAAc,MAAM;MACpB;MACA;;;AAMI,eAAA,UAAA,gBAAR,SAQE,cACA,QACA,SACA,UAA2E;AAA3E,QAAA,aAAA,QAAA;AAAA,iBAAW,sBAAsB,QAAQ,cAAc,QAAQ;;AAE/D,QAAM,WAAW,oBAAI;AACb,QAAA,WAAa,KAAK,MAAK;AAE/B,QAAM,eAAe,IAAI,KAUtB;AAEH,IAAC,kBAEC,eACA,kBAA0B;AAE1B,UAAM,cAAc,aAAa,OAC/B,eAKA,iBAAiB,YACjB,iBAAiB;AAEnB,UAAI,YAAY;AAAS;AACzB,kBAAY,UAAU;AAEtB,oBAAa,WAAW,QAAQ,SAAA,WAAS;AACvC,YAAI,CAAC,cAAc,WAAW,QAAQ;AAAY;AAE5C,YAAA,aAAyB,iBAAgB,YAA7B,WAAa,iBAAgB;AAC/C,YAIE,CAAE,eAAc,aAChB,gBAAgB,UAAU,aAC1B;AACA,oBAAU,WAAW,QAAQ,SAAA,KAAG;AAC9B,gBAAM,OAAO,IAAI,KAAK;AACtB,gBAAI,SAAS;AAAU,2BAAa;AACpC,gBAAI,SAAS,SAAS;AACpB,kBAAM,OAAO,yBAAyB,KAAK,QAAQ;AAKnD,kBAAI,CAAC,QAAS,KAA0B,OAAO,OAAO;AACpD,2BAAW;;;;;AAQnB,YAAI,QAAQ,YAAY;AACtB,cAAM,WAAW,SAAS,IAAI;AAC9B,cAAI,UAAU;AAIZ,yBAAa,cAAc,SAAS;AACpC,uBAAW,YAAY,SAAS;;AAGlC,mBAAS,IACP,WACA,iBAAiB,SAAS,YAAY;eAGnC;AACL,cAAM,WACJ,yBAAyB,WAAW,QAAQ;AAE9C,cAAI,YACA,SAAS,gBACP,UAAU,UAAU,QAAQ,QAAQ,YAAY;AAEpD,oBACE,SAAS,cACT,iBAAiB,SAAS,YAAY;;;;OAK7C,cAAc;AAEjB,WAAO;;AAGD,eAAA,UAAA,cAAR,SACE,WACA,UACA,UACA,SACA,gBAAsD;;AALxD,QAAA,QAAA;AAOE,QAAI,UAAU,IAAI,QAAQ,CAAC,YAAY,WAAW;AAChD,UAAM,MAIJ,CAAC,QAAQ,aAIR,aAAY,aAAa,wBAAwB,aAChD,WAAW;AAKf,UAAM,MAAI;AAMV,UAAI,OAAK,CAAC,gBAAgB;AACxB,yBAAiB,CAAC,YAAY,OAAK,IAAE,QAAQ;;AAQ/C,UAAI;AAEJ,UAAM,aAAW,SACf,OACA,MAAqB;AAErB,eAAO,QAAQ,SACV,OAAO,SAAS,WAAW,MAAK,QAAQ,SACzC,QAAQ,MAAM,cAAc,OAAM,OAAO;;AAG/C,gBAAU,IAAI,QAAQ,SAAC,WAAW,gBAAc;AAC9C,YAAM,OAAO,WAAS,KAAG;AACzB,YAAM,OAAO,WAAS,KAAG;AAEzB,YAAI,AAAW,SAAX;AAAiB;AACrB,YAAI,gBAAgB;AAClB,yBAAe,KAAK;;AAEtB,YAAM,OAAO,MAAK,YAChB,WACA,MACA,MACA,SACA;AAEF,YAAI,SAAS,MAAM;AACjB,4BAAgB,mBAAiB,oBAAI;AACrC,0BAAc,IAAI,gBAAgB;;AAEpC,YAAI,gBAAgB;AAClB,oBAAU,eAAe,UAAU;;;AAIvC,UAAI,iBAAe;AAEjB,mBAAY,QAAQ,OAAK,IAAE,MAAM,KAAI,SAAA,IAAM;AAC3C,wBAAc,QAAQ,SAAC,OAAO,MAAI;AAC/B,mBAAiB,QAAQ;;;;AAKhC,QAAI,UAAU,MAAM;AAClB,aAAO,KAAK,MAAM,SAAS,iBACzB,UACA,UACA,UAAU,MACV,SACA,kBAAkB,OAAA,QAAQ,OAAM,WAAU,MAAA,KAAI;;AAIlD,WAAO;;AAEX,SAAA;;AAEA,IAAM,qBAAkC;AAExC,2BACE,KACA,MAAqB;MADnB,MAAG,IAAA;AAGL,MAAI,CAAC,IAAI,IAAI,OAAO;AAClB,QAAI,IAAI,MAAM,mBAAmB,SAAS,EAAE,KAAK,oBAAI;;AAEvD,SAAO,IAAI,IAAI;;AAGjB,yBACE,MACA,OAA4B;AAE5B,MAAI,SAAS,SAAS,CAAC,SAAS,iBAAiB;AAAQ,WAAO;AAChE,MAAI,CAAC,QAAQ,iBAAiB;AAAO,WAAO;AAE5C,MAAM,OAAO,KAAK,QAAQ,MAAM,OAAM,SAAA,SAAA,IACjC,KAAK,OACL,MAAM,QACP,KAAK,QAAQ,MAAM;AAEvB,MAAM,kBAAkB,KAAK,IAAI,QAAQ,MAAM,IAAI;AACnD,MAAM,MAAM,kBAAkB,oBAAI,QAChC,KAAK,IAAI,OAAO,KAAK,MAAM,MAAM;AAEnC,MAAM,SAAS,EAAE,MAAM;AAEvB,MAAI,iBAAiB;AACnB,QAAM,uBAAqB,IAAI,IAAI,MAAM,IAAI;AAE7C,SAAK,IAAI,QAAQ,SAAC,UAAU,KAAG;AAC7B,aAAO,IAAI,IACT,KACA,gBAAgB,UAAU,MAAM,IAAI,IAAI;AAE1C,2BAAmB,OAAO;;AAG5B,yBAAmB,QAAQ,SAAA,KAAG;AAC5B,aAAO,IAAI,IACT,KACA,gBACE,MAAM,IAAI,IAAI,MACd,KAAK,IAAI,IAAI;;;AAMrB,SAAO;;AAGT,0BAA0B,MAA2B;AACnD,SAAO,CAAC,QAAQ,CAAE,MAAK,QAAQ,KAAK,IAAI;;AAG1C,oCACE,KACA,MAAqB;MADnB,MAAG,IAAA;AAGL,MAAM,YAAY,IAAI,IAAI;AAC1B,MAAI,aAAa,iBAAiB,YAAY;AAC5C,uBAAmB,KAAK;AACxB,QAAI,OAAO;;;AAIf,IAAM,WAAW,oBAAI;AAIrB,2BACE,aACA,aACA,gBACA,OAAsB;AAEtB,MAAM,WAAW,SAAC,UAAiC;AACjD,QAAM,QAAQ,MAAM,cAA2B,UAAU;AACzD,WAAO,OAAO,UAAU,YAAY;;AAGtC,MAAM,WAAW,SAAS;AAC1B,MAAI,CAAC;AAAU;AAEf,MAAM,WAAW,SAAS;AAC1B,MAAI,CAAC;AAAU;AAIf,MAAI,YAAY;AAAW;AAI3B,MAAI,MAAM,UAAU;AAAW;AAK/B,MAAI,OAAO,KAAK,UAAU,MACxB,SAAA,KAAG;AAAI,WAAA,MAAM,cAAc,UAAU,SAAS;MAAS;AACvD;;AAGF,MAAM,aACJ,MAAM,cAAsB,aAAa,iBACzC,MAAM,cAAsB,aAAa;AAC3C,MAAM,YAAY,uBAAuB;AACzC,MAAM,cAAc,GAAA,OAAG,YAAU,KAAA,OAAI;AAErC,MAAI,SAAS,IAAI;AAAc;AAC/B,WAAS,IAAI;AAEb,MAAM,iBAA2B;AAGjC,MAAI,CAAC,QAAQ,aACT,CAAC,QAAQ,WAAW;AACtB,KAAC,UAAU,UAAU,QAAQ,SAAA,OAAK;AAChC,UAAM,WAAW,MAAM,cAAc,OAAO;AAC5C,UAAI,OAAO,aAAa,YACpB,CAAC,eAAe,SAAS,WAAW;AACtC,uBAAe,KAAK;;;;AAK1B,aAAU,UACZ,KAAA,6CAA6C,OAAS,WAAA,gBAAe,OAAU,YAAA,+EAG7E,OAAA,eAAqB,SACjB,uCACE,eAAe,KAAK,WAAW,gDACjC,IAAE,2CAAA,OAEN,aAAW,4EAAA,OAGC,KAAK,UAAU,UAAU,MAAM,GAAG,MAAK,kBAAA,OACvC,KAAK,UAAU,UAAU,MAAM,GAAG,MAAK;;;;ACjxBrD,IAAA,gBAAA,SAAA,QAAA;AAAmC,YAAA,gBAAA;AAwBjC,0BAAY,QAAgC;AAAhC,QAAA,WAAA,QAAA;AAAA,eAAA;;AAAZ,QAAA,QACE,OAAA,KAAA,SAAO;AApBD,UAAA,UAAU,oBAAI;AAGd,UAAA,wBAAwB,oBAAI;AAcpB,UAAA,UAAU;AA4UlB,UAAA,UAAU;AAxUhB,UAAK,SAAS,gBAAgB;AAC9B,UAAK,cAAc,CAAC,CAAC,MAAK,OAAO;AAEjC,UAAK,WAAW,IAAI,SAAS;MAC3B,OAAO;MACP,kBAAkB,MAAK,OAAO;MAC9B,eAAe,MAAK,OAAO;MAC3B,cAAc,MAAK,OAAO;;AAG5B,UAAK;;;AAGC,iBAAA,UAAA,OAAR,WAAA;AAIE,QAAM,YAAY,KAAK,OAAO,IAAI,YAAY,KAAK;MACjD,UAAU,KAAK;MACf,eAAe,KAAK,OAAO;;AAQ7B,SAAK,iBAAiB,UAAU;AAEhC,SAAK;;AAGC,iBAAA,UAAA,mBAAR,SAAyB,uBAA+B;AAAxD,QAAA,QAAA;AACE,QAAM,iBAAiB,KAAK;AAK5B,SAAK,cAAc,IAAI,YACrB,MACA,KAAK,cAAc,IAAI,YAAY;MACjC,OAAO;MACP,aAAa,KAAK;MAClB,oBAAoB,KAAK,OAAO;MAChC,iBAAiB,sBAAsB,KAAK;MAC5C,OAAO,wBACH,SACA,kBAAkB,eAAe;;AAIzC,SAAK,sBAAsB,KAAK,SAC9B,GACA,SAA0B;AAE1B,aAAO,MAAK,eAAe,GAAG;OAC7B;MACD,KAAK,KAAK,OAAO;MACjB,cAAc,SAAC,GAAqB;AAGlC,YAAM,QAAQ,EAAE,aAAa,MAAK,iBAAiB,MAAK;AACxD,YAAI,sBAAsB,QAAQ;AACxB,cAAA,aAAkC,EAAC,YAAvB,SAAsB,EAAC,QAAf,YAAc,EAAC;AAC3C,iBAAO,MAAM,aACX,EAAE,OAOF,EAAE,UACF,mBAAmB,EAAE,YAAY,QAAQ;;;;AASjD,yBAAI,IAAI;MACN,KAAK,KAAK;MACV,KAAK,eAAe;QACnB,QAAQ,SAAA,OAAK;AAAI,aAAA,MAAM;;;AAGrB,iBAAA,UAAA,UAAP,SAAe,MAA2B;AACxC,SAAK;AAIL,QAAI;AAAM,WAAK,KAAK,QAAQ;AAC5B,WAAO;;AAGF,iBAAA,UAAA,UAAP,SAAe,YAA2B;AAA3B,QAAA,eAAA,QAAA;AAAA,mBAAA;;AACb,WAAQ,cAAa,KAAK,iBAAiB,KAAK,MAAM;;AAGjD,iBAAA,UAAA,OAAP,SAAe,SAA0B;AASrC,QAAA,MACE,QAAO,mBADT,oBAAiB,QAAA,SAAG,QAAK;AAE3B,QAAI;AACF,aAAO,KAAK,YAAY,sBAAqB,SAAA,SAAA,IACxC,UAAO,EACV,OAAO,QAAQ,aAAa,KAAK,iBAAiB,KAAK,MACvD,QAAQ,KAAK,QACb,sBACC,UAAU;aACN,GAAP;AACA,UAAI,aAAa,mBAAmB;AAMlC,eAAO;;AAET,YAAM;;;AAIH,iBAAA,UAAA,QAAP,SAAa,SAA2B;AACtC,QAAI;AACF,QAAE,KAAK;AACP,aAAO,KAAK,YAAY,aAAa,KAAK,MAAM;;AAEhD,UAAI,CAAC,EAAE,KAAK,WAAW,QAAQ,cAAc,OAAO;AAClD,aAAK;;;;AAKJ,iBAAA,UAAA,SAAP,SAAc,SAA4B;AACxC,QAAI,OAAO,KAAK,SAAS,SAAS,CAAC,QAAQ,IAAI;AAU7C,aAAO;;AAET,QAAM,QAAQ,QAAQ,aAClB,KAAK,iBACL,KAAK;AACT,QAAI;AACF,QAAE,KAAK;AACP,aAAO,MAAM,OAAO,QAAQ,MAAM,cAAc,QAAQ;;AAExD,UAAI,CAAC,EAAE,KAAK,WAAW,QAAQ,cAAc,OAAO;AAClD,aAAK;;;;AAKJ,iBAAA,UAAA,OAAP,SACE,SAA6C;AAE7C,WAAO,KAAK,YAAY,sBAAqB,SAAA,SAAA,IACxC,UAAO,EACV,OAAO,QAAQ,aAAa,KAAK,iBAAiB,KAAK,MACvD,QAAQ,QAAQ,MAAM,cACtB,QAAQ,KAAK;;AAIV,iBAAA,UAAA,QAAP,SACE,OAA4C;AAD9C,QAAA,QAAA;AAGE,QAAI,CAAC,KAAK,QAAQ,MAAM;AAWtB,kBAAY;;AAEd,SAAK,QAAQ,IAAI;AACjB,QAAI,MAAM,WAAW;AACnB,WAAK,oBAAoB;;AAE3B,WAAO,WAAA;AAIL,UAAI,MAAK,QAAQ,OAAO,UAAU,CAAC,MAAK,QAAQ,MAAM;AACpD,oBAAY;;AAKd,YAAK,oBAAoB,OAAO;;;AAI7B,iBAAA,UAAA,KAAP,SAAU,SAQT;AACC,uBAAmB;AACnB,QAAM,MAAM,KAAK,eAAe;AAChC,QAAI,WAAW,CAAC,KAAK,SAAS;AAC5B,UAAI,QAAQ,kBAAkB;AAC5B,aAAK,iBAAiB,QAAQ;iBACrB,QAAQ,uBAAuB;AACxC,aAAK,YAAY;;;AAGrB,WAAO;;AAUF,iBAAA,UAAA,SAAP,SAAc,QAAgB,YAAoB;AAChD,WAAQ,cAAa,KAAK,iBAAiB,KAAK,MAAM,OAAO;;AAQxD,iBAAA,UAAA,UAAP,SAAe,QAAgB,YAAoB;AACjD,WAAQ,cAAa,KAAK,iBAAiB,KAAK,MAAM,QAAQ;;AASzD,iBAAA,UAAA,WAAP,SAAgB,QAA+B;AAC7C,QAAI,YAAY;AAAS,aAAO,OAAO;AACvC,QAAI;AACF,aAAO,KAAK,SAAS,SAAS,QAAQ;aAC/B,GAAP;AACA,iBAAU,UAAQ,KAAA;;;AAIf,iBAAA,UAAA,QAAP,SAAa,SAA2B;AACtC,QAAI,CAAC,QAAQ,IAAI;AACf,UAAI,OAAO,KAAK,SAAS,OAAO;AAG9B,eAAO;;AAET,gBAAO,SAAA,SAAA,IAAQ,UAAO,EAAE,IAAI;;AAE9B,QAAI;AAKF,QAAE,KAAK;AAIP,aAAO,KAAK,eAAe,MAAM,SAAS,KAAK;;AAE/C,UAAI,CAAC,EAAE,KAAK,WAAW,QAAQ,cAAc,OAAO;AAClD,aAAK;;;;AAKJ,iBAAA,UAAA,QAAP,SAAa,SAA4B;AAAzC,QAAA,QAAA;AACE,SAAK;AAEL,uBAAmB;AAEnB,QAAI,WAAW,QAAQ,gBAAgB;AAGrC,WAAK,QAAQ,QAAQ,SAAA,OAAK;AAAI,eAAA,MAAK,oBAAoB,OAAO;;AAC9D,WAAK,QAAQ;AACb,kBAAY;WACP;AAOL,WAAK;;AAGP,WAAO,QAAQ;;AAGV,iBAAA,UAAA,mBAAP,SAAwB,YAAkB;AACxC,QAAM,oBAAoB,KAAK,eAAe,YAAY;AAC1D,QAAI,sBAAsB,KAAK,gBAAgB;AAC7C,WAAK,iBAAiB;AACtB,WAAK;;;AAMF,iBAAA,UAAA,QAAP,SACE,SAAyD;AAD3D,QAAA,QAAA;AAII,QAAA,SAIE,QAAO,QAHT,MAGE,QAAO,YAHT,aAAU,QAAA,SAAG,OAAI,KACjB,mBAEE,QAAO,kBADT,iBACE,QAAO;AAEX,QAAI;AACJ,QAAM,UAAU,SAAC,OAAmB;AAC5B,UAAA,MAA2B,OAAzB,OAAI,IAAA,MAAE,iBAAc,IAAA;AAC5B,QAAE,MAAK;AACP,UAAI,OAAO;AACT,cAAK,OAAO,MAAK,iBAAiB;;AAEpC,UAAI;AACF,eAAO,eAAe,OAAO;;AAE7B,UAAE,MAAK;AACP,cAAK,OAAO;AACZ,cAAK,iBAAiB;;;AAI1B,QAAM,eAAe,oBAAI;AAEzB,QAAI,kBAAkB,CAAC,KAAK,SAAS;AAUnC,WAAK,iBAAgB,SAAA,SAAA,IAChB,UAAO,EACV,gBAAc,SAAC,OAAK;AAClB,qBAAa,IAAI;AACjB,eAAO;;;AAKb,QAAI,OAAO,eAAe,UAAU;AAIlC,WAAK,iBAAiB,KAAK,eAAe,SAAS,YAAY;eACtD,eAAe,OAAO;AAM/B,cAAQ,KAAK;WACR;AAGL;;AAGF,QAAI,OAAO,qBAAqB,UAAU;AACxC,WAAK,iBAAiB,KAAK,eAAe,YAAY;;AAMxD,QAAI,kBAAkB,aAAa,MAAM;AACvC,WAAK,iBAAgB,SAAA,SAAA,IAChB,UAAO,EACV,gBAAc,SAAC,OAAO,MAAI;AACxB,YAAM,SAAS,eAAe,KAAK,MAAM,OAAO;AAChD,YAAI,WAAW,OAAO;AAIpB,uBAAa,OAAO;;AAEtB,eAAO;;AAKX,UAAI,aAAa,MAAM;AACrB,qBAAa,QAAQ,SAAA,OAAK;AAAI,iBAAA,MAAK,oBAAoB,MAAM;;;WAE1D;AAIL,WAAK,iBAAiB;;AAGxB,WAAO;;AAGF,iBAAA,UAAA,qBAAP,SACE,QACA,cAA4B;AAE5B,WAAO,KAAK,MAAM;MAChB;MACA,YAAY,gBAAiB,iBAAiB;;;AAI3C,iBAAA,UAAA,oBAAP,SAAyB,UAAsB;AAC7C,QAAI,KAAK,aAAa;AACpB,UAAI,SAAS,KAAK,sBAAsB,IAAI;AAC5C,UAAI,CAAC,QAAQ;AACX,iBAAS,sBAAsB;AAC/B,aAAK,sBAAsB,IAAI,UAAU;AAIzC,aAAK,sBAAsB,IAAI,QAAQ;;AAEzC,aAAO;;AAET,WAAO;;AAGC,iBAAA,UAAA,mBAAV,SAA2B,SAA0B;AAArD,QAAA,QAAA;AACE,QAAI,CAAC,KAAK,SAAS;AACjB,WAAK,QAAQ,QAAQ,SAAA,GAAC;AAAI,eAAA,MAAK,oBAAoB,GAAG;;;;AAUlD,iBAAA,UAAA,iBAAR,SACE,GACA,SAA0B;AAElB,QAAA,WAAa,EAAC;AAQtB,QAAM,OAAO,KAAK,KAAU;AAE5B,QAAI,SAAS;AACX,UAAI,EAAE,cACF,OAAO,QAAQ,eAAe,UAAU;AAC1C,aAAK,4BAA4B;;AAGnC,UAAI,QAAQ,kBACR,QAAQ,eAAe,KAAK,MAAM,GAAG,MAAM,cAAc,OAAO;AAGlE;;;AAIJ,QAAI,CAAC,YAAY,CAAC,MAAM,SAAS,QAAQ,KAAK,SAAS;AACrD,QAAE,SAAS,EAAE,WAAW,MAAM;;;AAGpC,SAAA;EA/gBmC;;;ACzB7B,uBAAwB,KAAU;AACtC,SAAO,IAAI,eAAe;;AAO5B,IAAM,uBAAuB,SAAC,KAAgB;AAC5C,MAAI,UAAU;AAEd,MAAI,gBAAgB,IAAI,kBAAkB,gBAAgB,IAAI,eAAe;AAC3E,QAAM,SAAW,KAAI,iBAAiB,IACnC,OAAO,IAAI,gBAAgB;AAC9B,WAAO,QAAQ,SAAC,OAAY;AAC1B,UAAM,eAAe,QACjB,MAAM,UACN;AACJ,iBAAW,GAAA,OAAG,cAAY;;;AAI9B,MAAI,IAAI,cAAc;AACpB,eAAW,GAAA,OAAG,IAAI,aAAa,SAAO;;AAIxC,YAAU,QAAQ,QAAQ,OAAO;AACjC,SAAO;;AAOT,IAAA,cAAA,SAAA,QAAA;AAAiC,YAAA,cAAA;AAc/B,wBAAY,KAYX;QAXC,gBAAa,IAAA,eACb,eAAY,IAAA,cACZ,eAAY,IAAA,cACZ,eAAY,IAAA,cACZ,YAAS,IAAA;AALX,QAAA,QAaE,OAAA,KAAA,MAAM,iBAAa;AACnB,UAAK,gBAAgB,iBAAiB;AACtC,UAAK,eAAe,gBAAgB;AACpC,UAAK,eAAe,gBAAgB;AACpC,UAAK,UAAU,gBAAgB,qBAAqB;AACpD,UAAK,YAAY;AAIhB,UAAa,YAAY,aAAY;;;AAE1C,SAAA;EAtCiC;;;ACxCjC,IAAY;AAAZ,AAAA,UAAY,gBAAa;AAMvB,iBAAA,eAAA,aAAA,KAAA;AAMA,iBAAA,eAAA,kBAAA,KAAA;AAMA,iBAAA,eAAA,eAAA,KAAA;AAMA,iBAAA,eAAA,aAAA,KAAA;AAOA,iBAAA,eAAA,UAAA,KAAA;AAKA,iBAAA,eAAA,WAAA,KAAA;AAKA,iBAAA,eAAA,WAAA,KAAA;GAzCU,iBAAA,iBAAa;AAgDnB,kCACJ,eAA6B;AAE7B,SAAO,gBAAgB,gBAAgB,IAAI;;;;ACtB3C,IAAA,SAEE,OAAM;AAFR,IACA,kBACE,OAAM;AAmBV,IAAI,yBAAyB;AAQ7B,IAAA,kBAAA,SAAA,QAAA;AAGU,YAAA,kBAAA;AAkCR,4BAAY,KAQX;QAPC,eAAY,IAAA,cACZ,YAAS,IAAA,WACT,UAAO,IAAA;AAHT,QAAA,QASE,OAAA,KAAA,MAAM,SAAC,UAA4C;AAGjD,UAAI;AACF,YAAI,cAAe,SAAiB,cAAc;AAClD,YAAI,eAAe,CAAC,YAAY,OAAO;AACrC,sBAAY,QAAQ;;eAEtB,KAAA;;AAEF,UAAM,QAAQ,CAAC,MAAK,UAAU;AAC9B,YAAK,UAAU,IAAI;AAGnB,UAAM,OAAO,MAAK;AAClB,UAAI,QAAQ,KAAK,OAAO;AACtB,iBAAS,SAAS,SAAS,MAAM,KAAK;iBAC7B,QAAQ,KAAK,QAAQ;AAC9B,iBAAS,QAAQ,SAAS,KAAK,KAAK;;AAKtC,UAAI,OAAO;AAKT,cAAK,YAAY,MAAM,WAAA;;;AAGzB,aAAO,WAAA;AACL,YAAI,MAAK,UAAU,OAAO,aAAa,CAAC,MAAK,UAAU,MAAM;AAC3D,gBAAK;;;UAGT;AA9DI,UAAA,YAAY,oBAAI;AAChB,UAAA,gBAAgB,oBAAI;AAgE1B,UAAK,aAAa;AAGlB,UAAK,UAAU;AACf,UAAK,UAAU,UAAU,WAAW,aAAa;AAEjD,QAAM,QAAQ,uBAAuB,QAAQ;AAC7C,UAAK,YAAY,SAAS,MAAM,QAAQ,MAAM,KAAK;AAEnD,UAAK,qBAAqB,QAAQ,eAAe;AAGjD,UAAK,eAAe;AACpB,UAAK,YAAY;;;AAxFnB,SAAA,eAAW,iBAAA,WAAA,aAAS;SAApB,WAAA;AACE,aAAO,KAAK,QAAQ;;;;;AA0Ff,mBAAA,UAAA,SAAP,WAAA;AAAA,QAAA,QAAA;AACE,WAAO,IAAI,QAAQ,SAAC,SAAS,QAAM;AAIjC,UAAM,WAA+C;QACnD,MAAM,SAAC,QAAgC;AACrC,kBAAQ;AAYR,gBAAK,UAAU,OAAO;AACtB,cAAI,CAAC,MAAK,UAAU,MAAM;AACxB,kBAAK,aAAa,YAAY,MAAK;;AAGrC,qBAAW,WAAA;AACT,yBAAa;aACZ;;QAEL,OAAO;;AAET,UAAM,eAAe,MAAK,UAAU;;;AAIjC,mBAAA,UAAA,mBAAP,SAAwB,kBAAuB;AAAvB,QAAA,qBAAA,QAAA;AAAA,yBAAA;;AAEtB,QAAM,aAAa,KAAK,cAAc;AAEtC,QAAM,gBACJ,KAAK,UAAU,iBACd,cAAc,WAAW,iBAC1B,cAAc;AAEhB,QAAM,SAAS,SAAA,SAAA,IACV,aAAU,EACb,SAAS,yBAAyB,gBAClC;AAGM,QAAA,MAAgC,KAAK,QAAO,aAA5C,cAAW,QAAA,SAAG,gBAAa;AACnC,QAGE,gBAAgB,kBAChB,gBAAgB,cAChB,gBAAgB,aAKhB,KAAK,aAAa,UAAU,KAAK,QAAQ,OAAO,oBAChD;WAEK;AACL,UAAM,OAAO,KAAK,UAAU;AAE5B,UAAI,KAAK,YAAY,KAAK,QAAQ,mBAAmB;AACnD,eAAO,OAAO,KAAK;;AAGrB,UAAI,MAAM,OAAO,MAAM,KAAK;AAC1B,eAAO,OAAO;;AAGhB,UAAI,KAAK,UAAU;AAGjB,eAAO,OAAO;AAKd,YACE,KAAK,YACL,OAAO,kBAAkB,cAAc,WACtC,iBAAgB,iBACjB,gBAAgB,eAChB;AACA,iBAAO,gBAAgB,cAAc;AACrC,iBAAO,UAAU;;aAEd;AACL,eAAO,UAAU;;AAGnB,UACE,WACA,CAAC,KAAK,YACN,CAAC,KAAK,QAAQ,kBACd,CAAC,OAAO,WACR,CAAC,OAAO,QACR,CAAC,OAAO,OACR;AACA,8BAAsB,KAAK;;;AAI/B,QAAI,kBAAkB;AACpB,WAAK,iBAAiB;;AAGxB,WAAO;;AAKF,mBAAA,UAAA,4BAAP,SAAiC,WAAmC;AAClE,WAAO,CAAC,KAAK,QAAQ,CAAC,MAAM,KAAK,KAAK,QAAQ;;AAGxC,mBAAA,UAAA,UAAR,SACE,KACA,oBAA4B;AAE5B,QAAM,OAAO,KAAK;AAClB,QACE,QACA,KAAK,QACJ,EAAC,sBAAsB,MAAM,KAAK,WAAW,KAAK,aACnD;AACA,aAAO,KAAK;;;AAIT,mBAAA,UAAA,gBAAP,SAAqB,oBAA4B;AAC/C,WAAO,KAAK,QAAQ,UAAU;;AAGzB,mBAAA,UAAA,eAAP,SAAoB,oBAA4B;AAC9C,WAAO,KAAK,QAAQ,SAAS;;AAGxB,mBAAA,UAAA,mBAAP,WAAA;AACE,WAAO,KAAK;AACZ,SAAK,aAAa;;AAGb,mBAAA,UAAA,wBAAP,WAAA;AACE,SAAK,aAAa,YAAY,KAAK;;AAU9B,mBAAA,UAAA,UAAP,SAAe,WAA+B;;AAC5C,QAAM,mBAAkE;MAEtE,cAAc;;AAMR,QAAA,cAAgB,KAAK,QAAO;AACpC,QAAI,gBAAgB,qBAAqB;AACvC,uBAAiB,cAAc;eACtB,gBAAgB,YAAY;AACrC,uBAAiB,cAAc;WAC1B;AACL,uBAAiB,cAAc;;AAGjC,QAAI,WAAW,aAAa,gBAAe,KAAK,WAAW,cAAc;AACvE,UAAM,WAAW,mBAAmB,KAAK,QAAQ;AACjD,UAAM,OAAO,SAAS;AACtB,UAAI,CAAC,QAAQ,CAAC,KAAK,KAAK,SAAA,GAAC;AAAI,eAAA,EAAE,SAAS,KAAK,UAAU;UAAc;AACnE,mBAAU,UAAK,KAAA,kBACT,OAAC,KAAU,UAAU,YAAA,gBAEzB,OAAA,QAAS,SAAI,UAAA,QAAA,QAAA,SAAA,SAAO,IAAI,UAAK,KAAU,UAAS,WAAA;;;AAMtD,QAAI,aAAa,CAAC,MAAM,KAAK,QAAQ,WAAW,YAAY;AAE1D,uBAAiB,YAAY,KAAK,QAAQ,YAAY,SAAA,SAAA,IACjD,KAAK,QAAQ,YACb;;AAIP,SAAK,UAAU;AACf,WAAO,KAAK,UAAU,kBAAkB,cAAc;;AAGjD,mBAAA,UAAA,YAAP,SACE,kBACqC;AAFvC,QAAA,QAAA;AAIE,QAAM,kBAAkB,SAAA,SAAA,IAClB,iBAAiB,QAAQ,mBAAkB,SAAA,SAAA,SAAA,IAC1C,KAAK,UACL,mBAAgB,EACnB,WAAS,SAAA,SAAA,IACJ,KAAK,QAAQ,YACb,iBAAiB,gBAEtB,EAMF,aAAa;AAGf,QAAM,MAAM,KAAK,aAAa;AAI9B,QAAI,gBAAgB,6BAA6B;AAC/C,WAAK,UAAU,gBAAgB,cAAc;AAC7C,WAAK;;AAGP,WAAO,KAAK,aAAa,WACvB,KACA,iBACA,cAAc,WACd,KAAK,SAAA,iBAAe;AACpB,UAAM,OAAO,gBAAgB;AACrB,UAAA,cAAgB,iBAAgB;AAExC,UAAI,aAAa;AACf,YAAI,WACA,CAAC,wBAAwB;AAC3B,qBAAU,UACpB,KAAA;AAWU,mCAAyB;;AAE3B,cAAK,YAAY,SAAA,UAAQ;AAAI,iBAAA,YAAY,UAAU;YACjD,iBAAiB;YACjB,WAAW,gBAAgB;;;aAExB;AAML,cAAK,aAAa,MAAM,WAAW;UACjC,OAAO,gBAAgB;UACvB,WAAW,gBAAgB;UAC3B;;;AAIJ,aAAO;OAEN,QAAQ,WAAA;AACT,YAAK,aAAa,UAAU;AAC5B,YAAK;;;AAOF,mBAAA,UAAA,kBAAP,SAIE,SAIC;AARH,QAAA,QAAA;AAUE,QAAM,eAAe,KAAK,aACvB,yBAAyB;MACxB,OAAO,QAAQ;MACf,WAAW,QAAQ;MACnB,SAAS,QAAQ;OAElB,UAAU;MACT,MAAM,SAAC,kBAA6C;AAC1C,YAAA,cAAgB,QAAO;AAC/B,YAAI,aAAa;AACf,gBAAK,YACH,SAAC,UAAU,KAAa;gBAAX,YAAS,IAAA;AACpB,mBAAA,YAAY,UAAU;cACpB;cACA;;;;;MAKV,OAAO,SAAC,KAAQ;AACd,YAAI,QAAQ,SAAS;AACnB,kBAAQ,QAAQ;AAChB;;AAEF,mBAAU,UAAM,MAAA,wCAA6C;;;AAInE,SAAK,cAAc,IAAI;AAEvB,WAAO,WAAA;AACL,UAAI,MAAK,cAAc,OAAO,eAAe;AAC3C,qBAAa;;;;AAKZ,mBAAA,UAAA,aAAP,SACE,YAAyD;AAEzD,WAAO,KAAK,UAAU;;AAwBjB,mBAAA,UAAA,eAAP,SACE,WAAqB;AAErB,QAAI,MAAM,KAAK,WAAW,YAAY;AAIpC,aAAO,KAAK,UAAU,OAClB,KAAK,WACL,QAAQ;;AAGd,SAAK,QAAQ,YAAY;AAGzB,QAAI,CAAC,KAAK,UAAU,MAAM;AACxB,aAAO,QAAQ;;AAGjB,WAAO,KAAK,UAAU;MAEpB,aAAa,KAAK;MAClB;OACC,cAAc;;AAGZ,mBAAA,UAAA,cAAP,SACE,OAGU;AAEF,QAAA,eAAiB,KAAI;AACrB,QAAA,SAAW,aAAa,MAAM,KAAY;MAChD,OAAO,KAAK,QAAQ;MACpB,WAAW,KAAK;MAChB,mBAAmB;MACnB,YAAY;OACZ;AAEF,QAAM,YAAY,MAAM,QAAS;MAC/B,WAAY,KAAa;;AAG3B,QAAI,WAAW;AACb,mBAAa,MAAM,WAAW;QAC5B,OAAO,KAAK,QAAQ;QACpB,MAAM;QACN,WAAW,KAAK;;AAGlB,mBAAa;;;AAIV,mBAAA,UAAA,eAAP,SAAoB,cAAoB;AACtC,SAAK,QAAQ,eAAe;AAC5B,SAAK;;AAGA,mBAAA,UAAA,cAAP,WAAA;AACE,SAAK,QAAQ,eAAe;AAC5B,SAAK;;AAGC,mBAAA,UAAA,QAAR,SACE,SACA,kBAAgC;AAEhC,SAAK,aAAa,mBAAmB;AACrC,WAAO,KAAK,aAAa,qBACvB,KAAK,SACL,SACA;;AAKI,mBAAA,UAAA,gBAAR,WAAA;AAAA,QAAA,QAAA;AAEE,QAAI,KAAK,aAAa,SAAS;AAC7B;;AAGI,QAAA,MAKF,MAJF,cAAW,IAAA,aAET,eAAY,IAAA,QAAA;AAIhB,QAAI,CAAC,cAAc;AACjB,UAAI,aAAa;AACf,qBAAa,YAAY;AACzB,eAAO,KAAK;;AAEd;;AAGF,QAAI,eACA,YAAY,aAAa,cAAc;AACzC;;AAGF,cACE,UAAA,cACA,oEACA,UAAA,cAAA;AAEF,QAAM,OAAO,eAAgB,MAAK,cAAc;AAChD,SAAK,WAAW;AAEhB,QAAM,aAAa,WAAA;AACjB,UAAI,MAAK,aAAa;AACpB,YAAI,CAAC,yBAAyB,MAAK,UAAU,gBAAgB;AAC3D,gBAAK,UAAU;YACb,aAAa;aACZ,cAAc,MAAM,KAAK,MAAM;eAC7B;AACL;;;AAEH;;AAGH,QAAM,OAAO,WAAA;AACX,UAAM,QAAO,MAAK;AAClB,UAAI,OAAM;AACR,qBAAa,MAAK;AAClB,cAAK,UAAU,WAAW,YAAY,MAAK;;;AAI/C;;AAGM,mBAAA,UAAA,mBAAR,SACE,WACA,WAA0B;AAA1B,QAAA,cAAA,QAAA;AAAA,kBAAY,KAAK;;AAEjB,SAAK,OAAI,SAAA,SAAA,IACJ,KAAK,OAAI,EACZ,QAAQ,KAAK,aAAa,yBACtB,YACA,UAAU,YACd;AAEF,QAAI,CAAC,gBAAgB,UAAU,SAAS;AACtC,aAAO,KAAK,KAAK;;AAEnB,WAAO,KAAK;;AAGP,mBAAA,UAAA,YAAP,SACE,YACA,kBAAgC;AAFlC,QAAA,QAAA;AAIE,SAAK,aAAa;AAElB,QAAM,uBAIJ,qBAAqB,cAAc,WAGnC,qBAAqB,cAAc,aAGnC,qBAAqB,cAAc;AAGrC,QAAM,eAAe,KAAK,QAAQ;AAElC,QAAM,UAAU,uBAGZ,QAAQ,KAAK,SAAS,cACtB,OAAO,KAAK,SAAS,QAAQ;AAEjC,QAAI,CAAC,sBAAsB;AAEzB,WAAK;AAIL,UACE,cACA,WAAW,aACX,CAAC,WAAW,eACZ,CAAC,MAAM,WAAW,WAAW,eAC7B;AACA,gBAAQ,cAAc,KAAK;AAC3B,YAAI,qBAAqB,QAAQ;AAC/B,6BAAmB,cAAc;;;;AAKvC,QAAM,YAAY,QAAQ,aAAS,SAAA,IAAS,QAAQ;AACpD,QAAM,UAAU,KAAK,MAAM,SAAS;AACpC,QAAM,WAA+C;MACnD,MAAM,SAAA,QAAM;AACV,cAAK,aAAa,QAAQ;;MAE5B,OAAO,SAAA,OAAK;AACV,cAAK,YAAY,OAAO;;;AAI5B,QAAI,CAAC,sBAAsB;AAMzB,UAAI,KAAK,WAAW,KAAK,UAAU;AACjC,aAAK,QAAQ,eAAe,KAAK,UAAU;;AAG7C,WAAK,UAAU;AACf,WAAK,WAAW;;AAGlB,YAAQ,YAAY;AAEpB,WAAO,QAAQ;;AAKT,mBAAA,UAAA,UAAR,WAAA;AAKE,SAAK,aACH,KAAK,iBAAiB,QACtB,KAAK;;AAID,mBAAA,UAAA,eAAR,SACE,QACA,WAAiC;AAEjC,QAAM,YAAY,KAAK;AACvB,QAAI,aAAa,KAAK,0BAA0B,SAAS;AACvD,UAAI,aAAa,CAAC,OAAO,WAAW,KAAK,QAAQ,mBAAmB;AAClE,aAAK,iBAAiB,QAAQ;;AAGhC,6BAAuB,KAAK,WAAW,QAAQ;;;AAI3C,mBAAA,UAAA,cAAR,SACE,OACA,WAAiC;AAIjC,QAAM,cAAc,SAAA,SAAA,IACf,KAAK,kBAAe,EACvB,OACA,QAAQ,MAAM,eACd,eAAe,cAAc,OAC7B,SAAS;AAGX,SAAK,iBAAiB,aAAa;AAEnC,2BAAuB,KAAK,WAAW,SAAS,KAAK,KAAM,QAAQ;;AAG9D,mBAAA,UAAA,eAAP,WAAA;AACE,WAAO,KAAK,UAAU,OAAO;;AAGvB,mBAAA,UAAA,gBAAR,WAAA;AACE,QAAI,KAAK;AAAY;AACrB,QAAI,KAAK,WAAW,KAAK,UAAU;AACjC,WAAK,QAAQ,eAAe,KAAK;AACjC,aAAO,KAAK;AACZ,aAAO,KAAK;;AAGd,SAAK;AAEL,SAAK,cAAc,QAAQ,SAAA,KAAG;AAAI,aAAA,IAAI;;AACtC,SAAK,cAAc;AACnB,SAAK,aAAa,UAAU,KAAK;AACjC,SAAK,UAAU;AACf,SAAK,aAAa;;AAEtB,SAAA;EA9uBU;AAkvBV,sBAAsB;AAEtB,kDAAkD,OAAkB;AAClE,aAAU,UAAM,MAAA,mBAAyB,MAAS,SAAW,MAAE;;AAG3D,+BACJ,SAAsD;AAEtD,MAAI,WAAW,SAAS;AACtB,eAAU,UAAM,MAAA,gCACV,OAAC,KAAU,UACb,WAAS;;;AAQX,8BACJ,SAIC;AAGC,MAAA,MAEE,QAAO,aAFT,cAAW,QAAA,SAAG,gBAAa,KAC3B,kBACE,QAAO;AAEX,MAAI,iBAAiB;AAWnB,YAAQ,cAAc,OAAO,oBAAoB,aAC7C,gBAAgB,KAAK,SAAS,eAC9B;;;;;ACtxBR,IAAA,aAAA,WAAA;AAME,uBAAY,KAKqB;QAJ/B,SAAK,IAAA,OACL,SAAM,IAAA,QACN,YAAS,IAAA,WACT,kBAAe,IAAA;AAEf,SAAK,QAAQ;AAEb,QAAI,QAAQ;AACV,WAAK,SAAS;;AAGhB,QAAI,WAAW;AACb,WAAK,aAAa;;AAGpB,QAAI,iBAAiB;AACnB,WAAK,mBAAmB;;;AAIrB,cAAA,UAAA,eAAP,SAAoB,WAAkC;AAAtD,QAAA,QAAA;AACE,SAAK,YAAY,KAAK,aAAa;AACnC,QAAI,MAAM,QAAQ,YAAY;AAC5B,gBAAU,QAAQ,SAAA,eAAa;AAC7B,cAAK,YAAY,UAAU,MAAK,WAAW;;WAExC;AACL,WAAK,YAAY,UAAU,KAAK,WAAW;;;AAIxC,cAAA,UAAA,eAAP,SAAoB,WAAkC;AACpD,SAAK,YAAY;AACjB,SAAK,aAAa;;AAGb,cAAA,UAAA,eAAP,WAAA;AACE,WAAO,KAAK,aAAa;;AAOd,cAAA,UAAA,eAAb,SAAiC,KAYhC;QAXC,WAAQ,IAAA,UACR,eAAY,IAAA,cACZ,UAAO,IAAA,SACP,YAAS,IAAA,WACT,KAAA,IAAA,wBAAA,yBAAsB,OAAA,SAAG,QAAK;;;AAQ9B,YAAI,UAAU;AACZ,iBAAA,CAAA,GAAO,KAAK,gBACV,UACA,aAAa,MACb,SACA,WACA,KAAK,iBACL,wBACA,KAAK,SAAA,aAAW;AAAI,mBAAA,SAAA,SAAA,IACjB,eAAY,EACf,MAAM,YAAY;;;AAItB,eAAA,CAAA,GAAO;;;;AAGF,cAAA,UAAA,qBAAP,SAA0B,iBAAgC;AACxD,SAAK,kBAAkB;;AAGlB,cAAA,UAAA,qBAAP,WAAA;AACE,WAAO,KAAK;;AAKP,cAAA,UAAA,cAAP,SAAmB,UAAsB;AACvC,QAAI,cAAc,CAAC,WAAW,WAAW;AACvC,UAAI,KAAK,WAAW;AAClB,eAAO;;;AAGX,WAAO;;AAIF,cAAA,UAAA,cAAP,SAAmB,UAAsB;AACvC,WAAO,6BAA6B;;AAG/B,cAAA,UAAA,iBAAP,SAAsB,SAA6B;AACzC,QAAA,SAAU,KAAI;AACtB,WAAA,SAAA,SAAA,IACK,UAAO,EACV,OAAK,QAEL,aAAA,SAAY,KAAgB;AAC1B,aAAO,OAAM,SAAS;;;AAQf,cAAA,UAAA,uBAAb,SACE,UACA,WACA,SAAY;AADZ,QAAA,cAAA,QAAA;AAAA,kBAAA;;AACA,QAAA,YAAA,QAAA;AAAA,gBAAA;;;;AAEA,YAAI,UAAU;AACZ,iBAAA,CAAA,GAAO,KAAK,gBACV,UACA,KAAK,wBAAwB,UAAU,cAAc,IACrD,KAAK,eAAe,UACpB,WACA,KAAK,SAAA,MAAI;AAAI,mBAAA,SAAA,SAAA,IACV,YACA,KAAK;;;AAIZ,eAAA,CAAA,GAAA,SAAA,IACK;;;;AAIA,cAAA,UAAA,uBAAP,SAA4B,UAAiB;AAC3C,QAAI,iBAAiB;AACrB,UAAM,UAAU;MACd,WAAW;QACT,OAAK,SAAC,MAAI;AACR,cAAI,KAAK,KAAK,UAAU,YAAY,KAAK,WAAW;AAClD,6BAAiB,KAAK,UAAU,KAC9B,SAAA,KAAG;AACD,qBAAA,IAAI,KAAK,UAAU,YACnB,IAAI,MAAM,SAAS,kBACnB,IAAI,MAAM,UAAU;;AAExB,gBAAI,gBAAgB;AAClB,qBAAO;;;;;;AAMjB,WAAO;;AAID,cAAA,UAAA,0BAAR,SACE,UACA,WAA+B;AAE/B,WAAO,KAAK,MAAM,KAAK;MACrB,OAAO,2BAA2B;MAClC;MACA,mBAAmB;MACnB,YAAY;OACX;;AAGS,cAAA,UAAA,kBAAd,SACE,UACA,WACA,SACA,WACA,iBACA,wBAAuC;AAHvC,QAAA,YAAA,QAAA;AAAA,gBAAA;;AACA,QAAA,cAAA,QAAA;AAAA,kBAAA;;AACA,QAAA,oBAAA,QAAA;AAAA,wBAAA,WAAA;AAAyC,eAAA;;;AACzC,QAAA,2BAAA,QAAA;AAAA,+BAAA;;;;;AAEM,yBAAiB,kBAAkB;AACnC,oBAAY,uBAAuB;AACnC,sBAAc,kBAAkB;AAEhC,8BAAuB,eAC1B;AAEG,+BAAuB,sBACzB,oBAAoB,OAAO,GAAG,gBAC9B,oBAAoB,MAAM,KAC1B;AAEE,cAAoB,MAAlB,SAAK,IAAA,OAAE,SAAM,IAAA;AACf,sBAA2B;UAC/B;UACA,SAAO,SAAA,SAAA,IACF,UAAO,EACV,OAAK,QACL;UAEF;UACA;UACA;UACA,mBAAmB;UACnB;;AAGF,eAAA,CAAA,GAAO,KAAK,oBACV,eAAe,cACf,WACA,aACA,KAAK,SAAA,QAAM;AAAI,iBAAC;YAChB;YACA,mBAAmB,YAAY;;;;;;AAIrB,cAAA,UAAA,sBAAd,SACE,cACA,WACA,aAAwB;;;;;AAEhB,sBAAoC,YAAW,aAAlC,UAAuB,YAAW,SAAzB,YAAc,YAAW;AACjD,yBAA0B,CAAC;AAE3B,mBAAU,SAAO,WAAwB;AAAA,iBAAA,UAAA,OAAA,QAAA,QAAA,WAAA;;;AAC7C,kBAAI,CAAC,cAAc,WAAW,YAAY;AAExC,uBAAA,CAAA;;AAGF,kBAAI,QAAQ,YAAY;AACtB,uBAAA,CAAA,GAAO,KAAK,aAAa,WAAW,WAAW,aAAa,KAC1D,SAAA,aAAW;;AACT,sBAAI,OAAO,gBAAgB,aAAa;AACtC,mCAAe,KAAK,OAAA,IAClB,IAAC,uBAAuB,cAAa;;;;AAS/C,kBAAI,iBAAiB,YAAY;AAC/B,2BAAW;qBACN;AAEL,2BAAW,YAAY,UAAU,KAAK;AACtC,0BAAU,UAAU,UAAA,qBAAqB,OAAU,UAAU,KAAI,UAAA,UAAA,UAAA;;AAGnE,kBAAI,YAAY,SAAS,eAAe;AAChC,gCAAgB,SAAS,cAAc,KAAK;AAClD,oBAAI,YAAY,gBAAgB,WAAW,eAAe,UAAU;AAClE,yBAAA,CAAA,GAAO,KAAK,oBACV,SAAS,cACT,WACA,aACA,KAAK,SAAA,gBAAc;AACnB,mCAAe,KAAK;;;;;;;;AAM5B,eAAA,CAAA,GAAO,QAAQ,IAAI,aAAa,WAAW,IAAI,WAAU,KAAK,WAAA;AAC5D,iBAAO,eAAe;;;;;AAIZ,cAAA,UAAA,eAAd,SACE,OACA,WACA,aAAwB;;;;;AAEhB,oBAAc,YAAW;AAC3B,oBAAY,MAAM,KAAK;AACvB,2BAAmB,uBAAuB;AAC1C,oBAAY,cAAc;AAC1B,wBAAgB,UAAU,qBAAqB,UAAU;AAC3D,wBAAgB,QAAQ,QAAQ;AAMpC,YACE,CAAC,YAAY,0BACb,KAAK,qBAAqB,QAC1B;AACM,yBACJ,UAAU,cAAc,YAAY;AAChC,wBAAc,KAAK,aAAa,KAAK,UAAU;AACrD,cAAI,aAAa;AACT,sBAAU,YAAY,YAAY,YAAY;AACpD,gBAAI,SAAS;AACX,8BAAgB,QAAQ,QAGtB,UAAU,UAAU,KAAK,OAAO,SAAS;gBACvC;gBACA,yBAAyB,OAAO;gBAChC,YAAY;gBACZ,EAAE,OAAO,aAAa,YAAY;;;;;AAO5C,eAAA,CAAA,GAAO,cAAc,KAAK,SAAC,QAAsB;AAAtB,cAAA,WAAA,QAAA;AAAA,qBAAA;;AAGzB,cAAI,MAAM,YAAY;AACpB,kBAAM,WAAW,QAAQ,SAAA,WAAS;AAChC,kBAAI,UAAU,KAAK,UAAU,YAAY,UAAU,WAAW;AAC5D,0BAAU,UAAU,QAAQ,SAAA,KAAG;AAC7B,sBAAI,IAAI,KAAK,UAAU,QAAQ,IAAI,MAAM,SAAS,eAAe;AAC/D,gCAAY,kBAAkB,IAAI,MAAM,SAAS;;;;;;AAQ3D,cAAI,CAAC,MAAM,cAAc;AACvB,mBAAO;;AAKT,cAAI,UAAU,MAAM;AAElB,mBAAO;;AAGT,cAAI,MAAM,QAAQ,SAAS;AACzB,mBAAO,MAAK,wBAAwB,OAAO,QAAQ;;AAIrD,cAAI,MAAM,cAAc;AACtB,mBAAO,MAAK,oBACV,MAAM,cACN,QACA;;;;;;AAMA,cAAA,UAAA,0BAAR,SACE,OACA,QACA,aAAwB;AAH1B,QAAA,QAAA;AAKE,WAAO,QAAQ,IACb,OAAO,IAAI,SAAA,MAAI;AACb,UAAI,SAAS,MAAM;AACjB,eAAO;;AAIT,UAAI,MAAM,QAAQ,OAAO;AACvB,eAAO,MAAK,wBAAwB,OAAO,MAAM;;AAInD,UAAI,MAAM,cAAc;AACtB,eAAO,MAAK,oBAAoB,MAAM,cAAc,MAAM;;;;AAKpE,SAAA;;;;ACraA,IAAM,0BAA0B,IAC9B,iBAAgB,UAAU;AAG5B,oCACE,QACA,YAAkC;AAElC,MAAM,WAAW,OAAM;AACvB,MAAI,OAAO,aAAa,YAAY;AAClC,WAAM,cAAc,WAAA;AAClB,8BAAwB,IACtB,QAKC,yBAAwB,IAAI,UAAU,KAAK;AAE9C,aAAO,SAAS,MAAM,MAAM;;;;AAKlC,6BAA6B,MAAe;AAC1C,MAAI,KAAK,kBAAkB;AACzB,iBAAa,KAAK;AAClB,SAAK,mBAAmB;;;AAgB5B,IAAA,YAAA,WAAA;AAaE,sBACE,cACgB,SAAwC;AAAxC,QAAA,YAAA,QAAA;AAAA,gBAAU,aAAa;;AAAvB,SAAA,UAAA;AAdlB,SAAA,YAAY,oBAAI;AAChB,SAAA,WAAgC;AAChC,SAAA,gBAAgB;AAChB,SAAA,gBAAgB,oBAAI;AAKpB,SAAA,UAAU;AA+DF,SAAA,QAAiB;AAmET,SAAA,kBAA+C;AA1H7D,QAAM,SAAQ,KAAK,QAAQ,aAAa;AAOxC,QAAI,CAAC,wBAAwB,IAAI,SAAQ;AACvC,8BAAwB,IAAI,QAAO;AACnC,iCAA2B,QAAO;AAClC,iCAA2B,QAAO;AAClC,iCAA2B,QAAO;;;AAI/B,aAAA,UAAA,OAAP,SAAY,OASX;AACC,QAAI,gBAAgB,MAAM,iBAAiB,cAAc;AACzD,QAAI,KAAK,aACL,KAAK,kBAAkB,cAAc,WACrC,CAAC,MAAM,KAAK,WAAW,MAAM,YAAY;AAC3C,sBAAgB,cAAc;;AAGhC,QAAI,CAAC,MAAM,MAAM,WAAW,KAAK,YAAY;AAC3C,WAAK,WAAW;;AAGlB,WAAO,OAAO,MAAM;MAClB,UAAU,MAAM;MAChB,WAAW,MAAM;MACjB,cAAc;MACd,eAAe,KAAK,iBAAiB;MACrC;;AAGF,QAAI,MAAM,iBAAiB;AACzB,WAAK,mBAAmB,MAAM;;AAGhC,QAAI,MAAM,eAAe;AACvB,WAAK,gBAAgB,MAAM;;AAG7B,WAAO;;AAOT,aAAA,UAAA,QAAA,WAAA;AACE,wBAAoB;AACpB,SAAK,WAAW;AAChB,SAAK,QAAQ;;AAGf,aAAA,UAAA,UAAA,SAAQ,WAA0B;AAA1B,QAAA,cAAA,QAAA;AAAA,kBAAY,KAAK;;AACvB,QAAM,UAAU,KAAK,eAAe;AAEpC,QAAI,KAAK,YAAY,MAAM,SAAS,KAAK,SAAS,UAAU;AAC1D,aAAO,KAAK,SAAS;;AAGvB,SAAK,YAAY,KAAK,YAAY;AAElC,QAAM,KAAK,KAAK;AAChB,QAAI,MAAM,GAAG,QAAQ,gBAAgB,YAAY;AAC/C,aAAO,EAAE,UAAU;;AAGrB,QAAM,OAAO,KAAK,MAAM,KAAK;AAC7B,SAAK,eAAe,MAAM;AAC1B,WAAO;;AAQD,aAAA,UAAA,iBAAR,SACE,MACA,SAA2B;AAE3B,SAAK,WAAW,OAAO;MACrB;MACA,SAAS,WAAW,KAAK;QACvB;;AAGE,aAAA,UAAA,iBAAR,SAAuB,WAA0B;;AAA1B,QAAA,cAAA,QAAA;AAAA,kBAAY,KAAK;;AACtC,WAAO;MACL,OAAO,KAAK;MACZ;MACA,mBAAmB;MACnB,YAAY;MACZ,iBAAiB,OAAA,KAAK,qBAAe,QAAA,QAAA,SAAA,SAAA,IAAE,QAAQ;;;AAInD,aAAA,UAAA,UAAA,SAAQ,MAAkC;AAA1C,QAAA,QAAA;AACE,QAAM,UAAU,KAAK,YAAY,KAAK,SAAS;AAC/C,SAAK,eAAe;AACpB,QAAI,CAAC,KAAK,SACN,CAAC,MAAM,WAAW,QAAQ,QACnB,QAAQ,KAAK,SAAS;AAC/B,WAAK,QAAQ;AACb,UAAI,CAAC,KAAK,eAAe;AACvB,aAAK,gBAAgB,WAAW,WAAA;AAAM,iBAAA,MAAK;WAAU;;;;AAQ3D,aAAA,UAAA,qBAAA,SAAmB,IAA+B;AAAlD,QAAA,QAAA;AACE,QAAI,OAAO,KAAK;AAAiB;AAEjC,QAAI,KAAK,YAAY;AACnB,WAAK,UAAU,OAAO,KAAK;;AAG5B,SAAa,kBAAkB;AAEhC,QAAI,IAAI;AACN,SAAG,eAAe;AAClB,WAAK,UAAU,IAAI,KAAK,aAAa,WAAA;AAMnC,YAAI,MAAK,UAAU,2BAA2B;AAC5C,aAAG;eACE;AACL,aAAG;;;WAGF;AACL,aAAO,KAAK;;;AAIhB,aAAA,UAAA,SAAA,WAAA;AAAA,QAAA,QAAA;AACE,wBAAoB;AAEpB,QAAI,KAAK,gBAAgB;AACvB,WAAK,UAAU,QAAQ,SAAA,UAAQ;AAAI,eAAA,SAAS;;;AAG9C,SAAK,QAAQ;;AAGP,aAAA,UAAA,eAAR,WAAA;AACE,QAAI,CAAC,KAAK,SAAS,CAAC,KAAK,UAAU,MAAM;AACvC,aAAO;;AAGT,QAAI,yBAAyB,KAAK,kBAC9B,KAAK,iBAAiB;AAChB,UAAA,cAAgB,KAAK,gBAAgB,QAAO;AACpD,UAAI,gBAAgB,gBAChB,gBAAgB,qBAAqB;AACvC,eAAO;;;AAIX,WAAO;;AAGF,aAAA,UAAA,OAAP,WAAA;AACE,QAAI,CAAC,KAAK,SAAS;AACjB,WAAK,UAAU;AAGf,WAAK;AAEL,WAAK;AAGL,WAAK,SAAS,WAAU,UAAU;AAElC,WAAK,cAAc,QAAQ,SAAA,KAAG;AAAI,eAAA,IAAI;;AAEtC,UAAM,KAAK,KAAK;AAChB,UAAI;AAAI,WAAG;;;AAMP,aAAA,UAAA,SAAR,WAAA;;AAIQ,aAAA,UAAA,cAAR,SAAoB,WAA0B;AAA9C,QAAA,QAAA;AAAoB,QAAA,cAAA,QAAA;AAAA,kBAAY,KAAK;;AACnC,QAAM,KAAK,KAAK;AAChB,QAAI,MAAM,GAAG,QAAQ,gBAAgB,YAAY;AAC/C;;AAGF,QAAM,eAAY,SAAA,SAAA,IAIb,KAAK,eAAe,aAAU,EACjC,SAAS,MACT,UAAU,SAAA,MAAI;AAAI,aAAA,MAAK,QAAQ;;AAGjC,QAAI,CAAC,KAAK,aACN,CAAC,MAAM,cAAc,KAAK,YAAY;AACxC,WAAK;AACL,WAAK,SAAS,KAAK,MAAM,MAAM,KAAK,YAAY;;;AAU7C,aAAA,UAAA,iBAAP,WAAA;AACE,SAAK,YAAY;;AAGX,aAAA,UAAA,cAAR,SACE,QACA,WAAyC;AAEjC,QAAA,YAAc,KAAI;AAC1B,WAAO,CACL,cAIA,UAAU,YAAY,wBAAwB,IAAI,KAAK,UACvD,MAAM,WAAW,UAAU,cAC3B,MAAM,OAAO,MAAM,UAAU,OAAO;;AAIjC,aAAA,UAAA,aAAP,SACE,QACA,SAIA,oBAAsC;AANxC,QAAA,QAAA;AAQE,SAAK,gBAAgB,gBAAgB,OAAO,UAAU,OAAO,SAAS;AAItE,SAAK;AAEL,QAAI,QAAQ,gBAAgB,YAAY;AACtC,WAAK,eACH,EAAE,QAAQ,OAAO,MAAM,UAAU,QACjC,KAAK,eAAe,QAAQ;eAGrB,uBAAkB,GAAgC;AAC3D,UAAI,kBAAkB,QAAQ,QAAQ,cAAc;AAKlD,aAAK,MAAM,mBAAmB,SAAA,QAAK;AACjC,cAAI,MAAK,YAAY,QAAQ,QAAQ,YAAY;AAC/C,mBAAM,WAAW;cACf,OAAO,MAAK;cACZ,MAAM,OAAO;cACb,WAAW,QAAQ;cACnB,WAAW,uBAAkB;;AAG/B,kBAAK,YAAY;cACf;cACA,WAAW,QAAQ;cACnB,SAAS,wBAAwB,IAAI,MAAK;;iBAEvC;AAiCL,gBAAI,MAAK,YACL,MAAK,SAAS,KAAK,UAAU;AAG/B,qBAAO,OAAO,MAAK,SAAS,KAAK;AACjC;;;AAMJ,cAAM,cAAc,MAAK,eAAe,QAAQ;AAChD,cAAM,OAAO,OAAM,KAAQ;AAK3B,cAAI,CAAC,MAAK,SAAS;AAGjB,kBAAK,YAAY,QAAQ;;AAQ3B,gBAAK,eAAe,MAAM;AAC1B,cAAI,KAAK,UAAU;AACjB,mBAAO,OAAO,KAAK;;;aAGlB;AACL,aAAK,YAAY;;;;AAKhB,aAAA,UAAA,YAAP,WAAA;AACE,SAAK,eAAe;AACpB,WAAO,KAAK,gBAAgB,cAAc;;AAGrC,aAAA,UAAA,YAAP,SAAiB,OAAkB;AACjC,SAAK,gBAAgB,cAAc;AACnC,SAAK,YAAY;AAEjB,SAAK;AAEL,QAAI,MAAM,eAAe;AACvB,WAAK,gBAAgB,MAAM;;AAG7B,QAAI,MAAM,cAAc;AACtB,WAAK,eAAe,MAAM;;AAG5B,WAAO;;AAEX,SAAA;;AAEM,2BACJ,QACA,aAAiC;AAAjC,MAAA,gBAAA,QAAA;AAAA,kBAAA;;AAEA,MAAM,eACJ,gBAAgB,YAChB,gBAAgB;AAClB,MAAI,kBAAkB,CAAC,sBAAsB;AAC7C,MAAI,CAAC,mBAAmB,gBAAgB,OAAO,MAAM;AACnD,sBAAkB;;AAEpB,SAAO;;;;AClbD,IAAA,kBAAmB,OAAO,UAAS;AAqB3C,IAAA,eAAA,WAAA;AAuBE,yBAAY,KAkBX;QAjBC,SAAK,IAAA,OACL,OAAI,IAAA,MACJ,KAAA,IAAA,oBAAA,qBAAkB,OAAA,SAAG,QAAK,IAC1B,cAAW,IAAA,aACX,KAAA,IAAA,SAAA,UAAO,OAAA,SAAG,QAAK,IACf,KAAA,IAAA,iBAAA,kBAAe,OAAA,SAAG,KAAE,IACpB,aAAU,IAAA,YACV,yBAAsB,IAAA;AAxBhB,SAAA,kBAA0C;AAU1C,SAAA,UAAU,oBAAI;AAId,SAAA,iBAAiB,oBAAI;AA0brB,SAAA,iBAAiB,IACvB,iBAAgB,UAAU;AAmIpB,SAAA,iBAAiB;AAKjB,SAAA,mBAAmB;AAKnB,SAAA,oBAAoB;AA2PpB,SAAA,0BAA0B,oBAAI;AA9yBpC,SAAK,QAAQ;AACb,SAAK,OAAO;AACZ,SAAK,qBAAqB;AAC1B,SAAK,kBAAkB;AACvB,SAAK,aAAa,cAAc,IAAI,WAAW,EAAE,OAAK;AACtD,SAAK,UAAU;AACf,SAAK,yBAAyB,CAAC,CAAC;AAChC,QAAK,KAAK,cAAc,aAAc;AACpC,WAAK,gBAAgB,uBAAO,OAAO;;;AAQhC,gBAAA,UAAA,OAAP,WAAA;AAAA,QAAA,QAAA;AACE,SAAK,QAAQ,QAAQ,SAAC,OAAO,SAAO;AAClC,YAAK,qBAAqB;;AAG5B,SAAK,qBACH,UAAI,IAAA,eAAe,oDACnB,IAAA,eAAA;;AAGI,gBAAA,UAAA,uBAAR,SAA6B,OAAY;AACvC,SAAK,eAAe,QAAQ,SAAA,QAAM;AAAI,aAAA,OAAO;;AAC7C,SAAK,eAAe;;AAGT,gBAAA,UAAA,SAAb,SAKE,KAa6C;QAZ7C,WAAQ,IAAA,UACR,YAAS,IAAA,WACT,qBAAkB,IAAA,oBAClB,gBAAa,IAAA,eACb,KAAA,IAAA,gBAAA,iBAAc,OAAA,SAAG,KAAE,IACnB,KAAA,IAAA,qBAAA,sBAAmB,OAAA,SAAG,QAAK,IACnB,oBAAiB,IAAA,QACzB,iBAAc,IAAA,gBACd,KAAA,IAAA,aAAA,cAAW,OAAA,SAAG,SAAM,IACpB,KAAA,IAAA,aAAA,cAAW,OAAA,SAAG,iBAAc,IAC5B,iBAAc,IAAA,gBACd,UAAO,IAAA;;;;;;AAEP,sBACE,UACA,UAAA,iGACA,UAAA,UAAA;AAEF,sBACE,UAAA,gBAAgB,kBAChB,gBAAgB,YAChB,gNACA,UAAA,gBAAA,kBAEI,gBAAkB,YAAA;AACxB,yBAAW,KAAK;AAEhB,uBAAS,KAAO,UAAC,UAAa;wBAErB,KAAA,aAAoB,UAAA;AACf,gBAAA,CAAA,KAAA,UAAW,UAAW;AAAqB,qBAAA,CAAQ,GAAE;;eAAjE;;;eAGI;iCAEE,KAAc,uBAClB,cAAQ,cAAA;cACR;cACA;cACA,SAAO;cACgB,OAAA;;gBAGzB,oBAAK;mBAMH,uBAAU,oBAAA;gBACV;gBACA,UAAS;gBACT;gBACA;gBACA;gBACA;gBACA;gBACA,QAAA;gBACC;;;AAKC,iBAAI;AAEV,mBAAA;oBACE,GAAA,IAAO,QAAQ,SACR,SAAA,QAAqB;qBAWxB,SAAI,KAAA,sBAAiC,UAAW,SAAK,SAAQ,IAAA,UAAA,EAAA,uBAAA,WAAA,QAAA,SAAA,QAAA;oBAC3D,sBAAsB,WAAA,gBAAA,QAAA;wBACpB,IAAA,YAAe;oBACd,eAAA,OAAA;;;oBAIH,oBAAmB;AACnB,qCAAmB,UAAQ;AAC5B,qCAAA,QAAA;;AAID,oBAAI,cAAO,SAAc,IAAK;oBAC5B,OAAA,mBAAiB,YAAe;AACjC,mCAAA,eAAA;;oBAGG,gBAAA,YACF,sBAAmB,cAAO;AAC3B,yBAAA,YAAA;;uBAQC,KAAA,mBAAU;kBACV;kBACA,QAAQ;kBACR,UAAS;kBACT;kBACA;kBACA;kBACA;kBACA,QAAA;kBACA;kBACA;kBACA;kBACA,kBAAc,qBAAA,aAAA;kBACd;kBACC;;2BAID;sBACF,SAAK,aAAmB;AAQxB,uBAAA;AACD,0BAAA;;uBAGC,SAAI,KAAA;sBACF,oBAAmB;AACnB,uCAAmB,UAAQ;AAC5B,uCAAA,QAAA;;sBAGC,oBAAW;AACZ,yBAAA,MAAA,iBAAA;;AAID,uBAAA;yBAEI,eAAiB,cAAA,MAAA,IAAA,YAAA;oBAEnB,cAAA;;;;;;;;;gBAMV,UAiKC,qBAAA,SAAA,UAAA,QAAA;AA3IC,QAAA,QAAA;AAEM,QAAA,WAAW,QAAQ;AAAA,eAAC,KAAA;;AAC1B,QAAM,SAAA,SAAuC;AAC7C,QAAM,cAAY;AAElB,QAAI,YAAU,SAAI,gBAAkB;QAClC,CAAA,aAAY,kBAAK,QAAA,SAAA,cAAA;kBACP,KAAA;QACR,QAAQ,OAAA;QACR,QAAO;QACP,OAAA,SAAW;QACV,WAAA,SAAA;;AAGH,UAAI,kBAAe,SAAA;UACjB,iBAAa;qBAAW,QAAA,SAAe,KAAA,SAAA;AACrC,cAAM,kBAAY,IAAA;AAClB,cAAI,YAAU,mBAAoB,gBAAK;cACrC,CAAA,aAAO,CAAA,gBAAA,KAAA,iBAAA,YAAA;AACR;;AAEK,cAAA,UAA8B,gBAAa;AAG3C,cAAA,KAA2C,MAAM,QAAY,IAAA,UAAA,WAAA,GAAA,UAAA,YAAA,GAAA;cACjE,KAAK,OAAE,KAAS;YAChB,OAAA;YACA;YACA,mBAAiB;YAJH,YAAA;cAOZ,qBAAY,GAAA,QAAoB,WAAA,GAAA;cAElC,YAAM,oBAA0B;gBAC9B,kBAAgB,QAAM,oBAAA;cACtB,gBAAW;cACX,WAAA,YAAgB,iBAAU,aAAA;cACzB,gBAAA;;gBAID,iBAAiB;0BACP,KAAA;gBACR,QAAQ;gBACR,QAAO;gBACP,OAAA;gBACC;;;;;;;QASX,YAAS,SAAA,KACT,SAAS,kBACT,SAAS,UACT,SAAS,kBAET,SAAM,kBAAoB;AAE1B,UAAI,YAAC;WACH,eAAa;qBACN,SAAW,QAAA;cACd,CAAA,WAAY;AACb,wBAAA,QAAA,SAAA,OAAA;AAAA,qBAAA,OAAA,MAAA;;;AAMD,cAAI,SAAQ,SAAA;cACV,QAAK;gBAKH,CAAA,WAAa;kBACX,OAAI,OAAA,KAAA;gBAIJ,IAAA;gBACA,OAAA,MAAW,UAAS,SAAS,UAAA;gBAC7B,WAAU,SAAO;gBACjB,YAAA;gBACC,mBAAA;;kBAGD,KAAA,UAAM;AACP,yBAAA,SAAA,SAAA,IAAA,SAAA,EAAA,MAAA,KAAA;;;mBAID,QAAS,QAAS;cAClB,SAAS,SAAE;cACV,WAAA,SAAA;;;cAMH,CAAA,aAAa,CAAA,SAAA,gBAAA;mBACT,OAAE;cACJ,IAAA;sBAAgB,SAAS,OAAA,KAAA;AACvB,oBAAA,YAAgB,IAAA,WAAK,UAAe,IAAM;AAC3C,uBAAA,cAAA,eAAA,QAAA;;;;;QAQP,SAAA,SAAiB;QAIjB,YAAA;QAMA,kBAAgB,SAAS;QAExB,gBAAQ,SAAM,kBAAW;SAE5B,QAAI,SAAS,SAAA;AAAA,eAAuB,UAAS,KAAA;;UAI3C,SAAO,uBAAqB,SAAK,gBAAM;AACxC,eAAA,QAAA,IAAA,WAAA,KAAA,WAAA;AAAA,iBAAA;;;;AAIJ,WAAA,QAAA,QAAA;;gBAED,UA4BC,yBAAA,SAAA,oBAAA,UAAA;AAdC,QAAM,QAAO;QACX,OAAE,OAAA,uBAA4B,aAC5B,mBAAmB,SAAA,aAEvB;WACE,KAAI,MAAA,4BAAA,SAAA,QAAA;UACF;AAID,cAAA,mBAAA,SAAA,SAAA,IAAA,WAAA,EAAA,QAAA,EAAA,WAAA;eACC;AACD,mBAAA,UAAA,MAAA;;OAEJ,SAAA;;gBAOQ,UAAK,aAAoB,SAE9B,SACA,SAAA,eACQ;AACX,WAAA,KAAA,qBAAA,SAAA,SAAA,eAAA;;gBAGY,UAA2C,gBAAa,WAAA;AACnE,QAAI,QAAQ,uBAAC,OAAQ;SACnB,QAAM,QAAW,SAAA,MAAA,SAAA;YACf,WAAW;QACX,WAAA,KAAe;QACf,eAAc,KAAK;QACnB,cAAa,KAAM;QACnB,eAAA,KAAA;;;AAGL,WAAA;;gBAGO,UAAY,cAAiB,SAAS,SAAA;AAC5C,QAAI,YAAW,KAAA,QAAA,IAAA;QACb,WAAU;AACV,gBAAU,eAAa;AACxB,gBAAA,gBAAA;;;gBAQO,UAAc,YAAS,SAAC,UAAA;AAEhC,QAAI,iBAAgB,KAAI;QACtB,CAAA,eAAiB,IAAG,WAAW;AAC/B,UAAM,cAAU,KAAA,MAAA,kBAAA;AAGhB,UAAM,UAAA,sCAA0C,KAAW,MAAE,iBAAA;AAC7D,UAAM,cAAc,KAAA,WAAgB,YAAW;AAE/C,UAAM,cAAU,WAAwB,KAAA,WAAA,YAAA;UACtC,eAAU;QAGV,UAAA;QACA,kBAAkB,iBAAiB;QACnC,oBAAW,KAAA,WAAA,qBAAA;QACX;QACA;QAKA,aAAO,iBAAA,uBAEL;iBACE,SAAQ,SAAS,IAAA,cAAA,EAAqB,aAAA,YAAA,YAAA,IAAA,SAAA,KAAA;cAClC,IAAI,SAAS,yBACf,IAAA,cAAA,SAAA;AACD,mBAAA,SAAA,SAAA,IAAA,MAAA,EAAA,WAAA;;AAED,iBACH;;;UAID,MAAI,SAAQ,KAAA;YACV,OAAA,CAAA,eAAsB,IAAE,MAAA;AACzB,yBAAA,IAAA,KAAA;;;AAMH,UAAI;AACJ,UAAI;AACJ,UAAI;AACL,UAAA;;AAGF,WAAA,eAAA,IAAA;;gBAMC,UAAA,eACU,SAAU,UAAU,WAAW;AAG1C,WAAA,SAAA,SAAA,IAAA,KAAA,UAAA,UAAA,cAAA;;gBAMQ,UAAA,aACF,SAAO,SACV;AAMF,cAAI,SAAe,SAAA,IAAA,UAAA,EAAA,WAAgC,KAAA,aAAa,QAAA,OAAA,QAAA;QAC9D,OAAO,QAAC,gCAAoC,aAAA;AAC7C,cAAA,8BAAA;;AAGD,QAAM,YAAU,IAAG,UAAI;QACrB,aAAY,IAAE,gBAAI;MAClB,cAAS;MACT;MACC;;AAIH,SAAA,QAAU,IAAK,WAAA,SAAA;cACb,KAAU;MACV,UAAA,QAAiB;MACjB,iBAAW;MACV,WAAA,QAAA;;AAGJ,WAAA;;gBAED,UA6BC,QAAA,SAAA,SAAA,SAAA;AA3BC,QAAA,QAAA;AAEA,QAAA,YACE,QAAa;AACb,gBAAA,KAAA;;cACE,UAAA,QACF,OAAA,2FAGkB,UAAK,QACvB,OAAA;AAGF,cACE,UAAkB,QAAA,MAAA,SAClB,YAAA,oDACA,UAAA,QAAA,MAAA,SAAA,YAAA;AAEF,cACE,UAAkB,CAAA,QAAA,mBAClB,4DACA,UAAA,CAAA,QAAA,mBAAA;AAEF,cAAO,UAAK,CAAA,QACV,cAEA,uDAAsC,UAAC,CAAA,QAAA,cAAA;AAC1C,WAAA,KAAA,WAAA,SAAA,SAAA,QAAA,WAAA;AAAA,aAAA,MAAA,UAAA;;;gBAIQ,UAAY,kBAAkB,WAAA;AACtC,WAAA,OAAA,KAAA;;gBAIQ,UAAK,oBAAmB,WAAA;AAChC,WAAA,KAAA;;gBAIQ,UAAY,qBAAqB,WAAA;AACzC,WAAA,OAAA,KAAA;;gBAGM,UAAA,mBAA4B,SAAS,SAAA;AAC1C,SAAK,4BAAmB;AACzB,SAAA;;gBAGO,UAAY,8BAA0B,SAAA,SAAA;AAC5C,QAAI,YAAS,KAAA,QAAA,IAAA;QAAE;AAChB,gBAAA;;gBAEiB,UAAA,aAAA,SAAA,SAAA;QAChB,YAAA,QAAoB;AAAA,gBAAA;QACrB,gBAAA;;;AAUC,SAAK,qBAAgB,UAAA,IAAS,eAAA,yEAAA,IAAA,eAAA;SAC5B,QAAI,QAAU,SAAA,WAAiB;UAG7B,UAAU,iBAAgB;AAC3B,kBAAA,gBAAA,cAAA;aACC;AACD,kBAAA;;;QAID,KAAK,eAAa;AACnB,WAAA,gBAAA,uBAAA,OAAA;;AAIF,WAAA,KAAA,MAAA,MAAA;;gBAED,UAuFC,uBAAA,SAAA,SAAA;AAtFC,QAAA,QAAA;AAEA,QAAM,YAAU,QAAwC;AAAA,gBAAA;;AACxD,QAAM,UAAA,oBAAA;AACN,QAAM,oBAAkB,oBAAG;AAE3B,QAAI,qBAAqB,oBAAG;QAC1B,MAAA,QAAQ,UAAQ;cACV,QAAO,SAAS,MAAQ;YAC1B,OAAA,SAAA,UAA0B;AAC3B,4BAAA,IAAA,MAAA;mBACC,eAAkB,OAAQ;AAC3B,4BAAA,IAAA,MAAA,UAAA,MAAA,UAAA;mBACC,gBAAmB,SAAU,KAAA,OAAA;AAC9B,6BAAA,IAAA;;;;iBAIsC,QAAA,SAAA,KAAE,SAAQ;AACnD,UAAI,KAAI,IAAA,iBAAA,WAAA,IAAA;UACN,IAAI;YACF,YAAY,OAAO;AACnB,kBAAO,IAAA,SAAA;AACR;;AAOD,YACE,YAAW,GAAA,WAAc,cAAA,GAAA,QAAA;YACzB,gBAAa,aAEb,YAAO,YAAA,CAAA,GAAA,gBAAA;AACR;;YAIC,YAAU,YACT,aAAY,kBAAkB,IAAI,cAEnC,YAAY,kBAAa,IAAA,WAAA;AACzB,kBAAI,IAAA,SAAS;cAAE;AACX,8BAAQ,IAAA,WAAA;cAAE;AACf,8BAAA,IAAA,UAAA;;;;QAKH,mBAAmB,MAAA;yBAID,QAAA,SAAa,SAAA;AAC7B,YAAM,UAAS,aAAQ;YACrB,YAAU,MAAQ,SAAK,SAAA,KAAA;UACvB,UAAS,QAAS;UACjB,WAAA,QAAA;;YAED,KAAA,IAAA,gBAAkB;UAClB,cAAS;UACT;UAIC,SAAA,SAAA,SAAA,IAAA,UAAA,EAAA,aAAA;;AAEH,kBAAU,GAAA,YAAA;AACV,kBAAQ,mBAAiB;AACxB,gBAAA,IAAA,SAAA;;;QAIH,WAAA,kBAA0B,MAAA;wBACX,QAAE,SAAA,UAAA,WAAA;YACb,CAAA,UAAU;AAKX,qBAAA,UAAA,KAAA,iBAAA,OAAA,OAAA,cAAA,WAAA,WAAA,IAAA,OAAA,KAAA,UAAA,WAAA,MAAA,IAAA;;;;AAKN,WAAA;;gBAED,UAqBC,2BAAA,SAAA,gBAAA;AApBC,QAAA,QAAA;AAEA,QAAM,mBAAA,QAA6D;AAAG,uBAAA;;AAEtE,QAAI,0BACF;SAEQ,qBAAgB,iBAAgB,QAAO,UAAC,QAAA,SAAA,iBAAA,SAAA;AAChD,UAAA,cAAgB,gBAAkB,QAAC;AACnC,sBAAI;UACA,kCACY,aACd,gBAAA,cAA6B;AAC9B,gCAAA,KAAA,gBAAA;;AAEA,YAAA,SAAA,SAAA,QAAA;;AAIH,SAAA;AACD,WAAA,QAAA,IAAA;;gBAGM,UAAS,qBAAyB,SAAA,iBAAmB;AAC3D,SAAA,SAAA,gBAAA,SAAA,mBAAA;;gBAED,UA0DC,2BAAA,SAAA,KAAA;QAzDC,QAAK;AAML,QAAA,QAAY,IAAC,OAAS,cAAQ,IAAS,aAAA,cAAA,IAAA,aAAA,YAAA,IAAA,WAAA,KAAA,IAAA,SAAA,UAAA,OAAA,SAAA,KAAA;AACvC,YAAA,KAAY,UAAK,OAAa;AAE9B,gBAAM,KAAA,aAAiB,OAAC;QACtB,iBAAK,SAAA,YACH;aAIA,MAAI,sBAA0B,OAAE,SAAA,YAAA,IAAA,SAAA,QAAA;YAG9B,gBAAI,YAAwB;cAC1B,kBAAiB,QAAA,cAAA;kBACf,MAAK,MAAA;cACL;cACA,QAAQ,OAAA;cACR,QAAA;cACC,WAAA;;;AAIN,gBAAA;;YAGC,sBAAsB,SAAA;gBACpB,IAAA,YAAe;YACd,eAAA,OAAA;;;AAIL,eAAA;;;QAGF,KAAM,UAAA,OAAA,kBAAyB;AAM/B,UAAA,sBAAsC,KAAA,WAAQ,qBAAA,OAAA,WAAA,SAAA,KAAA;aAC5C,IAAO,WAAuC,SAAA,UAAA;AAC9C,YAAA,MAAA;AAIA,4BAAO,KAAM,SAAO,YAAI;AAAA,iBAAc,MAAA,WAAA,UAAA;WAAA,SAAA;AACrC,eAAA,WAAA;AAAA,iBAAA,OAAA,IAAA;;;;AAIN,WAAA,eAAA;;gBAGM,UAAA,YAAqB,SAAS,SAAA;AACnC,SAAK,qBAAmB;AACzB,SAAA;;gBAGM,UAAA,uBAAqC,SAAA,SAAA;AAC1C,SAAK,4BAAqB;AAC3B,SAAA,YAAA;;gBAQM,UAAc,cAAQ,SAAS,SAAA;AACpC,SAAK,eAAS,OAAa;AAC3B,SAAK,SAAQ,SAAO;AACrB,SAAA,QAAA,OAAA;;gBAGU,UAAA,mBAAW,WAAA;QAAE,KAAK;AACvB,WAAC;AACN,SAAA,QAAA,QAAA,SAAA,MAAA;AAAA,aAAA,KAAA;;;gBAGQ,UAAK,gBAAW,WAAA;AACxB,WAAA,KAAA;;gBAOD,UA0EC,wBAAA,SAAA,OAAA,SAAA,WAAA,eAAA;;AAtEC,QAAA;AAKA,QAAI,kBAAuC,QAAA;AAAA,sBAAA,OAAA,YAAA,QAAA,YAAA,SAAA,SAAA,QAAA,wBAAA,QAAA,QAAA,SAAA,MAAA,KAAA;;AAEnC,QAAA;AACR,QAAI,cAAa,KAAA,UAAA,OAAA;QACT,aAAwC;AAE9C,UAAM,KAAA,MAAS,4BAAG,GAAA,yBAAA,OAAA,GAAA;UAChB,YAAO;QACP,OAAA;QACA;QACA,eAAc,iBAAc,gBAAA;QAI5B,SAAA,KAAA,eAAA,SAAA,SAAA,IAAA,UAAA,EAAA,YAAA,CAAA;;AAIF,gBAAI,UAAe;UACjB,eAAM;AACN,YAAA,gBAAA,0BAAyC,IAAA,gBAAa,oBAAA;AAEtD,kCAAgB,IAAA,aAAmB;AACnC,YAAA,YAAa,mBAAgB;AAE7B,qBAAK,cAAY,IAAA;YACf,CAAA,YAAa;cACX,UAAQ,IAAM,QAAA;YACb,QAAA,MAAA;;AAIH,wBAAQ,IAAQ,WAAA,aAAA;kBACV,QAAA,WAAkB;gBAClB,cAAY,OAAO,cACrB,cAAA,OAAA,GAAA;AACD,wCAAA,OAAA;;;;aAKL;qBACU,IAAI,QAAE;UACb,QAAA,MAAA;;;WAGL;mBACE,IAAa,QAAO;QACnB,WAAA,GAAA,EAAA,MAAA;;AAEJ,gBAAA,KAAA,eAAA;;AAGD,QAAI,cAAa,KAAA,UAAA,OAAA;QACf,aAAa;mBACJ,SAAK,YAAW,SAAa,QAAA;eAClC,MAAQ,WAAE,aAAW;UACrB,UAAA;UACA,cAAO;UACP;UACC;;;;AAKR,WAAA;;gBAWO,UAAY,qBAAuB,SAAQ,WAAA,oBAAoB,SAAA;AAErE,QAAA,YACE,UAAK,gBAAqB,KACxB;WAMA,SAAM,KAAY,sBAAuB,UAAQ,UAAA,QAAA,SAAA,QAAA,YAAA,SAAA,QAAA;AAIjD,UAAI,YAAS,gBAAc,OAAA;UACzB,aAAa,UAAI,eAAmB;YAElC,aAAM,QAAU,gBAAc,QAAY;gBACxC,UAAA,UAAsB,IAAA,YAAM;YAC1B,eAAA,OAAA;;;AAGN,kBAAU,WAAW,QAAC,SAAA;AACvB,kBAAA;;UAGC,MAAM;QACN,MAAA,OAAS;QACT,SAAA;QACA,eAAA,UAAA,iBAAA,cAAA;;UAGA,aAAa,QAAO,gBAAO,UAAA;AAC5B,YAAA,SAAA,OAAA;;AAKH,aAAA;gBACa,cAAG;UACZ,QAAE,cAAY,gBACZ,eAGA,IAAA,YAAa,EAAA;UACf,aAAU,UAAU,eAAO;AAC5B,kBAAA,UAAA;;AAIH,YAAA;;;gBAGJ,UA2EC,uBAAA,SAAA,SAAA,SAAA,eAAA;AArEC,QAAA,QAAA;AAEA,QAAM,kBAAa,QAAU;AAAA,sBAAe,cAAS;;AACrD,QAAM,QAAA,KAAY,UAAK,QAAa,OAAO;AAC3C,QAAM,YAAY,KAAK,aAAS,OAAS,QAAA;AAGvC,QAAA,YAKS,KAAA,SALT;AAOF,QAAM,MAAA,QAAa,aAAa,cAAc,QAAA,SAAA,gBAAA,KAAA,KAAA,QAAA,aAAA,cAAA,OAAA,SAAA,SAAA,IAAA,KAAA,QAAA,mBAAA,oBAAA,OAAA,SAAA,QAAA,IAAA,KAAA,QAAA,6BAAA,8BAAA,OAAA,SAAA,QAAA,IAAA,KAAA,QAAA,SAAA,UAAA,OAAA,SAAA,KAAA;QAC5C,aAAK,OAAA,OAAA,IAAA,SAAA;MACL;MACA;MACA;MACA;MACA;MACA;MACC;;QAMD,gBAAW,SAAY,YAAU;AACjC,iBAAO,YAAK;AAKZ,aAAA,MAAA,mBAAA,WAAA,YAAA;;SAMA,eAAW,IAAA,SAAM,SAAO,QAAQ;AAC/B,iBAAA,WAAA;AAAA,eAAA,QAAA,OAAA;;;QAcC,UAAO,IAAA,QAAW,KAAA,UAAA,WAChB,OAAgB,mBAIhB,KAAA,WAAc,qBAClB,WAAA,OAAA,WAAA,WAAA,WAAA,SAAA,KAAA,iBAEF,cAAgB,WAAA;YACd,QAAK,WAAe;AACpB,YAAA,eAAqB,OAAO;AAC3B,2BAAA;;AAGJ,WAAA;;gBAED,UA0JC,iBAAA,SAAA,KAAA;QAzJC,QAAA;AAOA,QAAM,cAAA,IAAA,aAA6B,UAI9B,IAAA,SAAA,KAAA,IAAA,YAAA,aAAA,OAAA,SAAA,QAAA,IAAA,KAAA,IAAA,kBAAA,mBAAA,OAAA,SAAA,aAAA,aAAA,oBAAA,SAAA,IAAA,iBAAA,IAAA;AAEL,QAAI,sBAAS,oBAAA;QACX,SAAK;WACH,qBAAoB,SAAW,QAAE,SAAA,IAAA,SAAA;4BAC7B,IAAA,SAAA;UACF;UACC,UAAA,MAAA,SAAA,SAAA;;;;AAMP,QAAI,UAAA,oBAAa;QACf,aAAW;WACT,MAAM,MAAE;QA+BR,QAAA;QASA,YAAA,cAAgB,oBAAA;QAEhB;wBAEI,SAAa,OAAA,MAAY,UAAS;cAClC,KAAK,MAAC,mBAAwB,aAE5B,MAAI,QAAA;cACN,IAAI;gBAIF,gBAAA;AAEA,kCACE,OAAc,GAAG;AAEnB,kBAAI,SAAM,eAAW,IAAA,MAAA;kBAGnB,WAAW,MAAC;AACb,yBAAA,GAAA;;kBAKC,WAAW,OAAK;AACjB,wBAAA,IAAA,IAAA;;AAKF,qBAAA;;gBAMC,mBAAmB,MAAK;AACzB,kCAAA,IAAA,GAAA,SAAA,EAAA,IAAA,UAAA;;;;;;QAOP,oBAAoB,MAAA;0BAAe,QAAQ,SAAA,KAAA,SAAM;AAC/C,YAAI,KAAA,IAAwE,IAAA,WAAA,IAAA,UAAA,OAAA,IAAA;AAI5E,YAAI;YACF,gBAAW;cACT,CAAA,MAAM;AACN,gBAAI,OAAM,GAAG;AACb,iBAAI;AACL,mBAAA,KAAA;;AAEF,mBAAA,eAAA,IAAA,MAAA;;YAIC,CAAA,kBAAmB,WAAG,MAAA;AACvB,mBAAA,GAAA;;YAGC,WAAW,OAAK;AACjB,kBAAA,IAAA,IAAA;;YAGC,QAAK,QAAA,yBAA8B,GAAA;AACpC,gBAAA,qBAAA;;;;QAYH,kBAAW;AACZ,WAAA,MAAA,iBAAA;;AAGF,WAAA;;gBAED,UAqJC,qBAAA,SAAA,WAAA,KAAA,eAAA;QAnJG,QAAK;AAcP,QAAM,QAAA,IAAA,OAAgB,YAAa,IAAA,WAAc,cAAA,IAAA,aAAA,qBAAA,IAAA,oBAAA,cAAA,IAAA,aAAA,oBAAA,IAAA,mBAAA,UAAA,IAAA,SAAA,8BAAA,IAAA;AAEjD,QAAA,mBAAe,UAAA;cACb,KAAU;MACV,UAAS;MACT;MACC;;AAIH,QAAM,YAAA,WAAmB;AAAA,aACM,UAC7B,QAAgE;;QAAhE,mBAAA,SAAA,OAAA,gBAAgB;AAEhB,UAAM,mBAAkB,QAAC;AAAA,yBAAA,UAAA,iBAAA,cAAA;;AAEzB,UAAI,OAAO,MAAA;UACP,WACA,CAAC,qBACH,CAAA,MAAA,MAAA,KAAA;AACD,8BAAA,MAAA;;AASD,UAAI,WAAQ,SAAK,OAAU;AAAK,eAAE,WAAA,GAAkB,SAAE,EAAA,MAAA,OAAA,SAAA,yBAAA,iBAAA,eAAA,kBAAA,MAAA,WAAA,OAAA,EAAA,SAAA;;UACpD,QAAO,MAAK,UAAW,OAAA,oBAAa;eAClC,MAAQ,WAAO,aAAA;UACf,UAAA;UACA,cAAO,EAAA;UACP;UACA;UACC,wBAAa;WACjB,KAAA,SAAA,UAAA;AAAA,iBAAA,SAAA,SAAA,QAAA;;;AAGD,aAAA,SAAA;;QAIA,qBAEoB,gBAAc,aAAO,sBACvC,cAAuB,WAEvB,uBAA2B,UAAA,IAEzB;QACJ,kBAAK,WAAA;aACH,MAAS,mBAAA,WAAA,oBAAA;QACT;QACA;QACA;QACA;;;QAIF,eAAO,+BACP,OAAA,qBAAqB,YACrB,qBAAA,iBAEF,yBAAqB;YACrB;;WACE,eAAa;AAEb,YAAI,OAAK;YACP,KAAA,UAAO;iBACL;YACA,iBAAA,MAAA,UAAA;;;YAIF,qBAAO,cAAA;iBACL;YACA,iBAAiB;YACjB;;;eAIF;UACA;;;WAIF,qBAAwB;AAExB,YAAI,OAAK;YACP,KAAA,YAAO,qBAAA,cAAA;iBACL;YACA,iBAAiB;YACjB;;;eAIF;UACA;;;WAIF;eACE;UACA,iBAAA,aAAA,UAAA;;WAGF;YACE,cAAO;iBACL;YACA,iBAAiB;YACjB;;;AAKN,eAAK,CAAA;WACH;YACE,cAAO;iBAIL;YACA,iBAAiB,UAAA;YACjB;;;AAKN,eAAK,CAAA;WACH;AACD,eAAA;;;gBAIG,UAAY,WAAa,SAAW,SAAG;QACzC,WAAK,CAAO,KAAK,QAAO,IAAE,UAAa;AACxC,WAAA,QAAA,IAAA,SAAA,IAAA,UAAA,MAAA;;AAEF,WAAA,KAAA,QAAA,IAAA;;gBAEsB,UAAA,iBAAA,SAAY,SAAA;AACjC,QAAM,YAAU,QAAQ;AAAA,gBAAW;;AACnC,QAAA,aAAA,KAAA,WACK,eACH;AAEH,WAAA,SAAA,SAAA,IAAA,aAAA,EAAA,iBAAA,KAAA;;AAp3CH,SAq3CC;;;;AC15CD,IAAI,uBAAuB;AA0BrB,sBAGJ,UACA,SAAiB;AAEjB,SAAO,QAAQ,UAAU,SAAS,QAAQ,aAAa;IACrD,WAAS,SAAA,SAAA,IACJ,SAAS,YACT,QAAQ;;;AAWjB,IAAA,eAAA,WAAA;AAmDE,yBAAY,SAAyC;AAArD,QAAA,QAAA;AA7CO,SAAA,iBAAiC;AAKhC,SAAA,sBAAiD;AACjD,SAAA,sBAAiD;AAyCrD,QAAA,MAqBE,QAAO,KApBT,cAoBE,QAAO,aAnBT,UAmBE,QAAO,SAlBT,SAkBE,QAAO,OAjBT,MAiBE,QAAO,SAjBT,UAAO,QAAA,SAAG,QAAK,KACf,KAgBE,QAAO,oBAhBT,qBAAkB,OAAA,SAAG,IAAC,IACtB,KAeE,QAAO,mBAfT,oBAAiB,OAAA,SAIf,OAAO,WAAW,YAClB,CAAE,OAAe,qBACjB,UAAO,IACT,KAQE,QAAO,oBART,qBAAkB,OAAA,SAAG,OAAI,IACzB,kBAOE,QAAO,gBANT,KAME,QAAO,wBANT,yBAAsB,OAAA,SAAG,QAAK,IAC9B,YAKE,QAAO,WAJT,WAIE,QAAO,UAHT,kBAGE,QAAO,iBAFH,sBAEJ,QAAO,MADA,yBACP,QAAO;AAEL,QAAA,OAAS,QAAO;AAEtB,QAAI,CAAC,MAAM;AACT,aAAO,MACH,IAAI,SAAS,EAAE,KAAK,aAAa,aACjC,WAAW;;AAGjB,QAAI,CAAC,QAAO;AACV,YAAM,UAAI,IAAA,eACR,gKAGA,IAAA,eAAA;;AAGJ,SAAK,OAAO;AACZ,SAAK,QAAQ;AACb,SAAK,wBAAwB,WAAW,qBAAqB;AAC7D,SAAK,qBAAqB;AAC1B,SAAK,iBAAiB,mBAAkB;AACxC,SAAK,WAAW;AAEhB,QAAI,oBAAoB;AACtB,iBACE,WAAA;AAAM,eAAC,MAAK,wBAAwB;SACpC;;AAIJ,SAAK,aAAa,KAAK,WAAW,KAAK;AACvC,SAAK,QAAQ,KAAK,MAAM,KAAK;AAC7B,SAAK,SAAS,KAAK,OAAO,KAAK;AAC/B,SAAK,aAAa,KAAK,WAAW,KAAK;AACvC,SAAK,2BAA2B,KAAK,yBAAyB,KAAK;AAEnE,QAAI,qBAAqB,OAAO,WAAW,UAAU;AAClD,aAAe,oBAAoB;;AAMtC,QAAI,CAAC,wBAAwB,SAAS;AACpC,6BAAuB;AACvB,UACE,OAAO,WAAW,eAClB,OAAO,YACP,OAAO,QAAQ,OAAO,QACtB,CAAE,OAAe,iCACjB;AACA,YAAM,MAAM,OAAO;AACnB,YAAM,KAAK,OAAO,IAAI;AACtB,YAAI,MAAG;AACP,YAAI,OAAO,OAAO,UAAU;AAC1B,cAAI,GAAG,QAAQ,aAAa,IAAI;AAC9B,kBAAM;qBAEG,GAAG,QAAQ,cAAc,IAAI;AACtC,kBAAM;;;AAGV,YAAI,KAAK;AACP,qBAAU,UACR,IAAA,uEACmB;;;;AAM3B,SAAK,UAAU;AAEf,SAAK,aAAa,IAAI,WAAW;MAC/B,OAAK;MACL,QAAQ;MACR;MACA;;AAGF,SAAK,eAAe,IAAI,aAAa;MACnC,OAAO,KAAK;MACZ,MAAM,KAAK;MACX;MACA;MACA,iBAAiB;QACf,MAAM;QACN,SAAS;;MAEX,YAAY,KAAK;MACjB;MACA,aAAa,oBAAoB,WAAA;AAC/B,YAAI,MAAK,gBAAgB;AACvB,gBAAK,eAAe;YAClB,QAAQ;YACR,OAAO;cACL,SAAS,MAAK,aAAa;cAC3B,WAAW,MAAK,aAAa,iBAAiB;;YAEhD,2BAA2B,MAAK,MAAM,QAAQ;;;UAGhD;;;AAQD,gBAAA,UAAA,OAAP,WAAA;AACE,SAAK,aAAa;;AAsBb,gBAAA,UAAA,aAAP,SACE,SAAyC;AAEzC,QAAI,KAAK,eAAe,YAAY;AAClC,gBAAU,aAAa,KAAK,eAAe,YAAY;;AAIzD,QACE,KAAK,yBACJ,SAAQ,gBAAgB,kBACvB,QAAQ,gBAAgB,sBAC1B;AACA,gBAAO,SAAA,SAAA,IAAQ,UAAO,EAAE,aAAa;;AAGvC,WAAO,KAAK,aAAa,WAA0B;;AAY9C,gBAAA,UAAA,QAAP,SACE,SAAoC;AAEpC,QAAI,KAAK,eAAe,OAAO;AAC7B,gBAAU,aAAa,KAAK,eAAe,OAAO;;AAGpD,cACG,UAAQ,QAAA,gBAA0C,qBACnD,uSAIA,UAAA,QAAA,gBAAA,qBAAA;AAEF,QAAI,KAAK,yBAAyB,QAAQ,gBAAgB,gBAAgB;AACxE,gBAAO,SAAA,SAAA,IAAQ,UAAO,EAAE,aAAa;;AAGvC,WAAO,KAAK,aAAa,MAAqB;;AAUzC,gBAAA,UAAA,SAAP,SAME,SAAqD;AAErD,QAAI,KAAK,eAAe,QAAQ;AAC9B,gBAAU,aAAa,KAAK,eAAe,QAAQ;;AAErD,WAAO,KAAK,aAAa,OAA4C;;AAOhE,gBAAA,UAAA,YAAP,SACE,SAA2C;AAE3C,WAAO,KAAK,aAAa,yBAA4B;;AAYhD,gBAAA,UAAA,YAAP,SACE,SACA,YAA2B;AAA3B,QAAA,eAAA,QAAA;AAAA,mBAAA;;AAEA,WAAO,KAAK,MAAM,UAAyB,SAAS;;AAiB/C,gBAAA,UAAA,eAAP,SACE,SACA,YAA2B;AAA3B,QAAA,eAAA,QAAA;AAAA,mBAAA;;AAEA,WAAO,KAAK,MAAM,aAA4B,SAAS;;AAQlD,gBAAA,UAAA,aAAP,SACE,SAAuD;AAEvD,SAAK,MAAM,WAA8B;AACzC,SAAK,aAAa;;AAcb,gBAAA,UAAA,gBAAP,SACE,SAA0D;AAE1D,SAAK,MAAM,cAAiC;AAC5C,SAAK,aAAa;;AAGb,gBAAA,UAAA,0BAAP,SAA+B,IAAa;AAC1C,SAAK,iBAAiB;;AAGjB,gBAAA,UAAA,eAAP,SAAoB,SAAuB;AACzC,WAAO,QAAQ,KAAK,MAAM;;AAmBrB,gBAAA,UAAA,aAAP,WAAA;AAAA,QAAA,QAAA;AACE,WAAO,QAAQ,UACZ,KAAK,WAAA;AAAM,aAAA,MAAK,aAAa,WAAW;QACvC,gBAAgB;;OAEjB,KAAK,WAAA;AAAM,aAAA,QAAQ,IAAI,MAAK,oBAAoB,IAAI,SAAA,IAAE;AAAI,eAAA;;OAC1D,KAAK,WAAA;AAAM,aAAA,MAAK;;;AAOd,gBAAA,UAAA,aAAP,WAAA;AAAA,QAAA,QAAA;AACE,WAAO,QAAQ,UACZ,KAAK,WAAA;AAAM,aAAA,MAAK,aAAa,WAAW;QACvC,gBAAgB;;OAEjB,KAAK,WAAA;AAAM,aAAA,QAAQ,IAAI,MAAK,oBAAoB,IAAI,SAAA,IAAE;AAAI,eAAA;;;;AAQxD,gBAAA,UAAA,eAAP,SAAoB,IAAsB;AAA1C,QAAA,QAAA;AACE,SAAK,oBAAoB,KAAK;AAC9B,WAAO,WAAA;AACL,YAAK,sBAAsB,MAAK,oBAAoB,OAAO,SAAA,GAAC;AAAI,eAAA,MAAM;;;;AASnE,gBAAA,UAAA,eAAP,SAAoB,IAAsB;AAA1C,QAAA,QAAA;AACE,SAAK,oBAAoB,KAAK;AAC9B,WAAO,WAAA;AACL,YAAK,sBAAsB,MAAK,oBAAoB,OAAO,SAAA,GAAC;AAAI,eAAA,MAAM;;;;AAgBnE,gBAAA,UAAA,2BAAP,SACE,gBAAwB;AAExB,WAAO,KAAK,aAAa,yBAAyB;;AAc7C,gBAAA,UAAA,iBAAP,SAIE,SAA+C;AAE/C,QAAM,MAAM,KAAK,aAAa,eAAe;AAC7C,QAAM,UAAkC;AACxC,QAAM,UAAmD;AAEzD,QAAI,QAAQ,SAAC,SAAQ,UAAQ;AAC3B,cAAQ,KAAK;AACb,cAAQ,KAAK;;AAGf,QAAM,SAAS,QAAQ,IACrB;AAKF,WAAO,UAAU;AACjB,WAAO,UAAU;AAKjB,WAAO,MAAM,SAAA,OAAK;AAChB,iBAAU,UAAM,MAAA,qEAAqE,OAAS;;AAGhG,WAAO;;AAWF,gBAAA,UAAA,uBAAP,SACE,SAAyC;AAAzC,QAAA,YAAA,QAAA;AAAA,gBAAA;;AAEA,WAAO,KAAK,aAAa,qBAAqB;;AAMzC,gBAAA,UAAA,UAAP,SAAe,YAAoB;AACjC,WAAO,KAAK,MAAM,QAAQ;;AAUrB,gBAAA,UAAA,UAAP,SAAe,iBAA4B;AACzC,WAAO,KAAK,MAAM,QAAQ;;AAMrB,gBAAA,UAAA,eAAP,SAAoB,WAAkC;AACpD,SAAK,WAAW,aAAa;;AAMxB,gBAAA,UAAA,eAAP,SAAoB,WAAkC;AACpD,SAAK,WAAW,aAAa;;AAMxB,gBAAA,UAAA,eAAP,WAAA;AACE,WAAO,KAAK,WAAW;;AAMlB,gBAAA,UAAA,+BAAP,SAAoC,iBAAgC;AAClE,SAAK,WAAW,mBAAmB;;AAM9B,gBAAA,UAAA,UAAP,SAAe,SAAmB;AAChC,SAAK,OAAO,KAAK,aAAa,OAAO;;AAEzC,SAAA;;;;AC3nBA,IAAM,WAAW,oBAAI;AAGrB,IAAM,oBAAoB,oBAAI;AAE9B,IAAI,wBAAwB;AAC5B,IAAI,gCAAgC;AAIpC,oBAAmB,QAAc;AAC/B,SAAO,OAAO,QAAQ,WAAW,KAAK;;AAGxC,yBAAyB,KAAa;AACpC,SAAO,WAAU,IAAI,OAAO,KAAK,UAAU,IAAI,OAAO,IAAI;;AAM5D,0BAA0B,KAAiB;AACzC,MAAM,WAAW,oBAAI;AACrB,MAAM,cAAgC;AAEtC,MAAI,YAAY,QAAQ,SAAA,oBAAkB;AACxC,QAAI,mBAAmB,SAAS,sBAAsB;AACpD,UAAI,eAAe,mBAAmB,KAAK;AAC3C,UAAI,YAAY,gBAAgB,mBAAmB;AAGnD,UAAI,eAAe,kBAAkB,IAAI;AACzC,UAAI,gBAAgB,CAAC,aAAa,IAAI,YAAY;AAGhD,YAAI,uBAAuB;AACzB,kBAAQ,KAAK,iCAAiC,eAAe;;iBAItD,CAAC,cAAc;AACxB,0BAAkB,IAAI,cAAc,eAAe,oBAAI;;AAGzD,mBAAa,IAAI;AAEjB,UAAI,CAAC,SAAS,IAAI,YAAY;AAC5B,iBAAS,IAAI;AACb,oBAAY,KAAK;;WAEd;AACL,kBAAY,KAAK;;;AAIrB,SAAA,SAAA,SAAA,IACK,MAAG,EACN;;AAIJ,kBAAkB,KAAiB;AACjC,MAAM,UAAU,IAAI,IAAyB,IAAI;AAEjD,UAAQ,QAAQ,SAAA,MAAI;AAClB,QAAI,KAAK;AAAK,aAAO,KAAK;AAC1B,WAAO,KAAK,MAAM,QAAQ,SAAA,KAAG;AAC3B,UAAM,QAAQ,KAAK;AACnB,UAAI,SAAS,OAAO,UAAU,UAAU;AACtC,gBAAQ,IAAI;;;;AAKlB,MAAM,MAAM,IAAI;AAChB,MAAI,KAAK;AACP,WAAO,IAAI;AACX,WAAO,IAAI;;AAGb,SAAO;;AAGT,uBAAuB,QAAc;AACnC,MAAI,WAAW,WAAU;AACzB,MAAI,CAAC,SAAS,IAAI,WAAW;AAC3B,QAAM,SAAS,MAAM,QAAQ;MAC3B;MACA,8BAA8B;;AAEhC,QAAI,CAAC,UAAU,OAAO,SAAS,YAAY;AACzC,YAAM,IAAI,MAAM;;AAElB,aAAS,IACP,UAGA,SAAS,iBAAiB;;AAG9B,SAAO,SAAS,IAAI;;AAIhB,aACJ,UAAoC;AACpC,MAAA,OAAA;WAAA,KAAA,GAAA,KAAA,UAAA,QAAA,MAAc;AAAd,SAAA,KAAA,KAAA,UAAA;;AAGA,MAAI,OAAO,aAAa,UAAU;AAChC,eAAW,CAAC;;AAGd,MAAI,SAAS,SAAS;AAEtB,OAAK,QAAQ,SAAC,KAAK,GAAC;AAClB,QAAI,OAAO,IAAI,SAAS,YAAY;AAClC,gBAAU,IAAI,IAAI,OAAO;WACpB;AACL,gBAAU;;AAEZ,cAAU,SAAS,IAAI;;AAGzB,SAAO,cAAc;;AAGjB,uBAAqB;AACzB,WAAS;AACT,oBAAkB;;AAGd,mCAAiC;AACrC,0BAAwB;;AAGpB,+CAA6C;AACjD,kCAAgC;;AAG5B,gDAA8C;AAClD,kCAAgC;;AAGlC,IAAM,SAAS;EACb;EACA;EACA;EACA;EACA;;AAGF,AAAA,UAAiB,OAAG;AAEhB,QAAA,MAKE,OAAM,KAJR,MAAA,cAIE,OAAM,aAHR,MAAA,0BAGE,OAAM,yBAFR,MAAA,sCAEE,OAAM,qCADR,MAAA,uCACE,OAAM;GAPK,OAAA,OAAG;AAUpB,IAAI,aAAU;;;AC9Ed,aAAa,cAAM,QAAQ;;;AC3F3B,aAAuB;;;ACFvB,YAAuB;AAcvB,IAAM,aAAa,eACf,OAAO,IAAI,wBACX;AAEE,4BAA0B;AAC9B,MAAI,UAAW,AAAM,oBAAsB;AAC3C,MAAI,CAAC,SAAS;AACZ,WAAO,eAAqB,qBAAe,YAAY;MACrD,OAAO,UAAU,AAAM,oBAAkC;MACzD,YAAY;MACZ,UAAU;MACV,cAAc;;AAEhB,YAAQ,cAAc;;AAExB,SAAO;;;;ADlBF,IAAM,iBAAgD,SAAA,OAAK;AAChE,MAAM,gBAAgB;AACtB,SAAO,AACL,qBAAA,cAAc,UAAS,MAAA,SACpB,SAAa;AACZ,cACE,UAAO,WAAY,QACnB,QAAA,+GAEA,UAAA,WAAA,QAAA,QAAA;AACF,WAAO,MAAM,SAAS,QAAQ;;;;;AEnBtC,aAAuB;AAUhB,IAAM,iBAAqD,SAAC,KAGlE;MAFC,SAAM,IAAA,QACN,WAAQ,IAAA;AAER,MAAM,gBAAgB;AACtB,SAAO,AACL,qBAAA,cAAc,UAAS,MAAA,SACpB,SAAkB;AAAjB,QAAA,YAAA,QAAA;AAAA,gBAAA;;AACA,QAAI,UAAU,QAAQ,WAAW,QAAQ;AACvC,gBAAU,OAAO,OAAO,IAAI,SAAS,EAAE;;AAGzC,cACE,UAAQ,QACR,QAAA,+GAEA,UAAA,QAAA,QAAA;AAEF,WACE,AAAA,qBAAC,cAAc,UAAQ,EAAC,OAAO,WAC5B;;;;;AC/Bb,mBAA2B;AAIrB,yBACJ,UAA+B;AAE/B,MAAM,UAAU,6BAAW;AAC3B,MAAM,SAAS,YAAY,QAAQ;AACnC,YACE,UACA,CAAA,CAAA,QAAA,wKAGA,UAAA,CAAA,CAAA,QAAA;AAEF,SAAO;;;;ACfT,oBAA+C;;;ACF/C,oBAAiE;;;ACSjE,IAAY;AAAZ,AAAA,UAAY,eAAY;AACtB,gBAAA,cAAA,WAAA,KAAA;AACA,gBAAA,cAAA,cAAA,KAAA;AACA,gBAAA,cAAA,kBAAA,KAAA;GAHU,gBAAA,gBAAY;AAYxB,IAAM,QAAQ,oBAAI;AAEZ,uBAAwB,MAAkB;AAC9C,MAAI;AACJ,UAAQ;SACD,aAAa;AAChB,aAAO;AACP;SACG,aAAa;AAChB,aAAO;AACP;SACG,aAAa;AAChB,aAAO;AACP;;AAEJ,SAAO;;AAIH,gBAAiB,UAAsB;AAC3C,MAAM,SAAS,MAAM,IAAI;AACzB,MAAI;AAAQ,WAAO;AAEnB,MAAI,WAAW,MAAM;AAErB,YACE,UAAU,CAAA,CAAA,YAAc,CAAC,CAAA,SACzB,MAAA,eAAe,OAAQ,UAAA,gDACrB,iHAEF,UAAA,CAAA,CAAA,YAAA,CAAA,CAAA,SAAA,MAAA;AAEF,MAAM,YAAY,SAAS,YAAY,OACrC,SAAC,GAAiB;AAAK,WAAA,EAAE,SAAS;;AAGpC,MAAM,UAAU,SAAS,YAAY,OACnC,SAAC,GAAiB;AAChB,WAAA,EAAE,SAAS,yBAAyB,EAAE,cAAc;;AAGxD,MAAM,YAAY,SAAS,YAAY,OACrC,SAAC,GAAiB;AAChB,WAAA,EAAE,SAAS,yBAAyB,EAAE,cAAc;;AAGxD,MAAM,gBAAgB,SAAS,YAAY,OACzC,SAAC,GAAiB;AAChB,WAAA,EAAE,SAAS,yBAAyB,EAAE,cAAc;;AAGxD,YACE,UAAU,CAAC,UAAM,UACd,SAAQ,UAAU,UAAU,UAAU,cAAc,SACvD,2HAEA,UAAA,CAAA,UAAA,UAEF,SACE,UAAQ,UAAS,UAAgB,cAAG,SAAoB;YAEtD,UAAG,QAAQ,SAAA,UAAe,SAAO,cAAA,UAAa,GAAA,8EAC9C,GAAA,OAAA,UAAA,SAAqB,OAAA,QAAgB,QAAA,cAAc,OAAA,cAAA,QAAA,OACnD,qBAAA,OAAA,UAAA,QAAA,kBAGA,2EAA+D,UAAA,QAAA,SAAA,UAAA,SAAA,cAAA,UAAA,GAAA;AACnE,SAAK,QAAQ,SAAW,aAAU,QAAM,aAAA;MAAE,CAAA,QAAO,UAAY,CAAC,UAAA;AAExD,WAAA,aAAc;MAClB,cAAS,QAAA,SACP,oBACA,SACA,YAGF;YAEE,UAAG,YAAkB,WAAA,GAAA,sDAAgB,OAAA,UAAA,WACrC,GAAA,OAAA,YAAA,QAAA,oBAGE,2EAAuD,UAAA,YAAA,WAAA,GAAA;AAC7D,MAAA,aAAY,YAAW;AAEvB,cAAI,WAAmB,uBAAoB;MACzC,WAAO,QAAW,WAAW,KAAA,SAAA,QAAA;AAC9B,WAAA,WAAA,KAAA;SACC;AACD,WAAA;;AAGD,MAAA,UAAU,EAAA,MAAkB,MAAC;AAC7B,QAAA,IAAO,UAAQ;AAChB,SAAA;;AAGC,4BAAiC,UAAE,MAAA;AACnC,MAAM,YAAA,OAAA;AACN,MAAM,wBAAoB,cAAc;AACxC,MAAA,oBACgB,cACd,UAAA;YACE,UAAG,UAAA,SAAqB,MAAA,aAAW,OAAA,uBAAiB,0BAEzD,GAAA,OAAA,uBAAA,YAAA,OAAA,mBAAA,yBAAA,UAAA,UAAA,SAAA,MAAA;;;;ADzGK,kBAIJ,OACA,SAA6C;;AAE7C,MAAM,UAAU,8BAAW;AAC3B,MAAM,SAAS,gBAAgB,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS;AACxC,MAAM,2BAA2B,OAAO,eAAe;AACvD,qBAAmB,OAAO,aAAa;AACjC,MAAA,KAA0B,4BAAS,WAAA;AACvC,QAAM,oBAAoB,wBAAwB,OAAO,SAAS;AAIlE,QAAI,YAAsD;AAC1D,QAAI,QAAQ,gBAAgB;AAC1B,kBAAW,QAAQ,eAAe,iBAAiB;;AAGrD,QAAI,CAAC,WAAU;AAEb,kBAAW,OAAO,WAAW;AAC7B,UAAI,QAAQ,gBAAgB;AAC1B,gBAAQ,eAAe,sBACrB,WACA;;;AAKN,QACE,QAAQ,kBACR,aAAO,QAAP,YAAO,SAAA,SAAP,QAAS,SAAQ,SACjB,CAAC,aAAO,QAAP,YAAO,SAAA,SAAP,QAAS,SACV,UAAS,mBAAmB,SAC5B;AAEA,cAAQ,eAAe,gBACrB;QAGE,YAAY,WAAA;AAAM,iBAAA,wBAAwB,OAAO,SAAS;;QAC1D,WAAW,WAAA;AAAM,iBAAA,IAAI,QAAc,SAAC,SAAO;AACzC,gBAAM,MAAM,UAAU,UAAU;cAC9B,MAAI,SAAC,SAAM;AACT,oBAAI,CAAC,QAAO,SAAS;AACnB;AACA,sBAAI;;;cAGR,OAAK,WAAA;AACH;AACA,oBAAI;;cAEN,UAAQ,WAAA;AACN;;;;;SAMR,WAAA;AAAM,eAAA;;;AAIV,WAAO;MAxDF,WAAQ,GAAA,IAAE,cAAW,GAAA;AA2DxB,MAAA,KAAsB,4BAAS,WAAA;;AACjC,QAAM,UAAS,SAAS;AACxB,QAAI,CAAC,QAAO,WAAW,SAAS;AAC9B,UAAI,QAAO,OAAO;AAChB,QAAA,OAAA,QAAQ,aAAO,QAAA,QAAA,SAAA,SAAA,IAAA,KAAf,SAAkB,QAAO;iBAChB,QAAO,MAAM;AACtB,QAAA,OAAA,QAAQ,iBAAW,QAAA,QAAA,SAAA,SAAA,IAAA,KAAnB,SAAsB,QAAO;;;AAIjC,WAAO;MAVJ,SAAM,GAAA,IAAE,YAAS,GAAA;AAatB,MAAM,MAAM,0BAAO;IACjB;IACA;IACA;IACA;IACA,cAAc;IACd,mBAAmB,wBAAwB,OAAO,SAAS;;AAM7D,+BAAU,WAAA;;AACR,QAAM,oBAAoB,wBAAwB,OAAO,SAAS;AAClE,QAAI;AACJ,QAAI,IAAI,QAAQ,WAAW,UAAU,CAAC,MAAM,IAAI,QAAQ,OAAO,QAAQ;AACrE,UAAM,aAAW,OAAO,WAAW;AACnC,kBAAY;AACZ,mBAAa,WAAS;eACb,CAAC,MAAM,IAAI,QAAQ,mBAAmB,oBAAoB;AACnE,eAAS,WAAW,mBAAmB,MAAM,WAAA;;AAC7C,mBAAa,SAAS;AACtB,UAAI,QAAQ,oBAAoB;;AAGlC,QAAI,YAAY;AACd,UAAM,iBAAiB,IAAI,QAAQ;AACnC,UAAI,eAAe,MAAM;AACvB,YAAI,QAAQ,eAAe,eAAe;;AAG5C,gBAAU,IAAI,QAAQ,SAAS;AAC/B,UAAI,CAAC,WAAW,WAAW,SAAS;AAClC,YAAI,WAAW,OAAO;AACpB,UAAA,OAAA,QAAQ,aAAO,QAAA,QAAA,SAAA,SAAA,IAAA,KAAf,SAAkB,WAAW;mBACpB,WAAW,MAAM;AAC1B,UAAA,OAAA,QAAQ,iBAAW,QAAA,QAAA,SAAA,SAAA,IAAA,KAAnB,SAAsB,WAAW;;;;AAKvC,WAAO,OAAO,IAAI,SAAS,EAAE,QAAQ;KACpC,CAAC,UAAU,QAAQ,OAAO;AAG7B,+BAAU,WAAA;AACR,QAAI,QAAQ,gBAAgB;AAC1B;;AAGF,QAAI,eAAe,SAAS,UAAU,QAAQ;AAI9C,sBAAe;;AACb,UAAM,iBAAiB,IAAI,QAAQ;AACnC,UAAM,UAAS,SAAS;AAExB,UACE,kBACA,eAAe,YAAY,QAAO,WAClC,eAAe,kBAAkB,QAAO,iBACxC,MAAM,eAAe,MAAM,QAAO,OAClC;AACA;;AAGF,UAAI,eAAe,MAAM;AACvB,YAAI,QAAQ,eAAe,eAAe;;AAG5C,gBAAU,IAAI,QAAQ,SAAS;AAC/B,UAAI,CAAC,QAAO,SAAS;AACnB,QAAA,OAAA,OAAA,IAAI,QAAQ,aAAO,QAAA,QAAA,SAAA,SAAA,IAAE,iBAAW,QAAA,QAAA,SAAA,SAAA,IAAA,KAAA,KAAG,QAAO;;;AAI9C,qBAAiB,OAAY;;AAC3B,UAAM,OAAO,SAAS;AACtB,mBAAa;AAQb,UAAI;AACF,iBAAS;AACT,uBAAe,SAAS,UAAU,QAAQ;;AAE1C,iBAAS,UAAU;;AAGrB,UAAI,CAAC,MAAM,eAAe,kBAAkB;AAE1C,cAAM;;AAGR,UAAM,iBAAiB,IAAI,QAAQ;AACnC,UACG,kBAAkB,eAAe,WAClC,CAAC,MAAM,OAAO,eAAe,QAC7B;AACA,kBAAU,IAAI,QAAQ,SAAS;UAC7B,MAAM,eAAe;UACrB;UACA,SAAS;UACT,eAAe,cAAc;;AAE/B,QAAA,OAAA,OAAA,IAAI,QAAQ,aAAO,QAAA,QAAA,SAAA,SAAA,IAAE,aAAO,QAAA,QAAA,SAAA,SAAA,IAAA,KAAA,KAAG;;;AAInC,WAAO,WAAA;AAAM,aAAA,aAAa;;KACzB,CAAC,UAAU,QAAQ,gBAAgB,OAAO;AAE7C,MAAI;AACJ,EAAC,MAAyB,QAAvB,UAAO,IAAA,SAAK,SAAM,OAAA,KAApB,CAAA;AAED;AAME,QACE,WACA,aAAO,QAAP,YAAO,SAAA,SAAP,QAAS,mBACT,CAAC,OAAO,WACP,EAAC,OAAO,QAAQ,OAAO,KAAK,OAAO,MAAM,WAAW,MACrD,SAAS,QAAQ,gBAAgB,cACjC;AACA,eAAM,SAAA,SAAA,IACD,SAAM,EACT,SAAS,MACT,eAAe,cAAc;AAG/B,eAAS;;AAKX,QACE,QAAQ,kBACR,aAAO,QAAP,YAAO,SAAA,SAAP,QAAS,SAAQ,SACjB,CAAC,aAAO,QAAP,YAAO,SAAA,SAAP,QAAS,SACV,OAAO,SACP;AACA,eAAS,WAAW,wBAAwB,OAAO,SAAS,2BAA2B,MAAM,WAAA;;;AAK/F,WAAO,OAAO,IAAI,SAAS,EAAE;;AAG/B,MACG,SAAQ,kBAAkB,OAAO,0BAClC,aAAO,QAAP,YAAO,SAAA,SAAP,QAAS,SAAQ,OACjB;AAGA,aAAS,IAAI,QAAQ,SAAS;MAC5B,SAAS;MACT,MAAM;MACN,OAAO;MACP,eAAe,cAAc;;aAEtB,aAAO,QAAP,YAAO,SAAA,SAAP,QAAS,SAAQ,aAAO,QAAP,YAAO,SAAA,SAAP,QAAS,iBAAgB,WAAW;AAW9D,aAAS;MACP,SAAS;MACT,MAAM;MACN,OAAO;MACP,eAAe,cAAc;;;AAIjC,MAAI,OAAO,UAAU,OAAO,OAAO,QAAQ;AAKzC,aAAM,SAAA,SAAA,IACD,SAAM,EACT,OAAO,OAAO,SAAS,IAAI,YAAY,EAAE,eAAe,OAAO;;AAInE,MAAM,iBAAiB,2BAAQ,WAAA;AAAM,WAAC;MACpC,SAAS,SAAS,QAAQ,KAAK;MAC/B,WAAW,SAAS,UAAU,KAAK;MACnC,aAAa,SAAS,YAAY,KAAK;MACvC,cAAc,SAAS,aAAa,KAAK;MACzC,aAAa,SAAS,YAAY,KAAK;MACvC,iBAAiB,SAAS,gBAAgB,KAAK;;KAC7C,CAAC;AAEL,SAAA,SAAA,SAAA,SAAA,IACK,iBAAc,EACjB,WAAW,wBAAwB,OAAO,SAAS,0BAA0B,WAC7E,QACA,QAAQ,MACR,cAAc,IAAI,QAAQ,iBACvB;;AAOP,iCACE,OACA,SACA,iBAAqD;;AADrD,MAAA,YAAA,QAAA;AAAA,cAAA;;AAOE,MAAA,OAME,QAAO,MALT,MAKE,QAAO,KAJT,cAIE,QAAO,aAHT,UAGE,QAAO,SAFT,cAEE,QAAO,aADN,eAAY,OACb,SAPE,CAAA,QAAA,OAAA,eAAA,WAAA;AASN,MAAI,oBAAiB,SAAA,EAAK,SAAU;AACpC,MAAI,iBAAgB;AAClB,wBAAoB,aAAa,iBAAgB;;AAGnD,MAAI,MAAM;AACR,sBAAkB,cAAc;aAEhC,QAAA,kBAAkB,aAAO,QAAA,QAAA,SAAA,SAAA,IAAE,mBAEzB,mBAAkB,gBAAgB,kBAClC,kBAAkB,gBAAgB,sBAEpC;AAGA,sBAAkB,cAAc;aACvB,CAAC,kBAAkB,aAAa;AAGzC,sBAAkB,cAAc;;AAGlC,MAAI,CAAC,kBAAkB,WAAW;AAChC,sBAAkB,YAAY;;AAGhC,SAAO;;;;ADpWT,IAAM,gBAAgB;EACpB;EACA;EACA;EACA;EACA;;AAGI,sBACJ,OACA,SAAiD;AAE3C,MAAA,MAA4B,4BAG/B;IACD,QAAQ;MAJH,YAAS,IAAA,IAAE,eAAY,IAAA;AAO9B,MAAI,SAAS,SAA4B,OAAK,SAAA,SAAA,SAAA,IACzC,UACA,UAAU,UAAO,EAGpB,aAAa,UAAU,SAAS,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS,cAAc,WACvD,MAAM;AAGR,MAAI,CAAC,UAAU,QAAQ;AACrB,aAAM,SAAA,SAAA,IACD,SAAM,EACT,SAAS,OACT,MAAM,QACN,OAAO,QACP,QAAQ;;AAKZ,MAAM,eAAe,2BAAQ,WAAA;AAC3B,QAAM,gBAAoC;2BAC/B,MAAG;AACZ,UAAM,SAAS,OAAO;AACtB,oBAAa,QAAO,WAAA;AAAC,YAAA,OAAA;iBAAA,MAAA,GAAA,MAAA,UAAA,QAAA,OAAY;AAAZ,eAAA,OAAA,UAAA;;AACnB,qBAAa,SAAC,YAAS;AAAK,iBAAA,SAAA,SAAA,IAAM,aAAS,EAAE,QAAQ;;AACrD,eAAQ,OAAc,MAAA,QAAI;;;AAJ9B,aAAkB,KAAA,GAAA,kBAAA,eAAA,KAAA,gBAAA,QAAA,MAAa;AAA1B,UAAM,MAAG,gBAAA;cAAH;;AAQX,WAAO;KACN;AAEH,SAAO,QAAQ,OAAO,SAAS;AAC/B,SAAO,OAAO,QAAQ;AAEtB,MAAM,WAAU,+BAEd,SAAC,gBAA6C;AAC9C,iBAAa,EAAE,QAAQ,MAAM,SAAS;AACtC,QAAM,UAAU,OAAO,QAAQ,mBAAc,QAAd,mBAAc,SAAA,SAAd,eAAgB,WAAW,KAAK,SAAC,SAAO;AACrE,UAAM,UAAO,SAAA,SAAA,IACR,SAAM,EACT,MAAM,QAAQ,MACd,OAAO,QAAQ,OACf,QAAQ,MACR,SAAS;AAGX,aAAO,OAAO,SAAS;AACvB,aAAO;;AAKT,YAAQ,MAAM,WAAA;;AAEd,WAAO;KACN;AAEH,SAAO,CAAC,UAAS;;;;AG7FnB,oBAAyD;AAqBnD,qBAMJ,UACA,SAA0D;AAE1D,MAAM,SAAS,gBAAgB,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS;AACxC,qBAAmB,UAAU,aAAa;AACpC,MAAA,MAAsB,4BAAwC;IAClE,QAAQ;IACR,SAAS;IACT;MAHK,SAAM,IAAA,IAAE,YAAS,IAAA;AAMxB,MAAM,MAAM,0BAAO;IACjB;IACA,YAAY;IACZ,WAAW;IACX;IACA;IACA;;AAKF;AACE,WAAO,OAAO,IAAI,SAAS,EAAE,QAAQ,SAAS;;AAGhD,MAAM,WAAU,+BAAY,SAC1B,gBAKM;AALN,QAAA,mBAAA,QAAA;AAAA,uBAAA;;AAOM,QAAA,MAA8B,IAAI,SAAjC,UAAM,IAAA,QAAE,WAAO,IAAA,SAAE,YAAQ,IAAA;AAChC,QAAM,cAAW,SAAA,SAAA,IAAQ,WAAO,EAAE,UAAQ;AAC1C,QAAI,CAAC,IAAI,QAAQ,OAAO,WAAW,CAAC,YAAY,eAAe;AAC7D,gBAAU,IAAI,QAAQ,SAAS;QAC7B,SAAS;QACT,OAAO;QACP,MAAM;QACN,QAAQ;QACR,QAAM;;;AAIV,QAAM,aAAa,EAAE,IAAI,QAAQ;AACjC,QAAM,gBAAgB,aACpB,aACA;AAGF,WAAO,QAAO,OAAO,eAAe,KAAK,SAAC,UAAQ;;AACxC,UAAA,OAAiB,SAAQ,MAAnB,SAAW,SAAQ;AACjC,UAAM,QACJ,UAAU,OAAO,SAAS,IACtB,IAAI,YAAY,EAAE,eAAe,YACjC;AAEN,UACE,eAAe,IAAI,QAAQ,cAC3B,CAAC,cAAc,eACf;AACA,YAAM,WAAS;UACb,QAAQ;UACR,SAAS;UACT;UACA;UACA,QAAM;;AAGR,YAAI,IAAI,QAAQ,aAAa,CAAC,MAAM,IAAI,QAAQ,QAAQ,WAAS;AAC/D,oBAAU,IAAI,QAAQ,SAAS;;;AAInC,MAAA,OAAA,YAAY,iBAAW,QAAA,QAAA,SAAA,SAAA,IAAA,KAAvB,aAA0B,SAAS;AACnC,MAAA,MAAA,eAAe,iBAAW,QAAA,OAAA,SAAA,SAAA,GAAA,KAA1B,gBAA6B,SAAS;AACtC,aAAO;OACN,MAAM,SAAC,OAAK;;AACb,UACE,eAAe,IAAI,QAAQ,cAC3B,IAAI,QAAQ,WACZ;AACA,YAAM,WAAS;UACb,SAAS;UACT;UACA,MAAM;UACN,QAAQ;UACR,QAAM;;AAGR,YAAI,CAAC,MAAM,IAAI,QAAQ,QAAQ,WAAS;AACtC,oBAAU,IAAI,QAAQ,SAAS;;;AAInC,UAAI,YAAY,WAAW,cAAc,SAAS;AAChD,QAAA,OAAA,YAAY,aAAO,QAAA,QAAA,SAAA,SAAA,IAAA,KAAnB,aAAsB;AACtB,QAAA,MAAA,eAAe,aAAO,QAAA,OAAA,SAAA,SAAA,GAAA,KAAtB,gBAAyB;AAEzB,eAAO,EAAE,MAAM,QAAQ,QAAQ;;AAGjC,YAAM;;KAEP;AAEH,MAAM,QAAQ,+BAAY,WAAA;AACxB,cAAU,EAAE,QAAQ,OAAO,SAAS,OAAO;KAC1C;AAEH,+BAAU,WAAA;AAAM,WAAA,WAAA;AACd,UAAI,QAAQ,YAAY;;KACvB;AAEH,SAAO,CAAC,UAAO,SAAA,EAAI,SAAU;;;;AC9I/B,oBAA4C;AAatC,yBACJ,cACA,SAAoD;AAEpD,MAAM,SAAS,gBAAgB,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS;AACxC,qBAAmB,cAAc,aAAa;AACxC,MAAA,MAAsB,4BAAoC;IAC9D,SAAS,CAAC,aAAO,QAAP,YAAO,SAAA,SAAP,QAAS;IACnB,OAAO;IACP,MAAM;IACN,WAAW,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS;MAJf,SAAM,IAAA,IAAE,YAAS,IAAA;AAOlB,MAAA,KAA8B,4BAAS,WAAA;AAC3C,QAAI,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS,MAAM;AACjB,aAAO;;AAGT,WAAO,OAAO,UAAU;MACtB,OAAO;MACP,WAAW,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS;MACpB,aAAa,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS;MACtB,SAAS,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS;;MATf,aAAU,GAAA,IAAE,gBAAa,GAAA;AAahC,MAAM,MAAM,0BAAO,EAAE,QAAQ,cAAc;AAC3C,+BAAU,WAAA;;AACR,QAAI,oBAAoB,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS;AACjC,QAAI,OAAO,sBAAsB,YAAY;AAC3C,0BAAoB,CAAC,CAAC,kBAAkB;;AAG1C,QAAI,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS,MAAM;AACjB,UAAI,CAAC,aAAO,QAAP,YAAO,SAAA,SAAP,QAAS,UAAS,CAAC,QAAA,IAAI,QAAQ,aAAO,QAAA,QAAA,SAAA,SAAA,IAAE,OAAM;AACjD,kBAAU;UACR,SAAS;UACT,MAAM;UACN,OAAO;UACP,WAAW,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS;;AAEtB,sBAAc;;eAGhB,sBAAsB,SACpB,YAAW,IAAI,QAAQ,UACvB,iBAAiB,IAAI,QAAQ,gBAC7B,aAAO,QAAP,YAAO,SAAA,SAAP,QAAS,iBAAgB,QAAA,IAAI,QAAQ,aAAO,QAAA,QAAA,SAAA,SAAA,IAAE,gBAC9C,CAAC,aAAO,QAAP,YAAO,SAAA,SAAP,QAAS,UAAS,CAAC,OAAA,IAAI,QAAQ,aAAO,QAAA,OAAA,SAAA,SAAA,GAAE,SACzC,CAAC,MAAM,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS,WAAW,MAAA,IAAI,QAAQ,aAAO,QAAA,OAAA,SAAA,SAAA,GAAE,aAElD;AACA,gBAAU;QACR,SAAS;QACT,MAAM;QACN,OAAO;QACP,WAAW,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS;;AAEtB,oBAAc,OAAO,UAAU;QAC7B,OAAO;QACP,WAAW,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS;QACpB,aAAa,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS;QACtB,SAAS,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS;;;AAItB,WAAO,OAAO,IAAI,SAAS,EAAE,QAAQ,cAAc;KAClD,CAAC,QAAQ,cAAc;AAE1B,+BAAU,WAAA;AACR,QAAI,CAAC,YAAY;AACf;;AAGF,QAAM,gBAAe,WAAW,UAAU;MACxC,MAAA,SAAK,aAAW;;AACd,YAAM,UAAS;UACb,SAAS;UAGT,MAAM,YAAY;UAClB,OAAO;UACP,WAAW,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS;;AAEtB,kBAAU;AAEV,QAAA,OAAA,OAAA,IAAI,QAAQ,aAAO,QAAA,QAAA,SAAA,SAAA,IAAE,wBAAkB,QAAA,QAAA,SAAA,SAAA,IAAA,KAAA,KAAG;UACxC;UACA,kBAAkB;;;MAGtB,OAAK,SAAC,OAAK;AACT,kBAAU;UACR,SAAS;UACT,MAAM;UACN;UACA,WAAW,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS;;;MAGxB,UAAQ,WAAA;;AACN,QAAA,OAAA,OAAA,IAAI,QAAQ,aAAO,QAAA,QAAA,SAAA,SAAA,IAAE,4BAAsB,QAAA,QAAA,SAAA,SAAA,IAAA,KAAA;;;AAI/C,WAAO,WAAA;AACL,oBAAa;;KAEd,CAAC;AAEJ,SAAO;;;;AC3HT,oBAAoC;AAG9B,wBAA4B,IAAkB;AAClD,MAAM,QAAQ;AAId,MAAM,WAAW,4BAAS,OAAO;AAKjC,+BAAU,WAAA;AACR,QAAM,oBAAoB;AAC1B,QAAI,UAAU,mBAAmB;AAG/B,eAAS;WACJ;AACL,aAAO,GAAG,aAAa;;KAExB,CAAC;AAEJ,SAAO;;",
  "names": []
}
